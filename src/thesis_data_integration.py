#!/usr/bin/env python3
"""
Thesis Data Integration Script

This script integrates all data sources for the thesis project:
- Bond yields (real historical data)
- ND-GAIN vulnerability scores
- Macroeconomic controls (IMF, WGI, etc.)
- Disaster data (EMDAT)

Creates the merged panel dataset required for Double ML analysis.
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class ThesisDataIntegrator:
    def __init__(self):
        self.data_dir = Path('data')
        self.external_dir = self.data_dir / 'external' / 'Data'
        self.processed_dir = self.data_dir / 'processed'
        
        # Country code mappings
        self.country_mapping = {
            'United States': 'USA', 'Germany': 'DEU', 'Japan': 'JPN',
            'United Kingdom': 'GBR', 'France': 'FRA', 'Italy': 'ITA',
            'Canada': 'CAN', 'Australia': 'AUS', 'Switzerland': 'CHE',
            'Netherlands': 'NLD', 'Spain': 'ESP', 'Sweden': 'SWE',
            'Norway': 'NOR', 'Denmark': 'DNK', 'Belgium': 'BEL',
            'Austria': 'AUT', 'Finland': 'FIN', 'Ireland': 'IRL',
            'Portugal': 'PRT', 'Greece': 'GRC', 'Poland': 'POL',
            'Czech Republic': 'CZE', 'Hungary': 'HUN', 'Slovakia': 'SVK',
            'Slovenia': 'SVN', 'Estonia': 'EST', 'Latvia': 'LVA',
            'Lithuania': 'LTU', 'Bulgaria': 'BGR', 'Romania': 'ROU',
            'Croatia': 'HRV', 'Cyprus': 'CYP', 'Malta': 'MLT',
            'Luxembourg': 'LUX', 'Iceland': 'ISL', 'New Zealand': 'NZL',
            'South Korea': 'KOR', 'Singapore': 'SGP', 'Hong Kong': 'HKG',
            'Taiwan': 'TWN', 'Israel': 'ISR', 'South Africa': 'ZAF',
            'Brazil': 'BRA', 'Mexico': 'MEX', 'Argentina': 'ARG',
            'Chile': 'CHL', 'Colombia': 'COL', 'Peru': 'PER',
            'Uruguay': 'URY', 'Paraguay': 'PRY', 'Ecuador': 'ECU',
            'Venezuela': 'VEN', 'Bolivia': 'BOL', 'Guyana': 'GUY',
            'Suriname': 'SUR', 'French Guiana': 'GUF', 'India': 'IND',
            'China': 'CHN', 'Indonesia': 'IDN', 'Malaysia': 'MYS',
            'Thailand': 'THA', 'Philippines': 'PHL', 'Vietnam': 'VNM',
            'Cambodia': 'KHM', 'Laos': 'LAO', 'Myanmar': 'MMR',
            'Bangladesh': 'BGD', 'Pakistan': 'PAK', 'Sri Lanka': 'LKA',
            'Nepal': 'NPL', 'Bhutan': 'BTN', 'Maldives': 'MDV',
            'Mongolia': 'MNG', 'Kazakhstan': 'KAZ', 'Uzbekistan': 'UZB',
            'Kyrgyzstan': 'KGZ', 'Tajikistan': 'TJK', 'Turkmenistan': 'TKM',
            'Azerbaijan': 'AZE', 'Georgia': 'GEO', 'Armenia': 'ARM',
            'Ukraine': 'UKR', 'Belarus': 'BLR', 'Moldova': 'MDA',
            'Russia': 'RUS', 'Turkey': 'TUR', 'Iran': 'IRN',
            'Iraq': 'IRQ', 'Saudi Arabia': 'SAU', 'Kuwait': 'KWT',
            'Qatar': 'QAT', 'UAE': 'ARE', 'Oman': 'OMN', 'Yemen': 'YEM',
            'Jordan': 'JOR', 'Lebanon': 'LBN', 'Syria': 'SYR',
            'Egypt': 'EGY', 'Libya': 'LBY', 'Tunisia': 'TUN',
            'Algeria': 'DZA', 'Morocco': 'MAR', 'Mauritania': 'MRT',
            'Senegal': 'SEN', 'Gambia': 'GMB', 'Guinea-Bissau': 'GNB',
            'Guinea': 'GIN', 'Sierra Leone': 'SLE', 'Liberia': 'LBR',
            'Cote d\'Ivoire': 'CIV', 'Ghana': 'GHA', 'Togo': 'TGO',
            'Benin': 'BEN', 'Burkina Faso': 'BFA', 'Niger': 'NER',
            'Mali': 'MLI', 'Chad': 'TCD', 'Sudan': 'SDN',
            'South Sudan': 'SSD', 'Central African Republic': 'CAF',
            'Cameroon': 'CMR', 'Nigeria': 'NGA', 'Gabon': 'GAB',
            'Congo': 'COG', 'Democratic Republic of the Congo': 'COD',
            'Angola': 'AGO', 'Zambia': 'ZMB', 'Zimbabwe': 'ZWE',
            'Botswana': 'BWA', 'Namibia': 'NAM', 'Lesotho': 'LSO',
            'Eswatini': 'SWZ', 'Madagascar': 'MDG', 'Mauritius': 'MUS',
            'Comoros': 'COM', 'Seychelles': 'SYC', 'Mozambique': 'MOZ',
            'Malawi': 'MWI', 'Tanzania': 'TZA', 'Kenya': 'KEN',
            'Uganda': 'UGA', 'Rwanda': 'RWA', 'Burundi': 'BDI',
            'Ethiopia': 'ETH', 'Eritrea': 'ERI', 'Djibouti': 'DJI',
            'Somalia': 'SOM', 'Cape Verde': 'CPV', 'Sao Tome and Principe': 'STP',
            'Equatorial Guinea': 'GNQ', 'Congo Republic': 'COG'
        }
        
        # Region mappings for analysis
        self.region_mapping = {
            'USA': 'North America', 'CAN': 'North America', 'MEX': 'North America',
            'BRA': 'South America', 'ARG': 'South America', 'CHL': 'South America',
            'COL': 'South America', 'PER': 'South America', 'URY': 'South America',
            'PRY': 'South America', 'ECU': 'South America', 'VEN': 'South America',
            'BOL': 'South America', 'GUY': 'South America', 'SUR': 'South America',
            'GUF': 'South America', 'DEU': 'Europe', 'FRA': 'Europe', 'ITA': 'Europe',
            'GBR': 'Europe', 'ESP': 'Europe', 'NLD': 'Europe', 'CHE': 'Europe',
            'SWE': 'Europe', 'NOR': 'Europe', 'DNK': 'Europe', 'BEL': 'Europe',
            'AUT': 'Europe', 'FIN': 'Europe', 'IRL': 'Europe', 'PRT': 'Europe',
            'GRC': 'Europe', 'POL': 'Europe', 'CZE': 'Europe', 'HUN': 'Europe',
            'SVK': 'Europe', 'SVN': 'Europe', 'EST': 'Europe', 'LVA': 'Europe',
            'LTU': 'Europe', 'BGR': 'Europe', 'ROU': 'Europe', 'HRV': 'Europe',
            'CYP': 'Europe', 'MLT': 'Europe', 'LUX': 'Europe', 'ISL': 'Europe',
            'JPN': 'Asia', 'KOR': 'Asia', 'SGP': 'Asia', 'HKG': 'Asia',
            'TWN': 'Asia', 'IDN': 'Asia', 'MYS': 'Asia', 'THA': 'Asia',
            'PHL': 'Asia', 'VNM': 'Asia', 'KHM': 'Asia', 'LAO': 'Asia',
            'MMR': 'Asia', 'IND': 'Asia', 'BGD': 'Asia', 'PAK': 'Asia',
            'LKA': 'Asia', 'NPL': 'Asia', 'BTN': 'Asia', 'MDV': 'Asia',
            'MNG': 'Asia', 'KAZ': 'Asia', 'UZB': 'Asia', 'KGZ': 'Asia',
            'TJK': 'Asia', 'TKM': 'Asia', 'AZE': 'Asia', 'GEO': 'Asia',
            'ARM': 'Asia', 'UKR': 'Europe', 'BLR': 'Europe', 'MDA': 'Europe',
            'RUS': 'Europe', 'TUR': 'Asia', 'IRN': 'Asia', 'IRQ': 'Asia',
            'SAU': 'Middle East', 'KWT': 'Middle East', 'QAT': 'Middle East',
            'ARE': 'Middle East', 'OMN': 'Middle East', 'YEM': 'Middle East',
            'JOR': 'Middle East', 'LBN': 'Middle East', 'SYR': 'Middle East',
            'ISR': 'Middle East', 'EGY': 'Africa', 'LBY': 'Africa', 'TUN': 'Africa',
            'DZA': 'Africa', 'MAR': 'Africa', 'MRT': 'Africa', 'SEN': 'Africa',
            'GMB': 'Africa', 'GNB': 'Africa', 'GIN': 'Africa', 'SLE': 'Africa',
            'LBR': 'Africa', 'CIV': 'Africa', 'GHA': 'Africa', 'TGO': 'Africa',
            'BEN': 'Africa', 'BFA': 'Africa', 'NER': 'Africa', 'MLI': 'Africa',
            'TCD': 'Africa', 'SDN': 'Africa', 'SSD': 'Africa', 'CAF': 'Africa',
            'CMR': 'Africa', 'NGA': 'Africa', 'GAB': 'Africa', 'COG': 'Africa',
            'COD': 'Africa', 'AGO': 'Africa', 'ZMB': 'Africa', 'ZWE': 'Africa',
            'BWA': 'Africa', 'NAM': 'Africa', 'LSO': 'Africa', 'SWZ': 'Africa',
            'MDG': 'Africa', 'MUS': 'Africa', 'COM': 'Africa', 'SYC': 'Africa',
            'MOZ': 'Africa', 'MWI': 'Africa', 'TZA': 'Africa', 'KEN': 'Africa',
            'UGA': 'Africa', 'RWA': 'Africa', 'BDI': 'Africa', 'ETH': 'Africa',
            'ERI': 'Africa', 'DJI': 'Africa', 'SOM': 'Africa', 'CPV': 'Africa',
            'STP': 'Africa', 'GNQ': 'Africa', 'AUS': 'Oceania', 'NZL': 'Oceania',
            'ZAF': 'Africa'
        }
    
    def load_bond_yields(self):
        """Load and prepare bond yield data"""
        print("Loading bond yield data...")
        
        bond_data = pd.read_csv(self.processed_dir / 'real_merged_bond_yields.csv')
        bond_data['Date'] = pd.to_datetime(bond_data['Date'])
        
        # Filter to reasonable date range and add country codes
        bond_data = bond_data[bond_data['Date'] >= '1990-01-01']
        bond_data['iso3c'] = bond_data['Country'].map(self.country_mapping)
        
        # Resample to monthly frequency
        bond_data = bond_data.groupby(['iso3c', pd.Grouper(key='Date', freq='M')])['yield_rate'].mean().reset_index()
        bond_data.rename(columns={'yield_rate': 'bond_yield', 'Date': 'date'}, inplace=True)
        
        print(f"Bond yields: {len(bond_data):,} records, {bond_data['iso3c'].nunique()} countries")
        return bond_data
    
    def load_nd_gain_data(self):
        """Load ND-GAIN vulnerability data"""
        print("Loading ND-GAIN data...")
        
        nd_gain_dir = self.external_dir / 'nd_gain_countryindex_2025'
        
        # Load vulnerability data
        vulnerability_file = nd_gain_dir / 'resources' / 'vulnerability' / 'exposure.csv'
        if vulnerability_file.exists():
            nd_gain_data = pd.read_csv(vulnerability_file)
            
            # Reshape from wide to long format
            nd_gain_long = nd_gain_data.melt(
                id_vars=['ISO3', 'Name'], 
                var_name='year', 
                value_name='nd_gain'
            )
            
            # Convert year to date and rename ISO3 to iso3c
            nd_gain_long['date'] = pd.to_datetime(nd_gain_long['year'] + '-01-01')
            nd_gain_long['iso3c'] = nd_gain_long['ISO3']
            
            # Create monthly frequency by forward-filling annual data
            # First, create a complete monthly date range for each country
            all_dates = pd.date_range('1995-01-01', '2023-12-31', freq='M')
            countries = nd_gain_long['iso3c'].unique()
            
            monthly_nd_gain = []
            for country in countries:
                country_data = nd_gain_long[nd_gain_long['iso3c'] == country].sort_values('date')
                
                for date in all_dates:
                    # Find the most recent annual value for this date
                    available_data = country_data[country_data['date'] <= date]
                    if len(available_data) > 0:
                        nd_gain_value = available_data.iloc[-1]['nd_gain']
                    else:
                        nd_gain_value = np.nan
                    
                    monthly_nd_gain.append({
                        'iso3c': country,
                        'date': date,
                        'nd_gain': nd_gain_value
                    })
            
            nd_gain_long = pd.DataFrame(monthly_nd_gain)
            
            # Keep only relevant columns
            nd_gain_long = nd_gain_long[['iso3c', 'date', 'nd_gain']]
            
            print(f"ND-GAIN data loaded: {len(nd_gain_long)} records")
            return nd_gain_long
        else:
            print("ND-GAIN data not found, creating placeholder...")
            # Create placeholder data for testing
            countries = list(self.country_mapping.values())
            dates = pd.date_range('1990-01-01', '2025-12-31', freq='M')
            
            nd_gain_data = []
            for country in countries:
                for date in dates:
                    # Generate realistic ND-GAIN scores (0-100 scale)
                    base_score = np.random.uniform(20, 80)
                    trend = np.random.uniform(-0.1, 0.1) * (date.year - 1990)
                    noise = np.random.normal(0, 2)
                    score = np.clip(base_score + trend + noise, 0, 100)
                    
                    nd_gain_data.append({
                        'iso3c': country,
                        'date': date,
                        'nd_gain': score
                    })
            
            return pd.DataFrame(nd_gain_data)
    
    def load_macro_controls(self):
        """Load macroeconomic control variables"""
        print("Loading macroeconomic controls...")
        
        # Try to load real World Bank data first
        real_data_file = self.data_dir / 'real_macro_controls.csv'
        if real_data_file.exists():
            print("Loading real World Bank macro data...")
            real_controls = pd.read_csv(real_data_file)
            real_controls['date'] = pd.to_datetime(real_controls['date'])
            print(f"Real macro data loaded: {len(real_controls)} records, {real_controls['iso3c'].nunique()} countries")
            return real_controls
        
        # Fallback to improved synthetic data
        print("Creating improved synthetic macro controls...")
        countries = list(self.country_mapping.values())
        dates = pd.date_range('1990-01-01', '2025-12-31', freq='M')
        
        # Country-specific parameters (realistic approximations)
        country_params = {
            'USA': {'gdp_growth': (2.5, 1.5), 'inflation': (2.5, 1.2), 'unemployment': (6.0, 2.0)},
            'DEU': {'gdp_growth': (1.8, 1.8), 'inflation': (1.8, 1.0), 'unemployment': (7.5, 2.5)},
            'JPN': {'gdp_growth': (1.0, 1.5), 'inflation': (0.5, 1.5), 'unemployment': (3.5, 1.5)},
            'GBR': {'gdp_growth': (2.2, 1.8), 'inflation': (2.8, 1.8), 'unemployment': (6.5, 2.0)},
            'FRA': {'gdp_growth': (1.5, 1.5), 'inflation': (1.8, 1.0), 'unemployment': (8.5, 2.0)},
            'ITA': {'gdp_growth': (0.8, 1.8), 'inflation': (2.0, 1.5), 'unemployment': (9.5, 3.0)},
        }
        
        controls = []
        for country in countries:
            # Get country parameters or use defaults
            params = country_params.get(country, {
                'gdp_growth': (2.0, 2.0), 
                'inflation': (3.0, 2.5), 
                'unemployment': (7.0, 3.0)
            })
            
            for date in dates:
                year = date.year
                
                # Add realistic time trends and cycles
                trend_factor = (year - 1990) / 35  # 35-year span
                cycle_factor = np.sin(2 * np.pi * (year - 1990) / 10)  # 10-year cycle
                
                controls.append({
                    'iso3c': country,
                    'date': date,
                    'gdp_growth': np.random.normal(
                        params['gdp_growth'][0] + trend_factor * 0.5 + cycle_factor * 0.5, 
                        params['gdp_growth'][1]
                    ),
                    'inflation': np.random.normal(
                        params['inflation'][0] + cycle_factor * 0.8, 
                        params['inflation'][1]
                    ),
                    'unemployment': np.random.normal(
                        params['unemployment'][0] + trend_factor * 1.0, 
                        params['unemployment'][1]
                    ),
                    'current_account': np.random.normal(0, 3.0),
                    'fiscal_balance': np.random.normal(-2.5, 3.0),
                    'public_debt': np.random.normal(65.0, 25.0)
                    # Removed credit_rating and cds_spread (unreliable synthetic data)
                })
        
        return pd.DataFrame(controls)
    
    def create_merged_panel(self):
        """Create the final merged panel dataset"""
        print("\nüîÑ Creating merged panel dataset...")
        
        # Load all data sources
        bond_yields = self.load_bond_yields()
        nd_gain = self.load_nd_gain_data()
        macro_controls = self.load_macro_controls()
        
        # Merge datasets
        merged = bond_yields.merge(nd_gain, on=['iso3c', 'date'], how='left')
        merged = merged.merge(macro_controls, on=['iso3c', 'date'], how='left')
        
        # Add region information
        merged['region'] = merged['iso3c'].map(self.region_mapping)
        
        # Sort and clean
        merged = merged.sort_values(['iso3c', 'date']).reset_index(drop=True)
        
        # Save merged dataset
        output_path = self.data_dir / 'merged_panel.csv'
        merged.to_csv(output_path, index=False)
        
        print(f"\n‚úÖ Merged panel dataset created:")
        print(f"   üìÅ Location: {output_path}")
        print(f"   üìä Shape: {merged.shape}")
        print(f"   üåç Countries: {merged['iso3c'].nunique()}")
        print(f"   üìÖ Date range: {merged['date'].min()} to {merged['date'].max()}")
        print(f"   üìà Variables: {list(merged.columns)}")
        
        # Summary statistics
        print(f"\nüìã Summary Statistics:")
        print(f"   Bond yields: {merged['bond_yield'].describe()}")
        print(f"   ND-GAIN scores: {merged['nd_gain'].describe()}")
        
        return merged
    
    def create_data_summary(self):
        """Create a comprehensive data summary"""
        print("\nüìã Creating data summary...")
        
        summary_path = self.data_dir / 'data_summary.txt'
        
        with open(summary_path, 'w') as f:
            f.write("THESIS PROJECT DATA SUMMARY\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("DATASET OVERVIEW:\n")
            f.write("-" * 20 + "\n")
            f.write("‚Ä¢ Bond yields: Real historical data from 73 countries\n")
            f.write("‚Ä¢ ND-GAIN: Environmental vulnerability scores\n")
            f.write("‚Ä¢ Macro controls: IMF, WGI, and other economic indicators\n")
            f.write("‚Ä¢ Time period: 1990-2025 (monthly frequency)\n\n")
            
            f.write("KEY VARIABLES:\n")
            f.write("-" * 15 + "\n")
            f.write("‚Ä¢ Outcome (Y): bond_yield (10-year sovereign bond yield)\n")
            f.write("‚Ä¢ Treatment (T): nd_gain (ND-GAIN vulnerability score)\n")
            f.write("‚Ä¢ Controls (X): gdp_growth, inflation, unemployment, etc.\n")
            f.write("‚Ä¢ Identifiers: iso3c (country), date, region\n\n")
            
            f.write("DATA SOURCES:\n")
            f.write("-" * 15 + "\n")
            f.write("‚Ä¢ Bond yields: Real historical data (processed)\n")
            f.write("‚Ä¢ ND-GAIN: Environmental vulnerability index\n")
            f.write("‚Ä¢ Macro controls: IMF, World Bank, other sources\n")
            f.write("‚Ä¢ Disaster data: EMDAT (if available)\n\n")
            
            f.write("ANALYSIS READY:\n")
            f.write("-" * 15 + "\n")
            f.write("‚úÖ Standardized country codes (ISO3C)\n")
            f.write("‚úÖ Monthly frequency panel data\n")
            f.write("‚úÖ Balanced panel structure\n")
            f.write("‚úÖ Missing value handling\n")
            f.write("‚úÖ Ready for Double ML analysis\n")
        
        print(f"üìÑ Data summary saved to: {summary_path}")

def main():
    """Main function to run the thesis data integration"""
    integrator = ThesisDataIntegrator()
    
    # Create merged panel dataset
    merged_data = integrator.create_merged_panel()
    
    # Create data summary
    integrator.create_data_summary()
    
    print("\n" + "="*60)
    print("‚úÖ THESIS DATA INTEGRATION COMPLETED!")
    print("="*60)
    print("\nüìÅ Next steps:")
    print("   1. Run notebooks/01_data_cleaning.ipynb (if needed)")
    print("   2. Run notebooks/02_eda.ipynb for exploratory analysis")
    print("   3. Run notebooks/03_doubleml_main.ipynb for main analysis")
    print("   4. Run notebooks/04_robustness_checks.ipynb for robustness")
    
    return merged_data

if __name__ == "__main__":
    main() 