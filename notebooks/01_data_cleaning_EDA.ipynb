{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee8dd08",
   "metadata": {},
   "source": [
    "# 01 Data Cleaning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f507f2",
   "metadata": {},
   "source": [
    "Phase 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd054b0d",
   "metadata": {},
   "source": [
    "Phase 1\t\n",
    "\t1.\tCompute within / between variance of ND-GAIN at annual frequency (total, between, within, share within). Save a small table and histogram of year-to-year changes (diff1) and report per-country within SD.\n",
    "\t2.\tCount how many countries and how many country-years show substantive ND-GAIN change; identify outliers (big diffs).\n",
    "\t3.\tCompute per-country summary (mean, SD, number of years). Produce a short paragraph interpreting whether FE is likely to be feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c492d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18880091",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82931855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance decomposition of ND-GAIN (annual):\n",
      "  Total variance:   116.0202\n",
      "  Between variance: 114.1825\n",
      "  Within variance:  4.5763\n",
      "  Share within:     3.94%\n",
      "\n",
      "Number of country-years with substantive ND-GAIN change (>|0.98|): 178\n",
      "Number of countries with at least one substantive change: 57\n",
      "\n",
      "Top 5 outlier year-to-year changes in ND-GAIN:\n",
      "     iso3c  year  gain_diff1\n",
      "2228   BGD  2014  -11.062157\n",
      "2274   NGA  2014  -10.871986\n",
      "2256   IND  2014   -9.909187\n",
      "2278   PAK  2014   -8.339038\n",
      "2270   MEX  2014   -7.692216\n",
      "\n",
      "Interpretation:\n",
      "The variance decomposition shows that a substantial share of the total variance in ND-GAIN is due to between-country differences, with within-country (over time) variance being relatively smaller. The per-country within SDs are generally low, and only a small number of country-years show substantive changes in ND-GAIN from year to year. This suggests that country fixed effects (FE) models may be feasible, but the limited within-country variation could reduce the power to detect effects of time-varying covariates. Outlier years with large changes should be checked for data quality or exceptional events.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/Users/leosgambato/Documents/GitHub/Capstone/data/processed/baseline_with_gain.csv')\n",
    "\n",
    "# Clean up: drop rows where 'gain' is missing or iso3c is missing\n",
    "df = df.dropna(subset=['gain', 'iso3c','sovereign_spread'])\n",
    "\n",
    "# 1. Compute within / between variance of Gain at annual frequency\n",
    "\n",
    "# Compute overall mean\n",
    "overall_mean = df['gain'].mean()\n",
    "\n",
    "# Compute per-country mean\n",
    "country_means = df.groupby('iso3c')['gain'].mean()\n",
    "\n",
    "# Merge country means back to df\n",
    "df = df.merge(country_means.rename('country_mean'), left_on='iso3c', right_index=True)\n",
    "\n",
    "# Between variance: variance of country means\n",
    "between_var = country_means.var(ddof=0)\n",
    "\n",
    "# Within variance: mean of per-country variances\n",
    "within_var = df.groupby('iso3c')['gain'].var(ddof=0).mean()\n",
    "\n",
    "# Total variance\n",
    "total_var = df['gain'].var(ddof=0)\n",
    "\n",
    "# Share within\n",
    "share_within = within_var / total_var if total_var > 0 else np.nan\n",
    "\n",
    "print(\"Variance decomposition of ND-GAIN (annual):\")\n",
    "print(f\"  Total variance:   {total_var:.4f}\")\n",
    "print(f\"  Between variance: {between_var:.4f}\")\n",
    "print(f\"  Within variance:  {within_var:.4f}\")\n",
    "print(f\"  Share within:     {share_within:.2%}\")\n",
    "\n",
    "# 2. Histogram and table of year-to-year changes (diff1), per-country within SD\n",
    "\n",
    "# Sort for diff calculation\n",
    "df = df.sort_values(['iso3c', 'year'])\n",
    "\n",
    "# Compute year-to-year difference\n",
    "df['gain_diff1'] = df.groupby('iso3c')['gain'].diff()\n",
    "\n",
    "# Table of year-to-year changes (drop NA)\n",
    "diff1_table = df[['iso3c', 'year', 'gain_diff1']].dropna()\n",
    "\n",
    "# Save small table (first 10 rows as example)\n",
    "diff1_table.head(10).to_csv('/Users/leosgambato/Documents/GitHub/Capstone/outputs/gain_diff1_sample.csv', index=False)\n",
    "\n",
    "# Histogram of all year-to-year changes\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(diff1_table['gain_diff1'], bins=30, edgecolor='k')\n",
    "plt.title('Histogram of Year-to-Year Changes in ND-GAIN')\n",
    "plt.xlabel('Year-to-Year Change (diff1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/leosgambato/Documents/GitHub/Capstone/outputs/gain_diff1_hist.png')\n",
    "plt.close()\n",
    "\n",
    "# Per-country within SD\n",
    "country_within_sd = df.groupby('iso3c')['gain'].std().rename('within_sd')\n",
    "country_within_sd = country_within_sd.reset_index()\n",
    "country_within_sd.head(10).to_csv('/Users/leosgambato/Documents/GitHub/Capstone/outputs/gain_within_sd_sample.csv', index=False)\n",
    "\n",
    "# 2. Count countries and country-years with substantive ND-GAIN change; identify outliers\n",
    "\n",
    "# Define substantive change threshold (e.g., > 1 SD of all diffs)\n",
    "diff1_sd = diff1_table['gain_diff1'].std()\n",
    "substantive_thresh = diff1_sd\n",
    "\n",
    "# Count country-years with |diff1| > threshold\n",
    "substantive_changes = diff1_table[np.abs(diff1_table['gain_diff1']) > substantive_thresh]\n",
    "n_substantive = len(substantive_changes)\n",
    "n_countries = substantive_changes['iso3c'].nunique()\n",
    "\n",
    "print(f\"\\nNumber of country-years with substantive ND-GAIN change (>|{substantive_thresh:.2f}|): {n_substantive}\")\n",
    "print(f\"Number of countries with at least one substantive change: {n_countries}\")\n",
    "\n",
    "# Identify outliers (e.g., top 5 biggest absolute diffs)\n",
    "outliers = diff1_table.reindex(diff1_table['gain_diff1'].abs().sort_values(ascending=False).index).head(5)\n",
    "print(\"\\nTop 5 outlier year-to-year changes in ND-GAIN:\")\n",
    "print(outliers)\n",
    "\n",
    "# 3. Per-country summary (mean, SD, number of years)\n",
    "country_summary = df.groupby('iso3c').agg(\n",
    "    mean_gain=('gain', 'mean'),\n",
    "    sd_gain=('gain', 'std'),\n",
    "    n_years=('gain', 'count')\n",
    ").reset_index()\n",
    "\n",
    "country_summary.head(10).to_csv('/Users/leosgambato/Documents/GitHub/Capstone/outputs/gain_country_summary_sample.csv', index=False)\n",
    "\n",
    "# Short paragraph interpreting FE feasibility\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"The variance decomposition shows that a substantial share of the total variance in ND-GAIN is due to between-country differences, with within-country (over time) variance being relatively smaller. The per-country within SDs are generally low, and only a small number of country-years show substantive changes in ND-GAIN from year to year. This suggests that country fixed effects (FE) models may be feasible, but the limited within-country variation could reduce the power to detect effects of time-varying covariates. Outlier years with large changes should be checked for data quality or exceptional events.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889a28e",
   "metadata": {},
   "source": [
    "### Data cleaning, Exploratory analysis, creating lags etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc51f909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values summary:\n",
      "cpi_yoy                   267\n",
      "wgi_cc                    144\n",
      "wgi_ge                    144\n",
      "wgi_pv                    144\n",
      "wgi_rl                    144\n",
      "wgi_rq                    144\n",
      "wgi_va                    144\n",
      "gain_diff1                 67\n",
      "gdp_annual_growth_rate     66\n",
      "debt_to_gdp                11\n",
      "dtype: int64\n",
      "\n",
      "Dataset ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining missing values\n",
    "print(f\"\\nMissing values summary:\")\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "if len(missing_summary) > 0:\n",
    "    print(missing_summary)\n",
    "else:\n",
    "    print(\"No missing values in the dataset\")\n",
    "\n",
    "print(\"\\nDataset ready for analysis!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5efa82be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "965b1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure year is integer\n",
    "df['year'] = df['year'].astype(int)\n",
    "df = df.sort_values(['iso3c','year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ded51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transforms (avoid log(0) by replacing zeros with tiny positive number)\n",
    "df['ln_gdp_per_capita'] = np.log(df['gdp_per_capita'].replace(0, np.nan))\n",
    "df['ln_gross_gdp'] = np.log(df['gross gdp'].replace(0, np.nan))\n",
    "\n",
    "# If you prefer to drop the raw gross_gdp or gdp_per_capita from covariates, decide later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "388cb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lags(df, group='iso3c', time='year', variables=None, lags=(1,2)):\n",
    "    \"\"\"\n",
    "    Add lagged versions of `variables` grouped by `group` and sorted by `time`.\n",
    "    variables: list of column names\n",
    "    lags: tuple/list of lag integers e.g. (1,2)\n",
    "    \"\"\"\n",
    "    df = df.sort_values([group, time]).copy()\n",
    "    for var in variables:\n",
    "        for lag in lags:\n",
    "            new_col = f\"{var}_lag{lag}\"\n",
    "            df[new_col] = df.groupby(group)[var].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Variables we recommend lagging (one or two lags)\n",
    "vars_to_lag = [\n",
    "    'sovereign_spread',    # outcome lag Y_lag1\n",
    "    'cpi_yoy',\n",
    "    'gdp_annual_growth_rate',\n",
    "    'ln_gdp_per_capita',\n",
    "    'ln_gross_gdp',\n",
    "    'debt_to_gdp',\n",
    "    'deficit_to_gdp',\n",
    "    'current_account_balance',\n",
    "    # Add global factors if present (VIX, US10y, Brent)\n",
    "    # 'VIX', 'US10y', 'Brent'\n",
    "]\n",
    "\n",
    "# add lag1 and lag2 (you can restrict to only lag1 by passing lags=(1,))\n",
    "df = create_lags(df, group='iso3c', time='year', variables=vars_to_lag, lags=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "07643b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ND-GAIN is 'gain' column\n",
    "df = df.sort_values(['iso3c','year']).reset_index(drop=True)\n",
    "df['gain_diff1'] = df.groupby('iso3c')['gain'].diff(1)\n",
    "df['gain_diff3'] = df.groupby('iso3c')['gain'].diff(3)\n",
    "df['gain_diff5'] = df.groupby('iso3c')['gain'].diff(5)\n",
    "\n",
    "# outlier threshold (you used 0.91 earlier; keep parametric)\n",
    "OUTLIER_THRESHOLD = 0.91\n",
    "df['gain_substantive_change'] = df['gain_diff1'].abs() > OUTLIER_THRESHOLD\n",
    "\n",
    "# list top K absolute diffs for quick inspection\n",
    "def top_gain_changes(df, k=10):\n",
    "    tmp = df[['iso3c','year','gain_diff1']].dropna().assign(absdiff= df['gain_diff1'].abs())\n",
    "    return tmp.sort_values('absdiff', ascending=False).head(k)\n",
    "\n",
    "# winsorize function\n",
    "def winsorize_ser(s, lower_pct=0.01, upper_pct=0.99):\n",
    "    lo = s.quantile(lower_pct)\n",
    "    hi = s.quantile(upper_pct)\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "# Example: create winsorized diff for diagnostics (do not replace original unless you choose)\n",
    "df['gain_diff1_wins'] = winsorize_ser(df['gain_diff1'], 0.01, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4c1b2",
   "metadata": {},
   "source": [
    "#### 5) Imputation flags (per variable) — create columns marking missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45fc2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose list of candidate covariates we'll eventually impute (lagged and level vars)\n",
    "candidate_covs = [\n",
    "    # lagged covariates\n",
    "    'sovereign_spread_lag1', 'sovereign_spread_lag2',\n",
    "    'cpi_yoy_lag1', 'cpi_yoy_lag2',\n",
    "    'gdp_annual_growth_rate_lag1', 'gdp_annual_growth_rate_lag2',\n",
    "    'ln_gdp_per_capita_lag1', 'ln_gdp_per_capita_lag2',\n",
    "    'debt_to_gdp_lag1', 'debt_to_gdp_lag2',\n",
    "    'deficit_to_gdp_lag1', 'deficit_to_gdp_lag2',\n",
    "    'current_account_balance_lag1', 'current_account_balance_lag2',\n",
    "    # governance (we treat as slow-moving; missing flags still useful)\n",
    "    'wgi_cc','wgi_ge','wgi_pv','wgi_rl','wgi_rq','wgi_va',\n",
    "    # treatment (do not impute treatment for FE logic) — we still examine missingness\n",
    "    'gain'\n",
    "]\n",
    "\n",
    "# add flags\n",
    "for col in candidate_covs:\n",
    "    flag_col = col + '_impflag'\n",
    "    df[flag_col] = df[col].isna().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a2bd4",
   "metadata": {},
   "source": [
    "6) Build the baseline covariate lists to feed the DML nuisance learners\n",
    "\n",
    "We create (A) a baseline set (lagged core variables + WGI + lagged outcome), and (B) an extended set including additional candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b733f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline covariates for DML nuisance (lagged)\n",
    "baseline_covariates = [\n",
    "    'sovereign_spread_lag1',   # lagged outcome\n",
    "    'cpi_yoy_lag1',\n",
    "    'gdp_annual_growth_rate_lag1',\n",
    "    'ln_gdp_per_capita_lag1',\n",
    "    'debt_to_gdp_lag1',\n",
    "    'deficit_to_gdp_lag1',    # mediator caution — we use lag1\n",
    "    'current_account_balance_lag1',\n",
    "    # governance (level or lagged)\n",
    "    'wgi_cc', 'wgi_ge', 'wgi_pv', 'wgi_rl', 'wgi_rq', 'wgi_va',\n",
    "    # imputation flags for these\n",
    "    'sovereign_spread_lag1_impflag', 'cpi_yoy_lag1_impflag', 'gdp_annual_growth_rate_lag1_impflag',\n",
    "    'ln_gdp_per_capita_lag1_impflag', 'debt_to_gdp_lag1_impflag', 'deficit_to_gdp_lag1_impflag',\n",
    "    'current_account_balance_lag1_impflag'\n",
    "]\n",
    "\n",
    "# Extended covariates (if you have them) — add here\n",
    "extended_covariates = baseline_covariates + [\n",
    "    'sovereign_spread_lag2', 'cpi_yoy_lag2', 'gdp_annual_growth_rate_lag2', 'ln_gdp_per_capita_lag2',\n",
    "    'debt_to_gdp_lag2', 'deficit_to_gdp_lag2', 'current_account_balance_lag2',\n",
    "    # placeholder for global factors you might add:\n",
    "    # 'VIX_lag1', 'US10y_lag1', 'Brent_lag1',\n",
    "]\n",
    "\n",
    "# The treatment is 'gain' (do not include it in covariates)\n",
    "T_col = 'gain'\n",
    "Y_col = 'sovereign_spread'\n",
    "idcol = 'iso3c'\n",
    "timecol = 'year'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d88250",
   "metadata": {},
   "source": [
    "7) Fold-aware preprocessing function (impute on train only, scale on train only, optional FE partial-out)\n",
    "\n",
    "This is the core function to call inside your cross-fitting loop. It returns processed X_train, X_test, y_train, y_test, t_train, t_test and optionally the FE means and saved imputer/scaler objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0adce219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def fold_aware_preprocess(train_df, test_df, covariates,\n",
    "                          idcol='iso3c', ycol='sovereign_spread', tcol='gain',\n",
    "                          imputer=None, scaler=None, include_country_fe=False,\n",
    "                          save_prefix=None):\n",
    "    \"\"\"\n",
    "    - train_df/test_df are pandas DataFrames for the fold\n",
    "    - covariates: list of column names to use in X (these should include imputation flags)\n",
    "    - imputer: sklearn imputer instance (if None, uses KNNImputer(n_neighbors=5))\n",
    "    - scaler: sklearn scaler instance (if None, uses StandardScaler())\n",
    "    - include_country_fe: if True, compute country means on train and demean Y, T, and covariates (fe partial-out)\n",
    "    - save_prefix: optional path prefix to pickle imputer/scaler/fe_means\n",
    "    Returns: dict with processed arrays/dataframes and saved artifacts paths\n",
    "    \"\"\"\n",
    "    if imputer is None:\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "    # 1) Impute covariates using training only\n",
    "    Xtrain_raw = train_df[covariates].copy()\n",
    "    Xtest_raw  = test_df[covariates].copy()\n",
    "    Xtrain_imp = pd.DataFrame(imputer.fit_transform(Xtrain_raw), columns=covariates, index=train_df.index)\n",
    "    Xtest_imp  = pd.DataFrame(imputer.transform(Xtest_raw), columns=covariates, index=test_df.index)\n",
    "\n",
    "    # save imputer\n",
    "    artifacts = {}\n",
    "    if save_prefix is not None:\n",
    "        p_imputer = f\"{save_prefix}_imputer.pkl\"\n",
    "        pickle.dump(imputer, open(p_imputer, 'wb'))\n",
    "        artifacts['imputer'] = p_imputer\n",
    "\n",
    "    # 2) optional: demean by country using training-based country means (for FE partial-out)\n",
    "    # We'll compute FE means for y, t, and covariates based on train only\n",
    "    if include_country_fe:\n",
    "        cols_for_means = [ycol, tcol] + covariates\n",
    "        # assemble train with imputed covariates for mean calc\n",
    "        train_for_means = train_df[[ycol, tcol]].join(Xtrain_imp)\n",
    "        fe_means = train_for_means.groupby(idcol).mean()\n",
    "        # global train means for countries not in train (rare in LOYO, but safe)\n",
    "        global_means = train_for_means.mean()\n",
    "\n",
    "        # join means into train/test\n",
    "        train_joined = train_for_means.join(fe_means, on=idcol, rsuffix='_mean')\n",
    "        test_joined  = test_df[[ycol, tcol]].join(Xtest_imp).join(fe_means, on=idcol, rsuffix='_mean')\n",
    "\n",
    "        # demean\n",
    "        for col in [ycol, tcol] + covariates:\n",
    "            mean_col = col + '_mean'\n",
    "            train_joined[col + '_d'] = train_joined[col] - train_joined[mean_col].fillna(global_means[col])\n",
    "            test_joined[col + '_d']  = test_joined[col]  - test_joined[mean_col].fillna(global_means[col])\n",
    "\n",
    "        # X matrices for ML are demeaned covariates\n",
    "        X_train = train_joined[[c + '_d' for c in covariates]].copy()\n",
    "        X_test  = test_joined[[c + '_d' for c in covariates]].copy()\n",
    "        y_train = train_joined[ycol + '_d'].copy()\n",
    "        y_test  = test_joined[ycol + '_d'].copy()\n",
    "        t_train = train_joined[tcol + '_d'].copy()\n",
    "        t_test  = test_joined[tcol + '_d'].copy()\n",
    "\n",
    "        # persist fe_means if requested\n",
    "        if save_prefix is not None:\n",
    "            p_femeans = f\"{save_prefix}_fe_means.pkl\"\n",
    "            pickle.dump(fe_means, open(p_femeans, 'wb'))\n",
    "            artifacts['fe_means'] = p_femeans\n",
    "\n",
    "    else:\n",
    "        # no FE partial-out: use imputed X directly\n",
    "        X_train = Xtrain_imp.copy()\n",
    "        X_test  = Xtest_imp.copy()\n",
    "        y_train = train_df[ycol].copy()\n",
    "        y_test  = test_df[ycol].copy()\n",
    "        t_train = train_df[tcol].copy()\n",
    "        t_test  = test_df[tcol].copy()\n",
    "\n",
    "    # 3) scale features using training-only scaler\n",
    "    X_train_cols = X_train.columns.tolist()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train_cols, index=X_train.index)\n",
    "    X_test_scaled  = pd.DataFrame(scaler.transform(X_test),  columns=X_train_cols, index=X_test.index)  # align columns\n",
    "\n",
    "    if save_prefix is not None:\n",
    "        p_scaler = f\"{save_prefix}_scaler.pkl\"\n",
    "        pickle.dump(scaler, open(p_scaler, 'wb'))\n",
    "        artifacts['scaler'] = p_scaler\n",
    "\n",
    "    out = {\n",
    "        'X_train': X_train_scaled, 'X_test': X_test_scaled,\n",
    "        'y_train': y_train, 'y_test': y_test,\n",
    "        't_train': t_train, 't_test': t_test,\n",
    "        'artifacts': artifacts\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8286e7fd",
   "metadata": {},
   "source": [
    "8) Example: how to use the preprocessing function in a leave-one-year-out fold loop\n",
    "\n",
    "This snippet shows how to produce per-fold artifacts and store OOS p(X) R² for the demeaned T (helpful for FE diagnostic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c966b581",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'iso3c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m test  \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[test_idx]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     16\u001b[0m save_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifacts/fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# change path as you see fit\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[43mfold_aware_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariates_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                             \u001b[49m\u001b[43midcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miso3c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mycol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mimputer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKNNImputer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                             \u001b[49m\u001b[43minclude_country_fe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfe_include\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m prep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m'\u001b[39m], prep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m prep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m'\u001b[39m], prep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[77], line 40\u001b[0m, in \u001b[0;36mfold_aware_preprocess\u001b[0;34m(train_df, test_df, covariates, idcol, ycol, tcol, imputer, scaler, include_country_fe, save_prefix)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# assemble train with imputed covariates for mean calc\u001b[39;00m\n\u001b[1;32m     39\u001b[0m train_for_means \u001b[38;5;241m=\u001b[39m train_df[[ycol, tcol]]\u001b[38;5;241m.\u001b[39mjoin(Xtrain_imp)\n\u001b[0;32m---> 40\u001b[0m fe_means \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_for_means\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43midcol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# global train means for countries not in train (rare in LOYO, but safe)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m global_means \u001b[38;5;241m=\u001b[39m train_for_means\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'iso3c'"
     ]
    }
   ],
   "source": [
    "# Choose folds: leave-one-year-out\n",
    "years = sorted(df['year'].unique())\n",
    "folds = [(df.index[df['year'] != y].tolist(), df.index[df['year'] == y].tolist()) for y in years]\n",
    "\n",
    "# Which covariates to feed to preprocess (choose baseline or extended)\n",
    "covariates_to_use = baseline_covariates  # or extended_covariates\n",
    "\n",
    "p_oos_r2_list = []\n",
    "fe_include = True   # set True for FE-DML diagnostic; False for pooled spec\n",
    "all_theta_parts = []  # optionally store residuals\n",
    "\n",
    "for fnum, (train_idx, test_idx) in enumerate(folds):\n",
    "    train = df.loc[train_idx].copy()\n",
    "    test  = df.loc[test_idx].copy()\n",
    "\n",
    "    save_prefix = f\"artifacts/fold{fnum}\"  # change path as you see fit\n",
    "\n",
    "    prep = fold_aware_preprocess(train, test, covariates=covariates_to_use,\n",
    "                                 idcol='iso3c', ycol=Y_col, tcol=T_col,\n",
    "                                 imputer=KNNImputer(n_neighbors=5),\n",
    "                                 scaler=StandardScaler(),\n",
    "                                 include_country_fe=fe_include,\n",
    "                                 save_prefix=save_prefix)\n",
    "\n",
    "    X_train, X_test = prep['X_train'], prep['X_test']\n",
    "    y_train, y_test = prep['y_train'], prep['y_test']\n",
    "    t_train, t_test = prep['t_train'], prep['t_test']\n",
    "\n",
    "    # Fit p(X) on demeaned T (LassoCV)\n",
    "    p_model = LassoCV(cv=5, random_state=0).fit(X_train, t_train)\n",
    "    p_hat_test = p_model.predict(X_test)\n",
    "    # OOS R^2 for demeaned T\n",
    "    r2 = np.nan\n",
    "    if len(t_test)>0 and np.nanvar(t_test)>0:\n",
    "        r2 = r2_score(t_test, p_hat_test)\n",
    "    p_oos_r2_list.append(r2)\n",
    "\n",
    "    # Fit m(X) for demeaned Y (random forest)\n",
    "    m_model = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "    m_model.fit(X_train, y_train)\n",
    "    m_hat_test = m_model.predict(X_test)\n",
    "\n",
    "    # residuals for stacking later\n",
    "    u_hat = y_test.values - m_hat_test\n",
    "    v_hat = t_test.values - p_hat_test\n",
    "\n",
    "    # store in a dict or DataFrame for later stacking\n",
    "    tmp = pd.DataFrame({\n",
    "        'index': test.index,\n",
    "        'u_hat': u_hat,\n",
    "        'v_hat': v_hat\n",
    "    }).set_index('index')\n",
    "\n",
    "    all_theta_parts.append(tmp)\n",
    "\n",
    "# After loop: stack residuals and compute theta (example)\n",
    "stacked = pd.concat(all_theta_parts).sort_index()\n",
    "u_all = stacked['u_hat']\n",
    "v_all = stacked['v_hat']\n",
    "\n",
    "theta_hat = (v_all * u_all).sum() / (v_all**2).sum()\n",
    "print(\"Theta (DML-style point estimate from residuals):\", theta_hat)\n",
    "print(\"Median p(X) OOS R2 across folds:\", np.nanmedian(p_oos_r2_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572eed27",
   "metadata": {},
   "source": [
    "# Phase 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db2fb770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: imports and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# SETTINGS - EDIT THESE\n",
    "idcol = 'iso3c'\n",
    "timecol = 'year'\n",
    "Y_col = 'sovereign_spread'   # outcome\n",
    "T_col = 'gain'               # treatment (ND-GAIN)\n",
    "# Choose covariates prepared earlier (baseline from preprocessing)\n",
    "covariates_to_use = [\n",
    "    'sovereign_spread_lag1', 'cpi_yoy_lag1','gdp_annual_growth_rate_lag1',\n",
    "    'ln_gdp_per_capita_lag1','debt_to_gdp_lag1','deficit_to_gdp_lag1',\n",
    "    'current_account_balance_lag1',\n",
    "    'wgi_cc','wgi_ge','wgi_pv','wgi_rl','wgi_rq','wgi_va',\n",
    "    'sovereign_spread_lag1_impflag', 'cpi_yoy_lag1_impflag', 'gdp_annual_growth_rate_lag1_impflag',\n",
    "    'ln_gdp_per_capita_lag1_impflag','debt_to_gdp_lag1_impflag','deficit_to_gdp_lag1_impflag',\n",
    "    'current_account_balance_lag1_impflag'\n",
    "]\n",
    "\n",
    "# folds & artifacts\n",
    "fold_output_dir = \"artifacts/dml_pooled\"\n",
    "os.makedirs(fold_output_dir, exist_ok=True)\n",
    "\n",
    "# modeling choices\n",
    "n_trees = 300\n",
    "use_xgboost = False   # set True if xgboost is installed and you want to use it\n",
    "n_permutations = 200  # for permutation test (200 is reasonable; increase if you have time)\n",
    "random_seed = 2025\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7425c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: fold-aware preprocess helper (compact)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def fold_aware_preprocess(train_df, test_df, covariates,\n",
    "                          idcol='iso3c', ycol='sovereign_spread', tcol='gain',\n",
    "                          imputer=None, scaler=None, include_country_fe=False,\n",
    "                          save_prefix=None):\n",
    "    if imputer is None:\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "    # Impute on training only\n",
    "    Xtrain_raw = train_df[covariates]\n",
    "    Xtest_raw  = test_df[covariates]\n",
    "    Xtrain_imp = pd.DataFrame(imputer.fit_transform(Xtrain_raw), columns=covariates, index=train_df.index)\n",
    "    Xtest_imp  = pd.DataFrame(imputer.transform(Xtest_raw), columns=covariates, index=test_df.index)\n",
    "\n",
    "    artifacts = {}\n",
    "    if save_prefix is not None:\n",
    "        p_imputer = f\"{save_prefix}_imputer.pkl\"\n",
    "        pickle.dump(imputer, open(p_imputer, 'wb'))\n",
    "        artifacts['imputer'] = p_imputer\n",
    "\n",
    "    if include_country_fe:\n",
    "        cols_for_means = [ycol, tcol] + covariates\n",
    "        train_for_means = train_df[[ycol, tcol]].join(Xtrain_imp)\n",
    "        fe_means = train_for_means.groupby(idcol).mean()\n",
    "        global_means = train_for_means.mean()\n",
    "\n",
    "        train_joined = train_for_means.join(fe_means, on=idcol, rsuffix='_mean')\n",
    "        test_joined  = test_df[[ycol, tcol]].join(Xtest_imp).join(fe_means, on=idcol, rsuffix='_mean')\n",
    "\n",
    "        for col in [ycol, tcol] + covariates:\n",
    "            mean_col = col + '_mean'\n",
    "            train_joined[col + '_d'] = train_joined[col] - train_joined[mean_col].fillna(global_means[col])\n",
    "            test_joined[col + '_d']  = test_joined[col]  - test_joined[mean_col].fillna(global_means[col])\n",
    "\n",
    "        X_train = train_joined[[c + '_d' for c in covariates]].copy()\n",
    "        X_test  = test_joined[[c + '_d' for c in covariates]].copy()\n",
    "        y_train = train_joined[ycol + '_d'].copy()\n",
    "        y_test  = test_joined[ycol + '_d'].copy()\n",
    "        t_train = train_joined[tcol + '_d'].copy()\n",
    "        t_test  = test_joined[tcol + '_d'].copy()\n",
    "\n",
    "        if save_prefix is not None:\n",
    "            p_femeans = f\"{save_prefix}_fe_means.pkl\"\n",
    "            pickle.dump(fe_means, open(p_femeans, 'wb'))\n",
    "            artifacts['fe_means'] = p_femeans\n",
    "\n",
    "    else:\n",
    "        X_train = Xtrain_imp.copy()\n",
    "        X_test  = Xtest_imp.copy()\n",
    "        y_train = train_df[ycol].copy()\n",
    "        y_test  = test_df[ycol].copy()\n",
    "        t_train = train_df[tcol].copy()\n",
    "        t_test  = test_df[tcol].copy()\n",
    "\n",
    "    # scale features using training-only scaler\n",
    "    X_train_cols = X_train.columns.tolist()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train_cols, index=X_train.index)\n",
    "    X_test_scaled  = pd.DataFrame(scaler.transform(X_test),  columns=X_train_cols, index=X_test.index)\n",
    "\n",
    "    if save_prefix is not None:\n",
    "        p_scaler = f\"{save_prefix}_scaler.pkl\"\n",
    "        pickle.dump(scaler, open(p_scaler, 'wb'))\n",
    "        artifacts['scaler'] = p_scaler\n",
    "\n",
    "    out = {\n",
    "        'X_train': X_train_scaled, 'X_test': X_test_scaled,\n",
    "        'y_train': y_train, 'y_test': y_test,\n",
    "        't_train': t_train, 't_test': t_test,\n",
    "        'artifacts': artifacts\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21336211",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# save per-fold models if desired\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(p_model, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pmodel.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 70\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(m_model, \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msave_prefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_mmodel.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     71\u001b[0m     per_fold_artifacts\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m: fnum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_imputer\u001b[39m\u001b[38;5;124m'\u001b[39m: prep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martifacts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_scaler\u001b[39m\u001b[38;5;124m'\u001b[39m: prep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martifacts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m)})\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Stack residuals\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CELL 3: pooled annual DML (leave-one-year-out) with year FE\n",
    "years = sorted(df[timecol].unique())\n",
    "folds = [(df.index[df[timecol] != y].tolist(), df.index[df[timecol] == y].tolist()) for y in years]\n",
    "\n",
    "u_list = []\n",
    "v_list = []\n",
    "p_oos_r2_folds = []\n",
    "m_oos_r2_folds = []\n",
    "per_fold_artifacts = []\n",
    "\n",
    "for fnum, (train_idx, test_idx) in enumerate(folds):\n",
    "    train = df.loc[train_idx].copy()\n",
    "    test  = df.loc[test_idx].copy()\n",
    "    save_prefix = os.path.join(fold_output_dir, f\"fold{fnum}\")\n",
    "\n",
    "    # preprocess (no FE partial-out for pooled spec)\n",
    "    prep = fold_aware_preprocess(train, test, covariates=covariates_to_use,\n",
    "                                 idcol=idcol, ycol=Y_col, tcol=T_col,\n",
    "                                 imputer=KNNImputer(n_neighbors=5),\n",
    "                                 scaler=StandardScaler(),\n",
    "                                 include_country_fe=False,\n",
    "                                 save_prefix=save_prefix)\n",
    "\n",
    "    X_train = prep['X_train']; X_test = prep['X_test']\n",
    "    y_train = prep['y_train']; y_test = prep['y_test']\n",
    "    t_train = prep['t_train']; t_test = prep['t_test']\n",
    "\n",
    "    # Add year dummies fitted on train\n",
    "    yrs_train = pd.get_dummies(train[timecol], prefix='yr')\n",
    "    yrs_test  = pd.get_dummies(test[timecol], prefix='yr').reindex(columns=yrs_train.columns, fill_value=0)\n",
    "    # Align indices\n",
    "    yrs_train.index = train.index\n",
    "    yrs_test.index = test.index\n",
    "\n",
    "    # append year dummies to X (train/test)\n",
    "    X_train_fe = pd.concat([X_train.reset_index(drop=True), yrs_train.reset_index(drop=True)], axis=1)\n",
    "    X_train_fe.index = X_train.index\n",
    "    X_test_fe  = pd.concat([X_test.reset_index(drop=True),  yrs_test.reset_index(drop=True)], axis=1)\n",
    "    X_test_fe.index = X_test.index\n",
    "    # ensure consistent columns\n",
    "    X_test_fe = X_test_fe.reindex(columns=X_train_fe.columns, fill_value=0)\n",
    "\n",
    "    # Fit p(X): predict T using LassoCV\n",
    "    p_model = LassoCV(cv=5, random_state=random_seed).fit(X_train_fe, t_train)\n",
    "    p_hat_test = p_model.predict(X_test_fe)\n",
    "    # OOS R2 for p(X)\n",
    "    r2_p = np.nan\n",
    "    if len(t_test)>0 and np.nanvar(t_test)>0:\n",
    "        r2_p = r2_score(t_test, p_hat_test)\n",
    "    p_oos_r2_folds.append(r2_p)\n",
    "\n",
    "    # Fit m(X): predict Y using RandomForest\n",
    "    m_model = RandomForestRegressor(n_estimators=n_trees, n_jobs=-1, random_state=random_seed).fit(X_train_fe, y_train)\n",
    "    m_hat_test = m_model.predict(X_test_fe)\n",
    "    # OOS R2 for m(X)\n",
    "    r2_m = np.nan\n",
    "    if len(y_test)>0 and np.nanvar(y_test)>0:\n",
    "        r2_m = r2_score(y_test, m_hat_test)\n",
    "    m_oos_r2_folds.append(r2_m)\n",
    "\n",
    "    # residuals for this fold\n",
    "    u_hat = y_test.values - m_hat_test\n",
    "    v_hat = t_test.values - p_hat_test\n",
    "\n",
    "    u_list.append(pd.Series(u_hat, index=test.index))\n",
    "    v_list.append(pd.Series(v_hat, index=test.index))\n",
    "\n",
    "    # save per-fold models if desired\n",
    "    pickle.dump(p_model, open(f\"{save_prefix}_pmodel.pkl\",'wb'))\n",
    "    pickle.dump(m_model, open(f\"{save_prefix}_mmodel.pkl\",'wb'))\n",
    "    per_fold_artifacts.append({'fold': fnum, 'p_imputer': prep['artifacts'].get('imputer'), 'p_scaler': prep['artifacts'].get('scaler')})\n",
    "\n",
    "# Stack residuals\n",
    "u_all = pd.concat(u_list).sort_index()\n",
    "v_all = pd.concat(v_list).sort_index()\n",
    "\n",
    "# Final DML estimate (residual-on-residual)\n",
    "theta_hat = (v_all * u_all).sum() / (v_all**2).sum()\n",
    "print(\"DML point estimate (theta):\", theta_hat)\n",
    "\n",
    "# OLS for clustered SE (u on v)\n",
    "res = sm.OLS(u_all.values, v_all.values).fit(cov_type='cluster', cov_kwds={'groups': df.loc[u_all.index, idcol]})\n",
    "print(res.summary())\n",
    "\n",
    "# Diagnostics\n",
    "print(\"Median p(X) OOS R^2:\", np.nanmedian(p_oos_r2_folds))\n",
    "print(\"Median m(X) OOS R^2:\", np.nanmedian(m_oos_r2_folds))\n",
    "# save results\n",
    "results = {\n",
    "    'theta': theta_hat,\n",
    "    'coef': res.params[0],\n",
    "    'se_cluster': res.bse[0],\n",
    "    'tstat': res.tvalues[0],\n",
    "    'pval': res.pvalues[0],\n",
    "    'median_p_oos_r2': np.nanmedian(p_oos_r2_folds),\n",
    "    'median_m_oos_r2': np.nanmedian(m_oos_r2_folds)\n",
    "}\n",
    "pd.Series(results).to_csv(os.path.join(fold_output_dir, 'pooled_dml_results_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "104c2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE(theta) = 0.287603; MDE (approx 80% power) = 0.805289\n",
      "Effective variance of residualised treatment (v): 28.876158120445485\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: MDE and effective within variance\n",
    "se_theta = res.bse[0]\n",
    "mde80 = (1.96 + 0.84) * se_theta\n",
    "print(f\"SE(theta) = {se_theta:.6f}; MDE (approx 80% power) = {mde80:.6f}\")\n",
    "\n",
    "# Effective within variance in demeaned T (for FE diagnostic, but we compute variance of v_all used)\n",
    "effective_within_var = np.var(v_all, ddof=1)\n",
    "print(\"Effective variance of residualised treatment (v):\", effective_within_var)\n",
    "\n",
    "# Save\n",
    "pd.Series({'se_theta': se_theta, 'mde80': mde80, 'effective_within_var': effective_within_var}).to_csv(os.path.join(fold_output_dir,'dml_inference_metrics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bba9d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining non-numeric columns: ['iso3c']\n",
      "OLS baseline beta: -0.2857027850116722 R2: 0.19721523203352676\n",
      "OLS full beta: -0.018163494197012783 R2: 0.6899069628115698\n",
      "DML theta: 0.3540514593305501\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAGMCAYAAACh0KjGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBCUlEQVR4nO3dB3iTVfs/8C+UUsree9NC2Zuy96iAgjIE5Ccowwm4ERcqCrwOVEBEQBmCInsv2aCA7F32KnuVven/+p73n75pm7RJm7Zp8v1cVyhNnjx5cvI0uXOfc+6TKiIiIgIiIiIi4pVSJ/cBiIiIiEjyUTAoIiIi4sUUDIqIiIh4MQWDIiIiIl5MwaCIiIiIF1MwKCIiIuLFFAyKiIiIeDEFgyIiIiJeTMGgSCJxl3ru7nIc7sTVbaI2Tnqe1uY6JyU5KRgU+f+2bt2KPn36oE6dOihfvjyaNGmCjz76CEeOHInXvnr37o3kdO7cOXMMp0+fdvg+77//Pho3bgxPUqpUKYwYMcL8//79+xg8eDDmz58f7+fMfXGfyfFa8zV97rnnzPlZq1Yt3Llzx+62YWFhGDhwoDmPuX3dunXx8ssvY/369TG2dbQNbt++bZ5/y5YtUaFCBVStWhWdOnXC9OnT4ww+/u///s9cEsrWa5hQS5cuRZcuXcz/N23aZF5f/rTVNtbnk6u48hxyxTnuiKNHj5p9Xr9+3aX7leShYFAEwJgxY8yHLD9cP/jgA/zyyy/mg3Pfvn14+umnsXDhQqf2xw/H+ASRrvTPP/9gzZo18HZ//vknOnToYP5/4cIFTJw4EQ8fPoy8/dVXX8XIkSMd3h/3xX0mx2vNY9+xYwf+85//mGP29/e3ud2GDRvw1FNPYfPmzejZs6c5n/nFJk2aNOjRo4cJFpzFYI9/E3zuDAB//vlnfPvttyhXrhw+/vhjDBkyBEnB1muYEJcvX8Znn32GDz/80PxetmxZ8xz5M6m48hxyxTnuiOLFi5svGl988YVL9yvJI00yPa6I21i1apX5UGNW8PXXX4+8vkaNGmjbti3efvtt8826ZMmSCAwMTNZjFedVqlQp1tsLFy7s1P7y5s1rLskhPDwcuXPnNpk5e86fP4++ffuiSpUq+PHHH+Hn5xd5W0hICCZMmGACN57LliDZ0ewVs2W//vqryZ5bNGzYEKlTp8bkyZPRq1cv5MqVCynJTz/9ZLKcluAvY8aMcZ4zKY2z57ijmM3k69+tW7ckDZ7F9ZQZFK/Hb8z8lvvaa6/FuM3X1xeff/45fHx8MHbs2Mjr//77b3Ts2BGVK1dG9erV8corr0R+s2fgOHv2bNM9yy6lWbNmmevv3buHr776Cg0aNDDZlCeffBKLFi2K8njsdmHWhm+u/ICyZCtsOXnypMnUBAcHo2LFinj22WcjM4F8zAEDBpj/89s7j4nZJO7zxo0bUfYzatQo091nr8uRWYtWrVqZY+YbP7vIHj16FGubxtY+FsuXL8czzzxjujAZXDDDwG5ICz5Os2bNsHr1atNWfPwWLVpgzpw5UfbDLAiDHO6nXr16+PTTT3Hz5s0Y3XrsNmVbENvG0m1m3YXGDBePJfrz+/LLL007P3jwIEo3sa3Xul27diZzFl337t3xwgsv2G0zvi4M0po2bWqeS+vWrTFjxozI23mM3P+ZM2di7apksMd2ZHtaB4LWx8Fgh0GQM+PKLl68aH4+fvw4xm3sYn3zzTeRKlWqOPfDALV27drm3GDG6tSpU1FuP3jwIF566SUTzPLCv0vLNvZeQ8t5yvOJz43neZs2bbB48eJYj+XKlSumjdnWFtG7iWPD14Pb8ris8bh4bsT3/YL74//Hjx9vzm3+fc+cOTPy74btzX3xb4K3T5kyJdb2cfYcj+t1sGDgX7NmTZMllpRNwaB4NX4Y7NmzB40aNbL7QZY1a1bz4bVixQrzO98Q+SHGN2J+oPJN9NixY+ZbMj8oeRsDPr5RsruJARQ/dPlmOnXqVBMQ8H58M+cHaPTghm/sDAYYpLVv397mMfFx+EbNAI4BJrflcfJD5sSJE+Yx+X9LsMtj4r4YkC5ZsiTKvubOnWsyTba6HPkmzw8Pjk8bPXq06UpnUMzr7ImrfYjjmdgeDMIZHDAjO2/ePHM/6wCFAQiD8eeff9505RcsWBD9+/eP/CBdsGABvv76a3Nc7ArlPvl8Bg0aFOO4mFGzdJWxbWx1mzGAuHTpUpRAgMfMoIIBMb8cWLP1WrOdt2/fbl4Hi7Nnz5p9Mlix5e7du+YDnu3Cbl1LgM4vA2x3y+to/Vj2snocE1i6dOlYs5dPPPGECT72798PRzFTnj59erz11lumzfl8eNxUtGhRkxXMmTNnnNlFDrn45JNPTLAaGhpqXltL8M7zhIE0u2755YXnDs+nzp07m+vsvYb8m+E+GUjznP3mm2+QNm1avPPOO2acpT3Lli0z3an8+08s8Xm/sGDAz3bl3zgDOH4x4jnOLBzPEd5eqFAh8zeyc+dOl53jcb0O1hiMrly5Erdu3Uq0NpTEp25i8WqWyRUFChSIdbsiRYqYYPDatWvYtWuX+RBkMJYnTx5zOz94eTszMuySyZ49u/kwsnQ3MTOwbt06fPfdd5FdfMxiMZjjBxczExzPRfnz5zcfYrHhGzIHcFs+SIjZEL75cwA5H9/SNcTAgEEUMQBlsGQJJLZt24bjx49j6NChNjNV/MBhxpHjzYiTEBh08ncGtba6zeNqnwwZMpjnzOfPnxYMKJi1YnbT8oHI9uEHEYNRyzb84OY2JUqUwL///mueG4NBdlVaAha+TtHx9WBbENumTJkyMbZhAMZzgUEmvwAQPzQZlPJDNDpbrzVfS7Yn25ndtcT/83kz02kLs0HMxPDLAl8jYvswUOFrwA9mHm/0x7KF2aH69esjrvPZcv7bagdbcuTIYb4IMMs0btw4c2HgwGPh+ERmRJlBjw1vZzezJVDllwEOxeAXoq5du0aOg2R2k921xNeeQR4fj18EbL2GDFQ4FpJ/DxZ8HRl8MwBlkGPLxo0bzXnE1yaxxOf9wpIhZ9DOdrXgeckxzNY9BjxfmNHjecoMoivOcUdeBwt+cWU2ccuWLZHvRZLyKBgUr2bJQkXP+ERn+ZDj9nzDZfcbM0D8VswPXr4ZMxizhwP6mXnkm6X1wG523TAjdujQocg3cctPC3bnWGfLGPQwAxMQEGAydMwEMUjjcVi6hu3hBwvvwyCAHwjsnipWrFhkAGKN2S1+iPEYox+zJcC1FQzG1T7M6jFbww9H6/2y+4wfPNyvdXbEOvCxBBGWD0t2UTGbwg99flCxfdml7Eh3pS28HwOb33//3XQ38wOamSwGoXxejsiUKROaN29uXldLMMh25peAdOnS2bwPg1q+HtFfBx4LuzGZ9XH0g5bniuWLhSPnszOqVatmsmkMsHje8bg5oYUTVRjQMdCz9xyJ3Y3WGUue68xs8f4MBhmcMaDnPiznBs8JPi4nRNlj6ZLlzFZ+SWJW1pL54pcjexhEWr4oJZb4vF9YRH8vYNaYmIVj9o5DRXbv3h3n83T2HHfmdbB8kY7eVS4pi4JB8WqWN7K4yq/wQ4PZA2bFeOFgeXZb8oN60qRJyJw5s+nme+ONN2wGIhz4zw9efhjamwFoeeNnZssas0nWx8fMADNP/OBlt9Nff/1lPogZ0DIg4szILFmy2HwcBiQck8hMFTMp7BqyV9KCx0z2bucx28IP19jax7JfHicvce3XuvuagbB1EMPnwy4ufrBZus34mjKzGtski9gwO8J2ZSaX2TkGPxzD6Qx+8DMYZLaEgRezr+xus4eZTFsTLyzdrs6U7+Dzd+R8tmShncXXgIE7L5ZjZ8b7jz/+MK83gzp7bHUjM+NoeX48NziONvpYWmL2zB4GRewm5pcu/h0w4xgUFBRnwMvuaXszsl0lrr+H2L64RH8v4LAWlgviuEHejxleBmjOBvZxnePOvA6W9rMepyspj4JB8Wr8IGLmiXXG+vXrFxlsWOObHLNV1oPVrbtkmSVhdopju/gBxK4dW9kivrHzgyC2bjtb+KZt/a0/W7Zs5ie7nPjNnh8OHHvFsYDsxuPtvM4WBrTMTjAI5OxoZthsdX8SP7CIXbnMGkQX2/iw2NqHGU167733TPYhOnuBrD3sluWF3drMVrEN3n33XdMdZumWcwYzpTx+thHPBwYqzKQ4g8+L3XR8TbgPBiexde3yOVuPMYw+acPymjuC5ym/KFiyv7bwuPLly+dwFzFZAnl2HUY/dgZiDBwOHz4c6z5sdd/zOVoyovw7YdelrYk29rKd/DLALywMAhls8UsVt+Wx8EtPbNiu0SdUOcMSyEWfVBN9/Jyz7xf28EsOM598DdhmzOpxKMW0adNceo478zpYAnlnzlFxP5pAIl6PkxfY5TJs2LAYt7GLloEVu0stXTR8I+a4Nb6x882YY2ksExY405OiB5UMDhh48ds7x9hYLhwnxgkUsdVM46xC6/sw08AuXL5ZczwSP5D4AcjJKAzw7B2DddaKj8tZuNyHvYCJXUb8gGWpEuvH54cB28pet1Bc7cPAiEE472+9Xx4HS/ywtqMzAYplFjg/wPjBynFjbE9bmcu4xrRZMEBm1oTdZ8zmsivTHlvtzNeEXdfM4HBwPbO5sWGWjcEbX1drzC7yNXCkS9GChZ3ZpcchA5YJHtaYRWX3Lrvp7Z0j9r6wsPuQ3cLRsa15fvP8iw0DIevgi93ffN7s7rf8nTCI4/lsOS848YLnFDPgtl7Dq1evmr9fnteW85PWrl1rd/azBTOjnNwTX5bxdNaTVDgMwpL9ju/7RWztxyEI7Gbmvmw9T1ec4468DhaW5x6fLLO4D2UGxeuxm4Rjjjhjj7MrOa6Os/IYrLDri9dxEoOl24kfXMyWMQhhlxjffDnwn2/OllmJzKpxxh4nOvANleO9+IHPQIUXDlpnIDd8+HDz+LF1gdnCjA7H8zC7xvqIzNJxLA+PlbMzLcdAfPPmOCU+JjFjxswAAwJ279nDb/oMgH/44QeTHeUHEAND/s5gx9Ie0cXVPvydgSuzSfw/r2N2gd283L8z9cr4WAzW2QXL58j9MAPDTKat42PASOxOZHvYGwfILmZ2xTPbZS/LahH9tea5QwwGLeVf7GVfLbgtgzS2GccZMuBnEMlyIvyyYnktHcHH52vE/XC/PB/4XJmVYyaIH/6ccMOZodb4GkfP+lk+5BmAvPjiiya4ZbaIXZw8H9hFyC8WzERy/Ki92dLRs3gsicQgjsE/A0hLVop/G5wsw0CVx8exdsyi8XH5t2LvNWQGlDOKOR6RbcUgx5KFj22VFs7QZZswQLXs1xlsA/4d8lxhzwIzgjxODiWxiM/7hT38UsAZ5/wb4XPlBDB2P/Pv0fI8XXGOO/I6WAeoPA8s3dWSQkWIiLF9+/aIN954I6J+/foR5cqVi2jUqFHERx99FHHo0KEY265bty6iU6dOEVWqVImoWLFixHPPPRfx77//Rt5+4MCBiJCQkIiyZctG/Pzzz+a6W7duRQwePNjsn9c3btw44ttvv424e/du5P34mP3793foeI8dOxbx+uuvR9SqVcvsr1WrVhFTp06NvP3mzZsR3bt3N7f16tUryn2HDBkSUb169Yh79+5FuZ6PzWOwNnny5IiWLVua/dSuXTvi7bffjjh9+nSsxxZX+9DChQsjnn76adPWNWrUiHj55ZcjQkNDI28fPnx4RMmSJWPsm9fxNotJkyaZ46tQoYLZT79+/SLCwsLsbs/nXqlSJfP879+/b/M500svvWSOLTw8PMr10Y/L1mttwecXve3tuXz5csQHH3wQUbNmTfO4Tz31VMT06dOjbGPvWG3ha/Tll19GNG/ePKJ8+fIRderUMW28du3aGNtyv3xOti7dunWL3O7GjRsRw4YNi2jdunVE5cqVzXG2aNHCXMfzLTZdu3aNeOuttyK++eYb0/a8P3/n87a2Z8+eiB49epjb+Tp17NgxYvny5VG2if4a7t+/3+yf1/Ec6NKli3mefF369u1r95j42HwOPBctNm7caJ43f9pq8+jn05o1a8xrxdefbT1v3ryIF198McrfsbPvF6dOnTKPM3PmzCjHy/Oa52XVqlXNpV27dhFz58417cX/u+ocd/R1oJ49e5q/OUnZUvGf5A5IRSTp8E+epTY4A5lL70niYJaTmR9mUjixR9wTu2w5m9/eeF6xj138nODGsZrOjD8V96NuYhEvYekGZCkKzibl2DJxPXbVs4YcJyWxu9p64pG4H3ZZ88sRh204MzZTYIYHcEKaAsGUTxNIRLwExzZxrBKDQZaXiW1ShMQfV3nhMmKcfMSJNs5M0pCkx5I+nJXPvwlxHCfKcFwrx/5KyqduYhEREREvpq+sIiIiIl5MwaCIiIiIF1MwKCIiIuLFNJs4iXBlAQ7P5GoCIiIiIontwYMHpii5ZclHe5QZTCIMBN19rg6Pj0smuftxuiO1XcKo/eJPbZcwar/4U9u5f/s5GnsoM5hELBlBrvHorri2KGukBQQEIH369Ml9OCmK2i5h1H7xp7ZLGLVf/Knt3L/9WErMEcoMioiIiHgxBYMiIiIiXkzBoIiIiIgXUzAoIiIi4sUUDIqIiIh4MQWDIiIiIl5MwaCIiIiIF0sRweDjx48xfPhw1KtXD5UqVUKvXr1w6tQpu9tfvXoVb7/9NqpXr44aNWrgs88+w507d6Jss3jxYrRs2RIVKlRA27ZtsWHDBqf3ISIiIpLSpYhgcNSoUfj9998xaNAgTJ061QSHPXv2NJW7benbty9OnDiBCRMm4IcffsCaNWvw6aefRt6+ceNGvPvuu+jUqRNmz56NWrVqoXfv3jhy5IjD+xARERHxBG4fDDLg+/XXX01w1rBhQwQFBeG7777DuXPnsGzZMptrAP/777/4z3/+g7Jly5pA7/PPP8fcuXNx/vx5s83YsWPRtGlTPP/88yhRogT69+9vtp04caLD+xARERHxBG6/HF1oaChu3bplAjKLzJkzo0yZMti8eTNat24dZfstW7YgV65cJsizYDcvF2reunUrQkJCsG3bNrz//vtR7hccHBwZXMa1D3YvxwfXB+TyM7akTp0a6dKli/zd3nbE4/D394/XtuzqtrdOYfRu8Ni2dWa/ZL3UjjPb3r1712SCXbEtj5fHTffu3cOjR49csq3162YvW229LV9ry7YPHz60u62fnx98fHyc3pYLk/NiT9q0aZEmTRqnt+Xjx/b8uOSiZdlFZ7Zl2/Ic5utn61zm4/M4LNvy9bDHelueC9ynK7Zl27KNiedubENGnNnWmb97e9vaarvEeo9IrG2T8z3Cuv0S8z3C0b/7lPQewTazft6J+R7h6N99SnyPuB2Pv3tHt+X+Ledpig4GmQGkfPnyRbk+d+7ckbdZY+Yu+rZ8MbNmzYqzZ8/i+vXrpoHy5s1rd39x7SO+OM7xiSeesHlbgwYNMG7cuMjfOZbR3snEwHTKlClRfucYR1u4FvKsWbMif2d29fTp0za3ZfDLrKvlcXmshw8ftrltgQIFsHr16sjfn3nmGbtrIGbLls1kWi2ee+65KL9Hf4PdtWtX5O8cDsAuensOHToU+f8+ffpgyZIldrfduXNn5AfDe++9Z4YI2MOhBDly5DD/5/AA6/aObtWqVZHbfvXVV5EZZlsWLVqEwMBA83+Ogx0xYoTdbWfOnGnOA0s2m/u2Z/LkyeYLjeX/HONqz5gxY9CoUaPIx4j+xcgaj9FyznKcLTP09gwdOhTt2rWLbBMOvbBn4MCB6Nq1q/n/pk2bIv9vC18rjhMmnhuWx7CF54DlGHluxPbFrUePHpHPPSwsLLJNbOE5axkmcvnyZdSsWdPutk8//XTka8X3mooVK9rdll9Orc8By7nhru8RXEOV54GF3iMcf48oWLBg5N/JL7/84jHvEWwnS+JE7xGfOvUewb9fBq6J+R7BYW6FCxdGig8GLW92lujcglH1tWvXbG4ffVvL9mx0S2Rva3+WbxNx7SMxMPvJBastYvuma1nc2iK2b6R8LtbbxvZt0PIt7fjx4+ZnbM+V+7Heb2zfgnh81tvG9s2Gz9t6W7ZLbKy3ZaAfmwMHDkR+a7J17ljjm8SFCxfM/+19iFrww/DGjRsOHcPRo0cjv71fvHgx1m35Oli+GVuOxR6Ob2XGnGx9SYr+pcTSbnF9ueEboGVb/j823Jdl29gmeFmO0bItjz02fO6WbS3npj1sU8u2J0+ejHXbK1euRG4b1/APngOWbeM6d3i7ZdvYMgmW88X6HHb39wi+J1hvq/cI598jeN550nuE5ThI7xH7nX6PiEtivUdElyoitly8G1i6dKmJ4vmNzTr92a9fPxO8/PTTT1G25yQTfjOYPn16lOvZzfzSSy+hTZs2JmLnNx9G0Rb8Vjds2DDTDRzXPrp37+708+A3Yr4w/LYcV9qYEittHFv3Cz+4eMIXLVrUfPt2pgvIld251tvG1f3izLaJ2QXEbfgmxNfX0r2S0ruAom+bmF1A4eHh5o2Z32CtzytP6AJydNu4/pbtbcv9R2+7xHqPSEg3sbu+R1i3X/bs2dVN7MR7BNuOAR4zg2wPdRP7OfV3z22OHTuGPHnyxHjfs7Xf+LxHMMvP84k9ACk6M2jprmXkb53q5O+lSpWKsT27f5cvXx7lOp5w/LBhVzC7evnmEP1bFH/nC+LIPuKLL0jOnDkd2tb6DSyptuWJw2CQJyW3S45jSKnbWt68+c3b0X0n1vGmRHwT498gu93ieq6ZMmVyeL8ZM2ZMlG0zZMiQKNvG55zg321cbZdS/o6SY1t77eeux+uKbV3F0naWz4zE5MzffUp6j0iVKpVD73vxPSccHdrm9rOJOXuYLwDHDFinTfft22dqAEbH65hetk4rW8aeVK1a1TR8lSpVYoxH4f6rVavm0D5EREREPIXbB4NM0XLg6DfffIMVK1aY2cVvvvmmyd41b97cpIQ5BsCSvuVATAZ73IZdvRzk+8knn5jC0pbM3wsvvICFCxdi/PjxprYgB3Kyn71bt24O70NERETEE7h9MEgcM9i+fXt89NFH6Ny5s+lS4mwsjidgCrRu3bpmBhYx8zdy5Egzc4vB3RtvvIH69etHKRjN7QcPHow//vjDzOphsDd69OjIGVGO7ENERETEE7j9mEFi8McVQ3iJjgEbZ4BZY/87p+THhlk+XuxxZB8iIiIiKV2KyAyKiIiISOJQMCgiIiLixRQMioiIiHgxBYMiIiIiXkzBoIiIiIgXUzAoIiIi4sUUDIqIiIh4MQWDIiIiIl5MwaCIiIiIF1MwKCIiIuLFFAyKiIiIeDEFgyIiIiJeTMGgiIiIiBdTMCgiIiLixRQMioiIiHixNMl9AOIajx5HYN/Ry7hy/S6yZ06HMsVzwCd1quQ+LBEREXFzCgY9wD+7zmDMnN24fO1u5HU5sqRD77blUbtC/mQ9NhEREXFv6ib2gEBwyMTNUQJB4u+8nreLiIiI2KNgMIV3DTMjGJuxc/eY7URERERsUTCYgnGMYPSMYHSXwu+Y7URERERsUTCYgnGyiCu3ExEREe+jYDAF46xhR2TO4JvoxyIiIiIpk4LBFIzlYzhrOC4//LkDSzYcx8NHj5PkuERERCTlUDCYgrGOIMvHxCajv68ZV/jjjJ14eegKrNh8Eo8UFIqIiMj/p2AwhWMdwQHdqsfIEObM6m+unzCwBXq2KYesGf1w/sptfD91O177eiXWbAvDY80yFhER8Xopouj0vXv3MHToUCxZsgR3795F48aN8eGHHyJ79ux27xMWFoZBgwZh8+bNSJ8+Pdq3b48+ffrAx8fH3M79/Pjjj1i4cCGuXr2KYsWK4bXXXkOTJk0i9/HRRx9h+vTpUfZboEABrFy5Eu4WEAaXy2d3BZI29UugRXARLPz7GGauOozTF2/hmylbMW3FQTzXIgi1yudDqlRarURERMQbpYhg8NNPP8WWLVswYsQIpE2bFgMHDkTfvn0xefJkm9s/ePAAPXr0QNGiRTF16lScPHnSBI+pU6c296MvvvgC69evx2effWa2Y1D4+uuvY8KECQgODjbbHDhwAC+//DK6du0auW9LMOluGPiVD8hp9/Z0fmnQrnEgnqhdFPPXHcXs1Ydx8twNU5i6eIEseC4kCGWLZErSYxYREZHk5/bB4Pnz5zFnzhyMHj0a1apVM9cNGzYMISEh2L59OypXrhzjPkuXLsWZM2cwbdo0ZMmSBSVLlsTly5fx1VdfmeDu0aNHZp+DBw9GgwYNzH1effVVbNq0CTNnzjTBYEREBA4fPozevXsjV65c8BTp0/ni2Wal0KpOMcxZcwTz1h3B0dPXMOiXTQgomAU1A30RFKTuYxEREW8R7zGDt2/fxpEjR7Bz506TeWNXbmLYunWr+VmzZs3I69ilmydPHtMFbAuziGXLljWBoAXvf/PmTezfv990iTK4rF+/fpT7MXN4/fp1838+Jz7H4sWLwxNlTJ8WXZ8ojbEfNEO7RgFI6+uDw2HXMHnVJXz6yxbsPnIpuQ9RRERE3C0zeP/+fcyYMQPz58/H7t27TYbNuvuUmbsnnngCTz/9tOnOdVVmMFu2bPDz84tyfe7cuXHu3Dmb9+H1efPmjbE9nT17FhUrVkTdunWj3L5r1y5s3LjRjBOkgwcPmp+//fYb1q5dawJFBo9vvvkmMmXynO7ULBn90L11WbRpUAJTl+7H0k0nEXoiHB+M+hsVA3Oia0hpBBX939hMLm1nb2yiiIiIeHAwOGvWLHz77bcmA9ioUSMT9HEyBSdnXLt2zQRg27ZtM124I0eONGPzOnToEOd+OdHDetJGdP369bMZWDI4tJeN5OSQzJkzx9iebN3n6NGjZvJIhQoV0LFjx8hgkAEgg0hmEZkpZDfzoUOHMHHiRHObs9j1zGyjO/LzATo2KoygPA+w4ySwZuc57Dx0CTsPrUOlwBx4tkkALobfwYRFB3Dl+v/aMHtmP3RvWQrBZfPAm925cyfKT3GO2i/+1HYJo/aLP7Wd+7cf4w5HJog6FAy+9NJLuHjxIj755BMTCNrL+nXv3t1kDxctWoTx48dj2bJlGDt2bKz7Zncvt7dnzZo1Zp/RMajz9/e3eZ906dLFuI8lCGTwao0BLMcLMpPIoM/X97+rdbzyyivo0qWLyUoSxx1y7CCDRWZFmV10Fie2sJvanWVO74P6QUCFQnmwZs917Dh6GzsOXTYXWxgYDpu6Cx3r5UCZQrZfD29y/Pjx5D6EFE3tF39qu4RR+8Wf2s6928+RnlqHgsHmzZujXbt2Dj9o27Zt0aZNG9OlHBcGXyVKlLB7O2f0hoeHm+DO+glduHDBBJK2MLCzdPNab0/W92Gw+s4775jAbtSoUVG6f5n5swSCFoGBgeYns6DxCQb5XAMCAuCu+O2EJyVnVzPQrlUNOHf5NqavPIL1u2x3yVus2HUTTzetjNRe2mUcve3EOWq/+FPbJYzaL/7Udu7ffpwI6wiHgkFHA0F6+PAh0qRJY9KSjnQTx6Vq1ap4/PixmUhSq1Ytc92xY8fMWMLq1avbvA+v52xhThjJmDGjuY7jATNkyICgoCDzO2sFcvwfu6i/+eabGJHze++9ZwJIlpqxYEaQ4hvQsU2iZybdEU9Ky3EWT58eLesgzmDw8rV7OHbuTqzlbbyBdduJ89R+8ae2Sxi1X/yp7dy3/RytIez0wDdOsLDXv80uUGcCR0cwk9eqVSvzuCz9wokeb731FmrUqIFKlSqZbZg1ZDe2pWu4adOmpkv3jTfeQGhoKJYvX27GMr744osm6OMYx/79+5sZx6w/yN95f16YhaQWLVpgw4YNZvwjxwuyu/qDDz5A69atY81keiJOFnHldiIiIuI+nA4GOZOY3cAMyiw4q5hBEzOBN27ccPUxmpVEmBVkUWgWk2a5l+HDh0feznqDnB3Mn5bJIuPGjTMZRY7xY2Fpjv/j2EDi7GCWkGFZHM4Q5n0tF65SQswYfv/991ixYgWefPJJEzSyu5y1Cb0NZw07Yu2OMFy+poHEIiIiKUmqCE41cQJrC7ILlWP5OMmCE0oYKHGMHlfqYDZOYwdisnQxly9fHu6KM52Z3S1dunSUlDXLyfT4YhkuX4s78+ebJjWeqFUU7RsHIpuDQaQnsNd24hi1X/yp7RJG7Rd/ajv3bz9HYw+nM4PsIuXKHszScdIFu4XZPcs1fAcMGKBA0AOxjmDvtrGfSF1aBKFs8Rx48PAx5q07ip6Dl2P8/L24djNxipGLiIhIMq5AwjF0nJDB7mGOzWOtwHXr1kUpQi2epXaF/BjQrTpyZIma7cuZ1d9c37l5KQx5tQ4+710LpQpnw/0HjzBr9WH0GvwXJi/ej5t3HiTbsYuIiIgL1ybm2MAxY8Yga9as+Pnnn1G7dm2MGDHCjOFjvUCO72PxZvHMgDC4XD67K5Bw1lLlUrlRqWQubN5/HlOWhJp1j/9cfhAL1h9F24YBeKpecbM+soiIiKTQzCCDwZCQECxYsAANGjQwtfM4u/ePP/4wRZU7d+6cOEcqboGBH8vHNKhS0Py0tRQdg8IaZfLi+zcbmKxh4byZcOvuQxMc9vzyL8xYeQh37z1MluMXERGRBGYGOU6wcePGMa5nNpC1/X744QdndykeikGhJZu4fsdp/LEsFKcv3sLEhfswd80RtG8SaCabpPX1Se5DFRER8VpOB4OWQJClWXbs2GFKyXClDgaDLPD87rvvJsZxSgrG7CEziXUr5sfqbWH4Y9kBnL9yG+Pm7sGsVYfRsWlJNA8uDN80PlFmMNvrjhYREZFkDAaJYwaZIeR6v5bKNCzmzDWMX3vtNRcenngSH5/UaFK9sAkMV2w+ial/HcSl8DsYPWsXZq46hE7NSqFxtUL4d+85jJmzO0opG05c4YxmZhpFREQkGYPBmTNnmtU82rdvj6eeego5c+Y0K3fMnTvXjCfMnz8/nn76aRceoniaND6p0aJmURP4Ld14AtNXHMTFq3cwYtoO/LZoP8JtlKNhYDhk4mYzBlEBoYiISDIGg1yrl5NEBg4cGHkdVwQJDg5GunTpMGnSJAWD4hB2C7euWxzNgotg8T/HTFBoKxC0NnbuHjMGUV3GIiIiyTSb+MSJE2btX1u4hNvRo0ddcVziRfx8fdC2QQDe7Fw1zm3ZrcyxhCIiIpJMwWCePHlw5swZm7ex+DQnkYjExy0HC1NzUomIiIgkUzDI2cQsH7Nr164o1+/cudMUn7ZVdkbEEZw17Igr1+9ETlwSERGRJB4z2KdPH/zzzz949tlnUaBAATOB5NKlSzh9+rRZt/jtt99O4CGJt2L5GM4atp5FbMuv8/fh333n0TWktFkPWURERJIwM8hu4BkzZuDjjz9G+fLlkT59evOTv/N6LlMnEh+cFMLyMbGpGpTbzEbec+Qy3v9xPT7++R8cOHElyY5RREQE3p4Z7NGjB3r27IkuXbqYi4grsWwMy8dErzOYM6s/erUpZ25nGZppKw7ir00nsOPgRXOpVjoPngsJQkBBfRkRERFJ1GBw27ZtZpkxkcRiWcLO3gokubL547X2FdGuUQCm/nUAq7acwpb9582lVvl8eK5FEIrky5zcT0NERMQzg8F69eph3rx5qFq1Knx9fRPnqMTrMfArH5Az1m3y5siANzpVQYcmJfHH0gNYuyMMG3afxcY9Z1GvYgF0blEKBXNnSrJjFhER8Ypg0M/PzwSDixcvNhNGOGbQGrOGEydOdOUxisSqQK6MeKdrVXRoGmiCwr93ncHaHaexfudpNKxaCJ2blzKBo4iIiLggGDx37hwqV64c+Xv0Eh8q+SHJpUjezHi/W3UcPX0NU5aE4t9957Byyyms2RaGpjUKo2PTksidLeqXl0ePI+x2R4uIiHgDp4PB3377LXGORMRFihfIgo97BOPgyasmKNx24IJZA3nF5lMIqVkEHZqWNIHfP7vOxJiowtI2nNGs9Y9FRMRbOB0MWhw7dgybN29GeHi4qTXItYlZd1DEXZQsnA2f9a6FvUcv4/elodh1+BIW/H0MyzadQKWSuUytwugYGA6ZuNnMaFZAKCIi3sDpYPD+/ft4//33zZhB6y7h1KlTm0LUn3zyiWYbi1thYeovX6mDnYcumkzh/uNXbAaC1sbO3WNmNKvLWEREPJ3TweA333yDFStWmICwRYsWyJ49Oy5fvowlS5bg+++/R968efHSSy8lztGKJEDFwFyoEJATM1cdwsSF+2Pd9lL4HTOWMK4ZzSIiIl4XDC5cuBBvvvkmunXrFnldvnz58MILL+Dhw4f4448/FAyK22LWOlfWqJNI7OGkEhEREU/n9HJ0t2/fRvHixW3eVrp0aVy9etUVxyWSaDh5xBEZ06uOpoiIeD6ng0F2DU+ePBmPHz+OcdvcuXPRqFEjVx2bSKJg+RjOGo7L939sw/x1R/Hg4aMkOS4REZEUEQyWL18eO3bsQOvWrfHTTz9h5syZGDduHDp37my6kPPkyYORI0eay48//uiSg7x37x4+++wz1KpVy9Q4fPvtt3HlypVY7xMWFma6q6tUqYK6deua8YyPHv3vQ53/r1ChAkqVKhXlMmLECIf3ISkTJ4WwfExsMmdIi/Cb903pmd6Dl2PxhuN48DDmFyARERGvGzM4aNAg8/P69ev44YcfYtw+fvz4KOOzXnvttYQeIz799FNs2bLFBGpp06bFwIED0bdvX5OhtOXBgwfo0aMHihYtiqlTp+LkyZP48MMPzYxn3o+OHz9ugkxmM3PkyBF5X8uKKo7sQ1Iulo1h+ZjodQZzZvVHrzblUL1MXiz/9wT+XH4Ql67dxagZOzFj5SF0blYKjaoWhI+P09+jREREPCMYDA0NRVI6f/485syZg9GjR6NatWrmumHDhiEkJATbt2+PshqKxdKlS3HmzBlMmzYNWbJkQcmSJc2M56+++govv/yyCSgPHDiAjBkzIigoyObjOrIPSfkBIcvH2FuB5InaxdCkemEs2Xgc01ccwoUrt/HDn9sxY+VBdGoehHqVCqj0jIiIpHgJSm8wu7Zz507TnZpYtm7dan7WrFkz8rpixYqZ7mgWvbaFWcSyZcuaIM6C97958yb27/9vSREGg1xb2R5H9iEpH4M5lo9pUKWg+Rk9uEvr64On6pXA2A+a4oXWZZApfVqcvngL307Zij7frDLrID9+rCUYRUTEy1YgYbfpqFGjcPHixcjr8ufPb8bytWzZ0uWZwWzZssHPzy/K9blz5zbrJNvC61nvMPr2dPbsWVSsWBEHDx40pXDYFcxsJ4NLlstp06aNw/twFot0cza2u7pz506UnxJVSHABNKiUB4s3nMSCv0/g1PkbGDpxM4rmzYQ29Qoia5oItV086dyLP7Vdwqj94k9t5/7tx7jDkYVAnA4GWUeQkzmaNGmC5s2bm/F2ly5dMkWnGQyy+7Rp06YO749ZRe7Lnn79+tnskmVwyDF/tty9exeZM2eOsT1Z7nPo0CEzI5rj/xj0rVmzBgMGDDBjBdu3b+/QPpzFfaeErCIzvmJf6TxA0da5sSH0BjaG3sTxczfww/T9KJDDF43K30OJfH5ahSeedO7Fn9ouYdR+8ae2c+/2c2RYm9PB4IQJE9ClSxez7Jy1tm3bmus4g9iZYJAZuUWLFtm9nUEal8CLjgGZv7+/zfukS5cuxn0sAZxlgsiCBQvMzOAMGTKY3zl2kGMEf/nlFxMMOrIPZ/n6+iIgIADuit9OeFJy0oy9tpX/qVIReP72fcxffwKLN57E6csPMHn1JZQqnBXPNi2BssWyR27LruT9J64i/MY9ZM3kh9JFsiG1xhtG0rkXf2q7hFH7xZ/azv3b7/Dhww5t53QwyO5Te5k81iDk7FxnA6TYxu5xbF94eLgJzKyj2wsXLphA0hZm+tgNbI3bk+U+DPai4ySRefPmObwPZzFbFN9AMinxpEwJx+kO2E4922ZFy9qFMX7ONmw9chsHTobj81+3mqXvuoaUxtUbd2PMWmadQ5a34SQW+R+de/GntksYtV/8qe3ct/0c7aWKV53BdevW2byNs3tZq8+VqlatarpzLRNJ6NixY2YsYfXq1W3eh9fv27fPTPaw2Lhxo8kCMgPIsjg1atTArFmzotxv9+7dCAwMdGgfItayZvRDSNWsGP5mHbSsXRRpfFJh1+FLeG/kOgyZuDlKIEj8ndf/s+tMsh2ziIhIvILBV155BbNnz8bHH39sZtyeOnUKu3btwnfffYcxY8bgmWeeMbN8LZeEYhauVatW+Oijj7Bp0ybzWG+99ZYJ5ipVqmS2YdaQk1ks3brsps6VKxfeeOMNMzlk+fLlphzNiy++aLKLHAvImcE8ZnZDM03LY2dWsE+fPg7tQ8QWlqd5pV1F/Px+UzSrUTjO7cfO3YNHmo0sIiLJyOluYs6+penTp2PGjBlRZqwQJ5dYfmd60hUTJljoevDgwXj99dfN7/Xr1zfBoXVG8vnnn8ekSZMQHBxsJnpwVRQeS8eOHU15GI5zfPXVVyPvw/2xiDULWLN+ILuqhw8fjnr16pnbHdmHiD25s6dHo6qF8Ne/J2Pd7lL4HVPnkGVtREREUkQwyIArqbEv/YsvvjAXWxgAcmyhtSJFiuDXX3+1u08WnObsYV7siWsfIrFhIWtXbiciIuIWwSC7Z0XEsS5jR6zccgpBRbMjT3YNwBYRkRRSdJrj9jh+j2P0LN3DloLKnOjBJdxEvB2XtuOs4eiTR6LbduACXh66HM1qFEHHpiXN+sgiIiJuGwxOmTLFdNdagkBrqVOnRt26dV11bCIpGpe2Y/kYzhq25/knSptZxzsOXcTiDcexfPNJhNQqig6NA5HNwcyiiIhIks4mnjx5spnAwcwgZ9ZycsWOHTvwww8/mEkXTz31VIIOSMSTsI7ggG7VTYbQGrN/vL5D05IY9HJtDH61DsoWz4EHDx9j/rqj6Dl4OcbP34trN+O32o2IiEiiZQa5fNz7779vZteWK1fOrDjCAs4sOH306FEzwaR169bO7lbEowPC4HL5zKxhThbhWEJ2ITNzaFG+RE4MebUOdhy8iClLQnHg5FXMWn0Yizccw5P1SuDpBiWQMb1KGomIiBsEg1wxxLJ6B2fbnjhxwqy5y+tZIHr8+PGJcJgiKRsDv7jKx7AUU+VSuVGpZC5s2X8ek5eE4ujpa5i2/CAWrj+Ktg0D8FS94kifzjfJjltERDyf093EpUuXxqpVq8z/ixUrZlYH2blzZ+RSdSKSMAwKq5fJi+/fbIAPuldHkbyZcOvuQ5Mx7PnlX5ix8hDu3nuY3IcpIiLemhl84YUXTPFnLunGws1cp/i9995D8+bNMX/+fJMdFBHXBIW1yudHcNl8WL/zNH5fegCnL97ExIX7MHfNEbRrHIgnaheFn69P5H24mkls3dEiIiIJDga5TNvo0aNx5MgR8/vnn3+Ot99+G1OnTjXrFn/yySfO7lJEYpE6dSrUr1wQdSrkx5rtYfhj2QGcu3wbv8zbg9mrD5tyNM2DC2PzvvMYM2d3lFI2nLjCGc0ctygiIuKyOoMNGzY0F8qWLZtW6RBJAj4+qdG4WmETGK7YfBJT/zpolrMbPWsXfl8aiuu3/rs2tzUGhixtw5nLCghFRCTeYwZZNoYFpp3BAtTfffedU/cRkbil8UmNFjWLYsyAJnj56fLIlimtzUDQ2ti5e0wXsoiISLyCQY4P5JjACRMm4MKFC7Fue/HiRYwaNcqUmuH9RCRx+KbxQau6xdGvU5U4t2UGkWMJRURE4tVN/PHHH5uxgkOHDsVXX32FihUrokKFCihYsCD8/f1x48YNnD171ixFd+DAAZQoUcJMLqlXr54juxeRBLh5+4FD23FSiYiISLzHDNaqVQtz587F6tWrzazhBQsW4PLl/2UacubMaZai40zjRo0aObpbEUkgzhp2xMWrt80ykpylLCIiEu8JJNaTR+7cuWOyglmzZkXatFodQSQ5sHwMZw1bzyK2ZeKi/di49xy6hgShYmAuBYUiIhK/otPW2EWcO3duBYIiyYh1BFk+JjY1yuZFWl8fHDhxFR//vAEDRv2NPUcuJdkxioiIh5WWERH3wrIxLB8Tvc5gzqz+6NWmnLmdYwanrziIJRtOYO/RyyYg5NJ3zBSWKpI9WY9fRESSj4JBEQ/BgC+4XD67K5Dw95eeroBnGgZi2oqD+GvTCew4eNFcqpXOg+dCghBQMGtyPw0REUliCgZFPAgDv/IBOWPdJlc2f7zWviLaNQrAn38dxMotJ7Fl/3lzqVU+H7q0CELRfJmT7JhFRCR5KRgU8VJ5c2RAv06V0b5JIP5YegBrd4Rhw+6z2LjnLOpVLIDOLUqhYO5MyX2YIiLirsEgy8pwVRKWqqDHjx+b2cVbtmxB586dXXmMIpKICuTKiHe6VkWHpv8NCv/edQZrd5zG+p2n0bBqIXRqVgr5cmaI3J4rmdjrihYRES8IBkNDQ/HOO+/gyJEjNm9nuQoFgyIpT5G8mfF+t+o4evqaWet4095zWLnlFNZsC0OT6oXxbLOSOHwqPMYkFZa14WxmrX0sIuIlwSBXILl27Rr69++PVatWmbIyLDK9du1ac5k0aVLiHKmIJIniBbLgoxeDcfDkVUxZEoptBy5g2aYTWL75JB7bWN+YgeGQiZvNbGYFhCIiXlBncOfOnejXrx+6d++Oli1bmq7hLl26YPTo0WbJut9++y1xjlREklTJwtnwWe9a+M/rdVG+RA6bgaC1sXP3mC5kERHx8GCQ4wSLFi1q/s+f7Da2eOaZZ7Bjxw7XHqGIJKsyxXKgc/OgOLe7FH7HjCUUEREPDwbz58+PU6dORQaDN2/eRFhYmPmdXcbsQna1e/fu4bPPPjPrI1euXBlvv/02rly5Eut9eEwvvfQSqlSpYtZM/v777/Ho0aPI20qVKmXzEhT0vw+9efPm2dzG8nxFvAUni7hyOxERScFjBps3b45vv/0W6dOnR4sWLVC8eHETaPXq1Qu//vorChUq5PKD/PTTT80s5REjRpiAc+DAgejbty8mT55sc/sHDx6gR48eJlidOnUqTp48iQ8//BCpU6c298uXLx/Wr18f5T7c5oUXXkDPnj0jrztw4ABq1KiBYcOGRdk2e3at1iDehbOGHbHz0EWz9J2/n6pWiYikFE6/Y7/++us4ceIEZsyYYYLBAQMGmOsWLlwIHx+fGIFTQp0/fx5z5swxYxKrVatmruNjhISEYPv27SZTGN3SpUtx5swZTJs2DVmyZEHJkiVNKRxOfnn55ZdNQJkrV67I7VkW55VXXjH76tOnT+T1Bw8eNJlA621FvBHLx3DWsPUsYlv++vekmYXcrlEgWtYpinRpFRSKiLg7p9+p/fz8MHz4cJN9o3r16mHBggXYs2cPypYti8KFC7v0ALdu3Wp+1qxZM/K6YsWKIU+ePNi8ebPNYJBZRB4LA0EL3p9d2vv370fFihWjbD99+nQT+LFbmKVxrDODjRs3dunzEUmJWEeQ5WM4a9iep+oVw+b9F3D20i2MX7AXc9YcNgWtQ2oWRVpfnyQ9XhERScQxg8wEcsygr69v5HXsGn7iiSfw8OFDk3lzdWYwW7ZsJgi1ljt3bpw7d87mfXh93rx5Y2xPZ8+ejTEhht3PnTp1ipwYQxz7yMdmYPnkk0+acYevvvoqjh075sJnJ5JysGwMy8cwQ2gtZ1Z/c32vthXw03uN0e/ZSsidPT2u3riHsXP24KUhy7F4w3E8ePg42Y5dREQSmBlkl6sFu2xZQoZdwtGxzuA///wDZ3AyRpMmTezezjI27NaNjsEhJ5bYcvfuXWTOHHVtVUswGf0+ixYtMoGf9VhBOnTokPnJFVaGDBli9vnTTz+ZMjrz589Hzpyxr/9qC/d1+/ZtuCuWCbL+KY7zlrarFJAVI9+qi/0nriL8xj1kzeSH0kWyIXXqVJHndu1yuVAjKAdWbT+DWauP4tK1uxg1YyemLz+Ado2Ko37FfPDxSe2V7ZcY1HYJo/aLP7Wd+7cf4w7rHs8EBYOcyctAz4JjBO09aJ06dZw5TtPdy4DMnjVr1pjsXXQM6vz9/W3eJ126dDHuYwkCOfHF2uzZs00waskcWnB84oYNG0xW0tKQI0eORMOGDTFr1iz07t0bzmLXOrup3d3x48eT+xBSLG9pO4Zy2dk5cJfDKc7b3KZgRuCVJ3Ji6+GbWLf3Bi6G38Xo2fswbflBNCyXGeWK+Jsg0hvbLzGo7RJG7Rd/ajv3bj9bCbV4BYOff/65yfgx2Pvggw/MZIvoYwM5U5fZuODgYKcOkt3NJUqUsHs7x+2Fh4eb4M76CV24cMEEkrawi5hjAK1xe7K+D/fLcYfsJrYl+qxhBp8FCxY03cfxwecaEBAAd8VvJzwp2V1uL9AW29R29lUoB3Rp+QjL/j2FueuO48qNB5i14Qr+PZwBHRqXQI0yuXHv3l21Xzzp3EsYtV/8qe3cv/0OHz7s0HYOBYMMoJ5++mnzf2bJGjRokGTlVapWrWpm+3IiCesMEsftMSCrXr26zfvwenZnc8JIxowZzXUbN25EhgwZotQR5GxkBrjWk1Ms/vzzTzNrmUvuWbKJ3B9fuPbt28frubDtomcm3RFPypRwnO5IbWcbm+TZ5mXwZP1ALFh/DLNWH0bYxVv47s9dKJY/M9o3LIb0ERFR2o+rmbCINWsXsrQNZzRzIovYpnMvYdR+8ae2c9/2c6SLOF6ziS1BIbtvmS28ePEi3nzzTdP9yRm8BQoUgCsxEG3VqhU++ugjDB482DQa6wyy/l+lSpXMNswactwfZw8ze8gxjax9+MYbb+Cdd94x4xIZ2L344otRsov79u0zk18YJEZXv359fPPNN3jvvffMuEWOGeQ+GARzpRURcV76dL7o2LQkWtYphrlrjmDu2iM4duY6vv59J/Jn90U339yoVaEQNuw+izFzdkcpZcOJK5zRrPWPRUSSeTYx05oMqri6x8yZM7F48WJcv34df/zxhwmSLBMvXGnQoEEmK8ixiiwmzULXLG9jneHjbF/+tEwWGTdunMkoduzY0Yx55MQPzga2xkA2a9asNh+ThaknTJhgBsV37tzZrMWcKVMmTJo0KcbMZhFxTkZ/XzwXEoRxHzZD+8aB8PNNjTNXHmDIpO145T8rTQmb6DUN+Tuv/2fX/ya0iYhIwqWKYD+pE7788ktTj++HH34wkyzKlStngkIWZuaMXI4l5EQLiWr37t3mZ/ny5eGuGPgyw1u6dGml/J2ktkuYMxeuYvycbdhy+BYePor9LYmlbBhEqsv4v3TuJYzaL/7Udu7ffo7GHk5nBpkJfOutt8w4O+u+aM7G5cQSS5FoERFHZc3oh5CqWdGnfbk4t70UfseMJRQREddwOhhkl7C9cYEcs+fOdfRExL1x0ogjOKlERESSKRgMDAw0RZdtWblypbldRCQ+WMTaEQ8ePkr0YxER8RZOzyZmVzAncrBGX6NGjUxXMWv1sRDz1KlT8e233ybOkYqIx+NqJpw1HH3ySHQ//LkDOw9dQufmpZA/13/LR4mISBJlBlm25euvvzbFoD/99FNTp2/o0KFYsmSJ+T0kJCSehyIi3o4rkrB8TGxKFv5vBYDV28Lwylcr8cPU7Th/RcNTRESSLDNITz75pLkcPXrUZAi58gjLvXAVEhGRhGAdwQHdqseoM8hZxL3alDO3Hw4Lx5Qlodiy/zyWbz6JVVtPoXlwEVPDkNuJiEgiB4OWJU7YPcwJJSzEzNp7LOAsIpJQDPiCy+WzuwJJQMGsGNizJkJPXDFB4Y6DF7F4w3ETGIbUKooOjQORLXO65H4aIiKeGQxyJY53330Xy5cvN13EFswKcpk2dhUrQygiCcXAr3xAzli3CSqSHYNeqo09Ry5h8pJQ7D16GfPXHcXSjSfQqk4xtGsUgCwZVSReRMSlwSCXaFu3bh0GDBiA5s2bm6zgpUuXsGDBAowYMcIUn+7Tp4+zuxURibdyJXJiyKt1sPPQRRMUHjhxFbNXH8aSDcfwZL0SeLpBCWRM/7+lKEVEJAHB4KJFi8xaxM8//3zkdfnz50fv3r3N/3/77TcFgyKS5FjZoFLJ3KgYmAtbQy9g8pL9OBJ2DdOWH8TC9UfRpkEA2tQvbtZHFhGRBASDXJuYk0VsqVChAm7evOnsLkVEXBoUViudB1WDcmPjnnOYsmQ/Tpy7gd+XhmL+uiN4plEgWtcphnR+aSILXdsbmygi4g3SxKe0DOsJ1qtXL8Zt7CquX7++q45NRCRBQWGt8vkQXDYv/t55Br8vC0XYhZuYuHAf5q45gnZmkokfxs/fG2XWMuscsrwNJ7GIiHgDh4LBkSNHRv4/Z86cpiu4bdu2aNGihfn92rVrWLNmDfbs2YPXXnstMY9XRMTp2oX1KhdA7Yr5sWZbGKYuO4Czl2/hl3l7bG7PwHDIxM2mvI0CQhHxBk4HgxahoaHmEh1XIOnZs6drjk5ExEXY9du4WiHUr1wAy/89iZ9m7kRsSyGPnbvHlLdRl7GIeDqHgkFbQZ+ISEqUxic1CuTKGGsgSJfC75ixhHGVtxERSelUEFBEvA4nizji8rU7iX4sIiLJTcGgiHgdzhp2BGsWbth9JkqBfRERT6NgUES8DsvHcNZwbDhS8PyV2xg8YTPe/H4NNu87p6BQRDySgkER8TqcFMLyMbF5o1NldGxaEv5+PqZ49ee/bMK7I9Zh+4ELCgpFxKMoGBQRr8SyMSwfEz1DmDOrv7m+cfXC+L8nSmPsB83wTMMApPX1McvcfTJmAwaM+tushywi4pVFp0VEPCkgZPmY2FYgyZLRDy88WRZtG5TAjJWHsHjDcew9etkEhJUCc+G5J4IQVCR7sj4PEZFEDwaDgoJMNX9H7d+/PyHHJCKSZBj4OVI+JlvmdOjVtjyebhiAaSsO4q9NJ7Dj0EVz4fJ3z7UIQkChrElyzCIiSR4MclURSzB47949jB8/HkWLFjUrkOTKlQvh4eFYuXIlDh48iFdeecWlBygi4k7Yjfxqu4po1ygQf/51ACu2nMKW/efNhcvfdWkRhKL5Mif3YYqIuDYY7NOnT+T/P/jgAzRs2BAjRoyIki18+eWX8e6772Lv3r2OP7qISAqVJ3t69H22Mto3DsQffx0wS91t2H0WG/ecRd2KBdC5eSkUypMpcvtHjyNi7Y4WEUkxYwYXL16M4cOH2+w2btOmTZTAUUTE0+XPlRFvd6mKjk1K4veloVi/8wzW7TiNv3eeRsOqhdCpWSkcO3MNY+bsNuseW3DiCmc0a/1jEUlxwWCGDBlw8uRJm7ft27cPWbJkccVxiYikKMwC9n++OjqeuYYpS0Kxae85rNxyCqu2noKtSjQMDIdM3GxmLisgFJEUVVqmVatWGDZsGKZNm4YLFy7gwYMHOHfuHCZMmIAff/wR7du3d/lBcpziZ599hlq1aqFy5cp4++23ceXKFYfv+9RTT2HWrFkxbpsyZQqaNGmCChUqoEuXLiaYtRYWFoaXXnoJVapUQd26dfH999/j0aNHLnteIuJ5iuXPgo9eDMawN+qjSqlcNgNBa2Pn7jFdyCIiKSYzyEDs7Nmz+OSTT6J0FbMIa8eOHc1kE1f79NNPsWXLFjNOMW3atBg4cCD69u2LyZMnx3q/Gzdu4I033sCBAwdi3DZ79mx89dVXGDRoEMqUKYMxY8bghRdeMN3g2bNnN0Fujx49zESZqVOnmmzohx9+iNSpU5vHFhGJTWChbGjfuCS2HbgY63aXwu+YsYSOzGgWEXGLYJDBGMcMHjp0yARo169fR7Zs2VCzZk0ULlzY5Qd4/vx5zJkzB6NHj0a1atXMdcxMhoSEYPv27SZTaAtnNzPQ47HZwv117drVZA1p8ODBaNq0KaZPn26ygUuXLsWZM2dMBpRd3yVLlsTly5dNAMnJMmwHEZHYcLKIK7cTEXGrFUgCAwPRunVrE0C1bdsWBQoUQGLYunWr+clg06JYsWLIkycPNm/ebPd+y5cvR6dOnUxWLzoGdcePHzfdzhZp0qQxwaZlnwx0y5YtG2UMJI/h5s2bqqMoIg7hrGFHbA09j5t3HiT68YiIuGwFkk2bNuGbb77Bnj17TFcxs2ljx45F3rx58f7778PVmUFm9/z8/KJcnzt3bjNW0R5m+uyx3C9fvnwx9hkaGhq5DZ9P9NuJ3eQVK1Z0+rmwK/327dtwV3fu3InyUxyntksYT22/Ynn9kT2zH65cvxfrdqu2huHfvefQuk4RPFGrMPz9HH9r9tS2Sypqv/hT27l/+zHucGTREKeDwQ0bNqBXr16me/add94xQaFllRJ2HzNjx7F3juIkDU7isKdfv342u2QZHHJySHxYGj76fq33effuXWTOHLVwrCUgje/jchxiSsgqMmsq8aO2SxhPbL+mFTNi2jr77xm1gzLi0Nm7uHjtIf5ccQTz1x9DndKZUL1kBqRNk9qr2y4pqf3iT23n3u3nyLA2p4NBzqhl8PbDDz/g4cOH+Prrr831HEfHrBezhM4EgwweFy1aZPf2NWvW4P79+zGuZ0Dm7++P+EiX7r9dN9H3a71PbmPrdkqfPn28HtfX1xcBAQFwVwySeVJy0kx829Zbqe0SxpPbr3RpoGCB85iw6ECUDGGOLH7o9kQpBJfNg8ePI/DP7nOYseoozl6+jb92XMO/h+/g6frF0KRaAaT19fHKtksKar/4U9u5f/sdPnzYoe2cDgaZ2bLMGI6eeqxTpw4mTpzodIBUokQJu7dzJjCXu2NgZh3dsqwNA8n4sHQPcx/Wj229T3YRc3k9a7yd4vu4bK/4BpJJiSdlSjhOd6S2SxhPbb9G1YuhftWisa5A0rxWCTSpUcx0GU/96wDOX7ltAsgFf59Ax6Yl0bRGEfjGkin01LZLKmq/+FPbuW/7OdJFHK8JJJkyZcLFi7ZLJXAsHW93papVq+Lx48eRE0no2LFjZixh9erV47XPHDlymEkoHPtowSwnJ41Y9smfrDvICSMWGzduNEW32SUuIuIMBn4sH9OgSkHz09ZSdD4+qdG0RmH81L8JXmtfETmzpMOla3cxauYuvDx0Of7adAKPHj1OluMXEc/ldDDILuLvvvsOu3fvjhJ5csIFy7Vw3WJXYhaOha4/+ugjE7zt2rULb731FmrUqIFKlSqZbZg1ZIBqqzvZnhdffBHjx4839QaZRuWayxwnaCmazVnSuXLlMnUKOamEs5NZ0ob3U1kZEUlMzACG1CqKnwc0NUvWZcvkhwtX72D4tB149auVWL31lApVi0jyFp3euXOnKTCdM+d/i6QyOGMwyO5X/t/VWC+Qs4Nff/1183v9+vVNcGjBeoPPP/88Jk2ahODgYIf2yeNnUWqOgWQ3dLly5UxwyILTlski48aNMyufcFuWmOEqJa+++qrLn5+IiC0cK/hkveJoFlwYi/85jhkrD+HMpVv49vdtmLbiILq0CEKlElmj3IdBYmzd0SIi0aWK4LxjJzEDx0LQ7DZlIMWuYWbqnnnmGQ0itcOSSS1fvjzcFScAcUxo6dKlNf7DSWq7hFH7OebOvYdYsP4oZq06HFmXsEjejKhV0g9tm1bGziPXMGbObrPusUWOLOlMdlHrH9umcy/+1Hbu336Oxh5OZwZZlJnLtzFbxos1rkbClT/YrSsiIq7F+oMdmpREy9rFMHftEXM5ce6muaza8zfOX4lZr4yB4ZCJmzGgW3UFhCLimjGD7I49cuSIzds44WLAgAHO7lJERJyQwd/XdBGP+7AZ2tYvijQ+sBkIWhs7d4/GGYpI/DOD/fv3NzOFib3Kn376KTJmzBhjO9bLsYwjFBGRxJUpfVp0bhaItBHXMW3dlVi3vRR+x4wl5ExmERGnM4MtWrQwQaD18ELL75ZL6tSpzezeIUOGOLJLERFxkUePHNuOk0pEROKVGWzcuLG50P/93/+ZzGBshaJFRCTpZPR3bMTP3fsPE/1YRMQLxgz+9ttvMQLBPXv2YNmyZWYCiYiIJK0iufyQPfN/106PzcjpOzF04macPKf3ahFJQDDIJdmYHRw1apT5ffLkyejQoQP69u2L5s2b49ChQ87uUkREEiB16lTo3rJUrNuUKZYdXJnq711n8Po3q/DN5K04ffF/KyyJiPdyOhj8+uuvzXJwrFnDZeK46kjt2rVN3cGAgAB8++23iXOkIiJiV3DZPKZ8DOsKWsuZ1d9c/5/X62HE241Qq3w+cPj3mu1hZjWT76duw7nLt5LtuEUk+TldZ3D9+vVm6bZ69eqZtXwvXbqEL7/80qzX27NnT7zzzjuJc6QiIhIr1hEMLpfP7gokRfJlxgfda+BIWDimLA3F5n3nsWLzKazeGoZmwUXQsUlJ5MqmhQNEvE2a+FTMzps3r/n/2rVrzTq9NWvWNL/z//FY0ERERFyEgV9c5WNKFMyKT3rUxIETVzBlSSi2H7yIJRuOY/m/JxFSq4gpbM1AUkS8g9PdxEWLFjUZwQcPHmDp0qVmGTqu40vz5s0zt4uIiPsrVSQ7Pn+pNoa+VhflSuTAw0ePsWD9MfQavBy/zt+LazfvJfchiog7BoO9evXCyJEjUatWLZw6dQovvPCCub59+/YmGOzRo0diHKeIiCSSssVzYPArdfDFS7URVCQb7j94hNmrD6Pnl39h0qJ9uHH7fnIfooi4Uzdx69atkS9fPmzdutVkBVlomqpXr25mFNevXz8xjlNERBJRqlSpULFkLlQIzImtoRcwZcl+HA67hukrDmHh38fQtn4JPFW/hFkKj7i0nb2xiSLi4cEgVa1a1VyiL1knIiIpPyisVjoPqgblxqa958yYwuNnr+P3ZQcwb91RPNMoALmy+mPCwn24fO1/K5pwFnPvtuXNJBYR8fBgkF3EcXn99dfjezwiIuImQWHNcvlQo0xeU5vw96WhCLtwE5MW7be5PQPDIRM3mzI2CghFvDgYzJgxI3Lnzq1gUETEgwpa16tUwAR4q7eewvBpO/D4sf2qEWPn7jHlbdRlLOLBwWBoaKjNcjOcYcw1iz/++GNXHZuIiLgJBne5s6WPNRCkS+F3zFjCuMrbiEgKnk1sS/r06c3Ekddeew1fffWVK3YpIiJuhpNFHMGAUES8LBi0yJ8/P44cOeLKXYqIiJtwtBA1y9Gs2RYWZxZRRDwoGOSqI2fPnsW4ceNQoEABV+xSRETcDMvHRF/7OLpUqYBL1+7imylb0ffbVfhn1xmtTCXiaWMGuQYxZ5nZwj94dROLiHjuuEGWj+GsYXve7FwFF67cNkWrT5y7YbYtXiALngsJQvXSeex+fohICgoGOS7Q1h8zZxI3bNhQy9GJiHgwzipm+Zgxc3ZHqTOYM6s/erUpF1lWplWdYpiz5gjmrTuCo6evYdAvm1CqcDZ0CQlC5ZK5FBSKpORgsE+fPolzJCIikiIw4GP5mNhWIMmYPi26PlEaT9YrbrKE89cfw4GTVzFwzAaz/B0zheVLaMaxSIoJBufMmYMGDRogW7Zs5v9x8ff3R5EiRUyXsoiIeB4Gfo6Uj8mS0Q/dW5dFmwYlMGPlISz+5zj2Hr2MD0b9jYqBOdE1pDSCimZPkmMWkQQEg++//z6mTZtmgkH+3xHsAujWrZvD24uIiOfKlikderUpj2caBmDa8oNYtukEdh66hJ2H1pnl755rEYSAQlmT+zBFvJJDweCKFSuQK1euyP/H5d69e5g4cSJmz56tYFBERCLlyOKPV9pVRLtGgZj61wGs2HIKW/afN5ea5fKiS4sgFMufJXL7R48jYu2OFpEkCgaty8U4WjqmWbNm2LVrF1yBweXQoUOxZMkS3L17F40bN8aHH36I7NmzO3TfDh06oHv37njmmWcir+d+fvzxRyxcuBBXr15FsWLFzOSYJk2aRG7z0UcfYfr06VH2x+e/cuVKlzwvERFvlTt7evR9tjLaNwnE1GUHTF3CjXvOmUvdivlNUHjq/I0YE1VY2oYzmrX+sUgSB4OxrUdsC9cmrlu3rrm4Ape543J3I0aMQNq0aTFw4ED07dsXkydPjvV+N27cwBtvvIEDBw7EuO2LL77A+vXr8dlnn5kZ0AwKedwTJkxAcHCw2Yb3e/nll9G1a9fI+/n4+LjkOYmICJA/Z0a81aUqOjQpid+XhmL9zjPm8vfOM7BVnZCBIcvVcEazAkKRZAwGOR6QNQUZGHEc4bVr1/DgwQP4+voiS5YsJqhylfPnz5tJK6NHj0a1atXMdcOGDUNISAi2b9+OypUr27wfs3eDBg0yxxfdnTt3zD4HDx5sJsbQq6++ik2bNmHmzJkmGOTzO3z4MHr37h3ZRS4iIomjUJ5M6P98dXQ8cw1TluzHpr3nY91+7Nw9ZkazuoxFkmgFktDQ0MjL+PHjkTVrVhOQsRuY2bXdu3djzJgx5voBAwbAlbZu3Wp+1qxZM/I6dunmyZMHmzfbL3y6fPlydOrUCVOnTo1xG4NZBpdcT9la6tSpcf36dfP/kydP4vbt2yhevLgLn42IiMSG4wXb1A9waP1jjiUUkWSoM/j555+bLtqWLVtGuZ6BVb9+/fDdd9+hVatWcGVmkNk9Pz+/KNfnzp0b586ds3s/Zv3sSZcuXYwubAa2GzduNOME6eDBg+bnb7/9hrVr15pAkc/xzTffRKZMmeL1XJhtZIDprpgxtf4pjlPbJYzaL/48se3OXbrm8HYl8qdP0GN5YvslFbWd+7cf4w5HCrw7HQxyDWJ7k0hy5MiBy5ed+6YWFhYWZdJGdAwwOU4wOgaHnBziCkePHjWTRypUqICOHTtGBoMMABl0MovITCGX2jt06JCZKc3bnMWu9P3798PdHT9+PLkPIcVS2yWM2i/+PKntrl3534SR2KzcdBjpHl9Ger+Ej+X2pPZLamo7924/WzGUS9YmnjJlCurUqRNlMgUDs3HjxpmAyhns7l20aJHd29esWYP79+/HuJ6Px+LWCbVt2zYzXjBv3rwm6OO4R3rllVfQpUuXyDGHJUuWNGMHGSyyW7xixYpOPxb3HRAQd/dHcuG3E56UnFDjirb1Jmq7hFH7xZ8ntl2pUhGYv3kdrlyP/Qv/npN3ceT8BbSsVRitahdBBv//vn97e/slFbWd+7cf5z44wulg8K233kKPHj3QtGlT1KtXzwRLly5dMkEbn1hcM3xtBUglSpSweztn9IaHh5uA0Dq6vXDhggkkE2LZsmV45513TGA3atSoKN2/zPxFn3wSGBhofrJ7Oj7BIFO16dMnrEsjKfCkTAnH6Y7Udgmj9os/T2u7l56uYGYN28OSNNtCL5h1j2euPoYlm8LwdIMSZvm79OmcDwo9rf2SktrOfdvP0TXAne7rrFGjhpmUUb58eTNj95dffjFj6mrXro1Zs2ahdOnScKWqVavi8ePHkRNJ6NixY2YsYfXq1eO9Xx47x/81bNjQPIfo4wDfe+89U5vQGjOC5M7ZPRERT8CyMSwfw7qC1nJm9TfXd2tZBt+/2cD8v3DeTLh15wEmLwlFzy+XY9aqQ7h7/2GyHbtISuN0ZpDKli2L4cOHIykw+8cJKZzYwUkhjKBZZ5BBaaVKlcw2zBqyvA3L2jjSN85t+/fvb54Hi1fzd+tMJWdFt2jRwnQfs6zOU089ZQJQTp5p3bp1rJlMERFxXUDI8jH2ViBh1sOyzfodp/HHslCcvngL4xfsw+w1R9ChcSBCahVFWl/VhxVxeTDI8XrsvmUQxpkqxOwdu4lZHJpdr67EeoEMBC31Czmr1zLrl1hv8Pnnn8ekSZMiC0bHhplMlpDZuXNnjPIyDDI5g5iTWr7//ntTMmfs2LEmc/jkk0+aItYiIpI0GPiVD8gZ5zYNqhQ0K5es3haGP5YdwPkrt00twlmrD+PZpiXRtEYR+KZxfuKfiDdIFWGJ5hzEwsyc4WudTbOWIUMGExAKbHYxs3vdXbHsDWc7s6tf4z+co7ZLGLVf/KntYnr46DFWbD6JqX8dNPUILcvfdWpaEo2rFYKPz/+CQrVf/Knt3L/9HI09nM4Mso4gJ1YwWzdv3jwz0YJr/jLb9scff5gsmoiISHJJ45MaLWoWNYHfso0nMG3FQVy4chvDp+3A9JWH0Ll5KdSvXDDK6iWPH0dg9+FLNrujRTyd08Egu4e5rm+zZs3M2r+cTMIl3XhhHb2ffvrJdK2KiIgkJ980PmhVtziaBhfB4n+OYfqKQzh76RaG/b4N01ccRJcWQahUIiv2nbqD4QuilrLhxJXebctr/WPxCk4PoODYQEtJlyJFipgizBacdLFv3z7XHqGIiEgC+Pn6oG2DAIz7sBmeb1kaGf19cer8Tfxn0hb0GbYe09ZdjlHT8PK1u6a0zT+7ziTbcYu4bTBYuHBhkx20rBHMSSNcwYMePnyIW7duuf4oRUREEsjfLw06NClpgsIuzUvB388Hl67FvtoJJ6E8euzU0HoRzw8GOaP2m2++McWls2fPjnLlypnxg6zb9+OPP6oGn4iIuDWuVNK5RRDefq5qnNtyAgpL24h4MqeDwZ49e6JTp06mLAux5h9nw7AmHzOELNYsIiLi7u7ee+TQdpxUIuLJnJ5AwtnDLNhswenKy5cvN4Fg8eLFkTFjRlcfo4iIiMtx1rAjbt19kOjHIpKcElSBkyUKBwwYYAo4V6hQQYGgiIikGCwfkz2zX5zb/TRzFwb9ssmsgyziiRIUDHJm8Zw5c3D16lXXHZGIiEgSYB3B7i1LxbpN+RI5wHKD/+47h37DVmPIxH9x4tz1JDtGEbddjs6akwuYiIiIuI3gsnnQsV4OLN95M0p5mZxZ/dGrTTlTZ/D0xZv4Y+kBrN0Rhn92ncWG3WdRv1JBdG5RCgVyqUdMUr4EB4MiIiIpWZlC/ni6aWUcO3fH5gokDPje6VoVHZoG4veloSYgXLM9DOt2hKFRtULo1KwU8ubIkNxPQyR5gsFUqVIhf/78SJs2bUJ2IyIikqxSp06F8gE5Y92mSN7MGNCtBo6EheP3pQdM1/GKzaewemsYmtYojGeblkKubP5JdswiyTZm8OOPP44sK8OZxawvGBgY6LIDEhERcWclCmbFxz2C8W2/+qhcMpcpSr104wn0HrIcP8/epVI04vnB4Lx587TKiIiIeL2ShbPh85dqY+hrdVG+RE48fPQYC9YfQ68v/8Iv8/bg2s2oS9yJeEwwWLlyZWzatClxjkZERCSFKVs8Bwa/WgdfvFwbpYtmx/2HjzFnzRH0/PIvTFq0Dzdu34/cllnE3YcvYc22MPNTS91JihwzWKpUKfzyyy9YsmQJgoKCkD59+hjjCAcPHuzKYxQREXF7FQNzoUJATmwNvYApS0Nx+FQ4pq84hIV/H0Pb+iXMJJOJi/bhstV6yDmypEPvtuXNrGWRFBMM/vXXX8idOzcePHiA3bt3x7idwaCIiIg34mdgtdJ5UDUoNzbtPYcpS0Jx/Ox1/L7sgM3tGRgOmbgZA7pVV0AoKScY5IQRERERiT0orFkuH2qUyYv1O09j2O/bYu0SHjt3D4LL5YssZyOSIlYg4eojoaGhWLt2LW7evInw8HDXHpmIiIgHlKzJlildnGMDL4Xfwb6jl5PsuEQSXGdw7ty5+Pbbb3HhwgXz7WfGjBkYMWIEfH19zfWqOygiIvJfjpaaYUAokiIyg4sWLUL//v1Rs2ZNfPfdd5HL0TVr1gxr1qzBqFGjEuM4RUREUiSuaOKI8Qv2YsXmk3j06HGiH5NIgoLB0aNHo1OnTvjqq6/QvHnzyOvbtWuHPn36YOHChc7uUkRExGNxaTvOGo4N515evXEP30/djte+XmlKzzxW2Rlx12Dw2LFjJgtoS8WKFXH+/HlXHJeIiIhH4KQQlo+Jzdudq+CF1mWQKX1anL54C99M2Yo+367CP7vORPbAibhNMJgjRw4cOXLE5m28nreLiIjI/7BsDMvHRM8Q5szqb65vULUQnmkUiHEfNkXXkCBk8PfFyXM3TNmZN75bY9ZBVlAobjOBpGXLlhg+fLipNdigQQNzHSeR7Nmzx4wXbN26dWIcp4iISIoPCFk+hrOGOamEYwnZhWxdTiZ9Ol8826wUWtUtjjlrDmPe2iM4evoaBv2yCaUKZ0OXkCCzHrJq+kqyBoNvvPEGDh48aH6mTv3fxOL//d//4fbt26hWrRr69esHV7t37x6GDh1qVj25e/cuGjdujA8//BDZs2d36L4dOnRA9+7d8cwzz0Re/+jRI7O0Hm+39vrrr5uxjxQWFoZBgwZh8+bNZqWV9u3bm9t8fHxc/hxFRMTzMfArH5Azzu0y+vuia0hpPFm3OGavPowFfx/DgZNXMXDMBrP83XMhQWY9ZJFkCQZZNmbcuHH4+++/sXHjRlNfMFOmTKhRo4bJFCbGt5VPP/0UW7ZsMeVr+PgDBw5E3759MXny5Fjvd+PGDRO0HjgQs/L78ePHTSDIMjnWXduW5fW4wkqPHj1QtGhRTJ06FSdPnjQBKANgPraIiEhiy5LRD91bl0WbBiUwY+UhLP7nOPYevYwPRv2NioE5TcAYVDTuxIiIS4PBOXPmmKCvTp065mLt4sWL5vZevXrBVTghhfvkLGZmHmnYsGEICQnB9u3bTXbP3kopzOply5bN5u0MEDNmzGjWV7Zl6dKlOHPmDKZNm4YsWbKgZMmSuHz5splF/fLLL6uWooiIJBkWru7VpjyeaRiAacsPYtmmE9h56BJ2Hlpnlr5jUBhQKGvk9ixyHVt3tEiCgsEBAwbgzz//tBlk7d+/34wndGUwuHXrVvOTdQ0tihUrhjx58pjuW3vB4PLly00JnBdeeAHly5e3GQyWKFHC7uMyE1m2bFkTCFrwGLjaCp8nZ06LiIgkpRxZ/PFKu4po1ygQU/86gBVbTmFr6AVzCS6b13Qfn710C2Pm7DbrHv/vfunMjGatfyzxDgZ79+4dOYOYs5lee+01m5kxZs4KFy4MV2JmkIGnn59flOs5geXcuXN27zd48OBY98txjw8fPjRdwVxWj8Flt27d0KZNG3M79503b94Yj0lnz56NVzDItuPYSnd1586dKD/FcWq7hFH7xZ/azjvbL2M6oOeTpdC6diHMWHUU63edxaa958zFFgaGnJn8VqcKCC6bx6vbzl3cSYL2Y9zhyPA9h4JBdotOnz7d/H/27NkoU6ZMjMkbHEuXOXPmKJM0HMFJGk2aNLF7Oyek2Ao8GRxGn/zhjEOHDpn1lTn+j0EfV09h1pNjBTlRhBNV+HyiPybF93G5b2YV3R3HU0r8qO0SRu0Xf2o7722/JmV9UKFgHqzadQ37TsW+9N24eXuREZfNmsmukpLbzh0cT+T2c2RYm0PBYJUqVczF4tVXX0WhQoXgCszIcYk7exik3b9/P8b1DMj8/f3j/bgLFiwwM4ozZMhgfufYQY4R/OWXX0wwmC5duhiPawkCLZNMnMW1mwMCAuCu+O2EJyUnzSSkbb2R2i5h1H7xp7ZLGE9pv9LsCs5zBZ//+t+hVfZcv/0ISJ8XpYslfNKJp7RdckmK9jt8+HDijBkcMmSI+cnuTktQZJlswZIvRYoUcTpAim3sHsf2ccYyAzPr6PbChQsmkIwvBnvRcZLIvHnzzP+ZLWRXsjU+JsX3cZmqjW8gmZR4UqaE43RHaruEUfvFn9ouYTyh/W7fu+LgdvFPanhq2yWnxGw/Ryu8OL0CydGjR81ydGPGjDG/f//996Yr9z//+Q+eeuqpyAkfrlK1alXTnWu9Xy6Jx7GE1atXj9c+r1+/bkrhzJo1K8r1u3fvRmBgoPk/971v3z4zYcSCpXSYSbQ3A1lERCS5cNawI/7ZfQZXb8TenSzexelg8JtvvkGaNGnMOD9m637//XezKgln39arV88Eh67ELFyrVq3w0UcfYdOmTdi1axfeeustE8xVqlTJbMPjYFkbW93JtnAsIGcGf/fdd6YbmmlaBrfMCloKTjdt2hS5cuUydQo5wYSzk1nS5sUXX1RZGRERcTssHxN9uTtb/tl1Fr0GL8eEBXtx7Wb8x96LFweDDPrefvttU67l33//NYWdn332WVOzj6VcuCydq7FeYK1atczqIJz9W7x4cVPCxoL1BuvWrWt+OoqzjRnEsoD1k08+acYtcp8MaC2TRVhcm1nJjh074rPPPkOXLl3MeEkRERF3wzqCLB8Tm07NSppl7e7df4SZqw6j1+C/MHnxfty88yDJjlPcT5r4zIi1zLJdu3at6etmVy5xQgazhq7GvvQvvvjCXGwJDg62ucqIha3bGLxy9jAv9nD846+//hrPoxYREUlarCM4oFv1GHUGc2b1R6825cztXVoEYcv+85i8JNSse/zn8oNmubunG5TAk/WKm/WRxbs4HblxksWyZctM4WeuFcyMHANABolTpkwxt4uIiEjyYMAXXC6f3RVIOKmgepm8qFY6DzbsPovfl4bixLkbJjicu/Yo2jUKQKs6xZDOz/XJHXFPTr/SrMvHotMM/Dh2zrLaSIsWLXDp0iWzbJyIiIgkHwZ+5QNyxroNg0IGjjXL5cP6nafx+9IDOH3xJiYs3Ic5a46gfZNAPFGrKNL6+iTZcUsKCQa5HvH8+fPNzFuuwlGgQAFzPVfv4KSMUqVKJcZxioiISCJgAer6lQuiToX8WLM9DH8sO4Bzl29j3Nw9mL36MDo2LYlmNYrAN43T0wwkhYhXDpgFp7NmzWqWObFgMCgiIiIpk49PajSuVtgEhis2n8TUvw7iUvgd/DRzF2auPIRnm5VC42qFkMbnf0Hh48cR2HvsiqlxGL07Wjw0GOT6xGPHjsWKFSsi6++x7h7LzHCWr8YLioiIpGwM9lrULGoCv2UbT2DaioO4cPUORkzbgRkrDqFT81JoUKUgNu09j3HzzuH67dOR92VpG85oZvezeGAwyNIrnHnLNYhr166NwoULm4kjp06dwsqVK7F48WJTrqV169aJe8QiIiKS6HzT+KBV3eJoGlwEi/85jhkrD+Ls5Vv47o9tmLRoX5TZyha8bsjEzWZGswJCDwsGmRFkINigQQNT8y9LlixRbmeWkPX6WBi6dOnSsS4vJyIiIimHn68P2jYogRY1i2DB+qOYteqQzUDQ2ti5e8yMZnUZpwwOjQadMGECAgICzIod0QNBS82+r7/+2izTNnHixMQ4ThEREUlG/n5p0KFJSbzV5b+1hWPDsYYsbSMeFAxu2LDBrL7h42N/ejm7j7kCyT///OPK4xMRERE3cvvuQ4e2Y41D8aBg8MKFC2Y1jrgULFjQrBEsIiIinomzhh1x7ZbWPfaoYJDLzzEgjAu3yZ49uyuOS0RERNwQy8dw1nBcxs7Zg09+/gcHT15NkuOSRA4Gq1Spgjlz5sS53axZs8y2IiIi4pk4KYTlY2JTqWQus932gxfx9g9r8fkvG3EkLDzJjlESIRhkQel169Zh1KhRdrf59ttvzdhCFZ8WERHxbCwb81anCsicPupcgpxZ/U1ZmUEv1cbo95ugafXCZoWTzfvO443v1mDIxH9x4tz1ZDtuSUBpmapVq+LNN9/EsGHDsHDhQjRq1MgsQ8c6g6dPn8ayZctw7Ngx9O/fHxUqVHBklyIiIpKCBZfNg4y4DKTPi9v3EGMFkrw5MqBfp8pmjeM/lh7A2h1h+GfXWWzYfRb1KhVAlxZBKJArY3I/DXGm6HTv3r0RGBiIkSNHYty4cVFuq1SpklmZpG7duolxjCIiIuKGmPUrXSw70qdPb3cbBnzvdK2KDk3/GxT+vesM1m4/jfU7TqNh1ULo3LyUCRwlhSxHx4wgL1evXjUZQa5NzAyhJo2IiIhIbIrkzYz3u1XH0dPX8PvSUGzaew4rt5zCmm1haFqjMDo2LYnc2ewHleImwaBFtmzZzEVERETEGcULZMFHLwabWcZTloRi24ELWLrxBFZsPoWQmkXQoWnJGOVrHj2OMEWsWbswene0JFMwKCIiIpIQJQtnw2e9a2Hv0csmU7jr8CUs+PsYlm06gZZ1iqFdo0BkzeSHf3adwZg5u6MsgcfSNpzRrPWPXUPBoIiIiCSbssVz4MtX6mDnoYsmU7j/+BXMWXMESzYcR+VSuc2Ek+gYGA6ZuNnMXFZAmHAKBkVERCTZVQzMhQoBOU238eQloTh8KtxmIGht7Nw9CC6XT13GSVFnUERERCSxpUqVClWD8mBYv/roGhIU5/aXwu+YsYSSMAoGRURExO2CQkfLzXBSiSSMgkERERFxO9FnFNuTOYNvoh+Lp1MwKCIiIm6H5WM4azguP/y5w0w2efjocZIclydSMCgiIiJuh5NCWD4mNhnT+5qZxT/O2ImXh67A8n9P4pGCQqcpGBQRERG3xLIxLB8TPUOYM6u/uX7iJy3Qq005U4/w/JXb+OHP7Xjt65VYvS3MFKoWDyotc+/ePQwdOhRLlizB3bt30bhxY3z44YcOLYPH+3bo0AHdu3fHM888Y64LCwtDkyZN7A5aDQ0NNf+fN28e3n333RjbrFixAgULFkzw8xIREZG4A0KWj7G3AslT9Uugec0iWPT3McxYeRinL97Ct1O2YvqKg+jSIgi1yuUzayhLCg8GP/30U2zZsgUjRoxA2rRpMXDgQPTt2xeTJ0+O9X43btzAG2+8gQMHDkS5Pl++fFi/fn2U606ePIkXXngBPXv2jLyO96tRowaGDRsWZVutxSwiIpJ0GPiVD8hp9/Z0adPgmUaBCKlVFPPXH8Xs1Udw8twNDJ24GcXzZ8FzIUGoXiaPSfhICgwGz58/jzlz5mD06NGoVq2auY7BWUhICLZv347KlSvbvN/KlSsxaNAgm2so+/j4IFeuXJG/P378GK+88orZV58+fSKvP3jwIEqVKhVlWxEREXFP6dP54tmmpdCqTnHMWXMY89YexdEz1zDo100oWTgrnmtRGpVL5VJQmNLGDG7dutX8rFmzZuR1xYoVQ548ebB582a791u+fDk6deqEqVOnxvkY06dPN4HfZ599FuUEYWawRIkSCX4OIiIiknQy+vuia0hpjPuwGdo1CoBfWh8cPBmOgWM34P0f12P34UvJfYhuJUVkBpnd8/Pzi3J97ty5ce7cObv3Gzx4sEP7v3//vul+ZuBYtGjRyOuvXbtmHpvd07///juuXr2KChUqmDGEDEbjIyIiArdv34a7unPnTpSf4ji1XcKo/eJPbZcwaj/Pbrs0qYCOjYuheY38mLfuOJb9G4Z9x67gg5/+Rrni2dGxSQmUKpw1cvvHjyOw/8RVhN+4ZyallC6SLdHGGyZF+zHucCQLmuzBYGyTOahfv35mnGB0DA45OSShFi1aZAI/67GCdOjQociGHDJkiJm48tNPP6FLly6YP38+cua0P3bBngcPHmD//v1wd8ePH0/uQ0ix1HYJo/aLP7Vdwqj9PL/tqhcFSuXOg3V7r2PrkVvYc/SKuQTk80OjCllw7fYjLNkajuu3H0XeJ3N6H4RUzYoyhfxTbPvZiqHcLhhkdy8DMnvWrFljsnfRMRD090/4izN79mwTjDLTaI3jEzds2GCykpaoeuTIkWjYsCFmzZqF3r17O/1Yvr6+CAgIgLvitxOelMyQuqJtvYnaLmHUfvGntksYtZ/3tV1wVeBi+B3MWn0Mq7efweGz93D47AWb2zIwnLbuMt7qVAHBZfOkuPY7fPiwQ9slezDIACm2cXkctxceHm4CQuvo9sKFCyaQTAjul+MO2U1sS/RZw3yxWFKG3cfxwaAyffr0cHd8ninhON2R2i5h1H7xp7ZLGLWfd7VdkfTp8WaXHOjU/Bb+WBaKVVvDYt1+0pJDqF+1aGQ5m5TSfo5OlHH7CSRVq1Y1s30tE0no2LFjJiCrXr16gvbN2cjsBraenGLx559/Ijg4OMoYv5s3b5oo3p2zeyIiIuKYfDkzoFmNInFudyn8jqlz6KncPhhk9q9Vq1b46KOPsGnTJuzatQtvvfWWqf9XqVIlsw2zhhcvXrTZnRybffv2oVChQsiQIUOM2+rXr2+C0Pfee8+MH9y9e7cpO8NsoaV4tYiIiKRsV67fdel2KZHbB4PEeoG1atXC66+/jh49eqB48eIYPnx4lAxf3bp1zU9nMIDMmvV/s4iiF6aeMGGCyQx27tzZrGCSKVMmTJo0KcbMZhEREUmZsmeOutSdPWu3h5kMoSdK9jGDjmBf+hdffGEutrA7N/oqI9bs3caVTWJTtmxZ/Prrr04erYiIiKQUZYrnMGsfX74We+bv333nsf3gcrPKSYfGgcjmYBCZEqSIzKCIiIhIYvBJnQq925aPdZvnWgShbPEcePDwMeavO4qeg5dj/Py9uHYz4SXu3IGCQREREfFqtSvkx4Bu1U2G0FrOrP7m+k7NS2HIq3Uw6KVaKFUkG+4/eIRZqw+j1+C/8Nvi/bh527k5C+4mRXQTi4iIiCR2QBhcLp+ZNczJIhxLyC5kSzkZlmmpVDI3Kgbmwpb95zFlaSiOhF3DtOUHsXD9UbRtGICn6hU36yOnNAoGRURERPDfLuPyAbGvMMagsHqZvKhWOg827jmLKUtCceLcDfNz3tojeKZRIFrXKYZ0fiknxEo5RyoiIiLiJlKlSoVa5fMjuGw+/L3zjMkUnr54ExMX7sPcNUfQrnEgnqhdFH6+PnB3CgZFRERE4il16lSoV7kAalfIhzXbw/DHsgM4d/k2fpm3B7NXH0bHpiXRPLgwfNP8Lyh89DgCe49dwd7jt/E43RVUKe2fKKubOErBoIiIiEgC+fikRuNqhVG/ckGs2HwKfy4/gItX72D0rF2YueoQnm1aCk2qF8K/e89hzJzdkaVsZv5zBTmy7DUzmjluMTkoGBQRERFxkTQ+qdGiZhE0rlYQyzadNBNMGBSOnL4DkxfvR7iNcjQMDIdM3GxmLidHQKjSMiIiIiIuxm7hVnWKYcwHTdHjqXLIkiGtzUDQ2ti5e0wXclJTMCgiIiKSSDiBpG2DEnizc5U4t+Vydyxtk9QUDIqIiIgkspt3Hji0HWscJjUFgyIiIiKJjEWsXbmdKykYFBEREUlkXM0k+nJ30XH5O26X1BQMioiIiCQy1hFk+ZjY9GpTLlnqDSoYFBEREUkCLBvD8jHRM4TMCCZXWRlSnUERERGRJMKAL7hcPmzbfxp7Q4+hbFAxVCldQCuQiIiIiHgLn9SpULZYdqS+ex6li2VP1kCQ1E0sIiIi4sUUDIqIiIh4MQWDIiIiIl5MwaCIiIiIF1MwKCIiIuLFFAyKiIiIeLFUEREREcl9EN5g27ZtYFOnTZsW7orH9+DBA/j6+iJVquSd5p7SqO0SRu0Xf2q7hFH7xZ/azv3b7/79+2bfVapUiXU71RlMIinhD4XH6M7BqjtT2yWM2i/+1HYJo/aLP7Wd+7cfH8OR+EOZQREREREvpjGDIiIiIl5MwaCIiIiIF1MwKCIiIuLFFAyKiIiIeDEFgyIiIiJeTMGgiIiIiBdTMCgiIiLixRQMioiIiHgxBYMiIiIiXkzBoIiIiIgXUzAoIiIi4sUUDIqIiIh4MQWDHurx48cYPnw46tWrh0qVKqFXr144deqUzW1HjBiBUqVK2bwMGDAgcrsNGzbgmWeeQcWKFRESEoKFCxfCUyVG+73wwgsxbv+///s/eHv70eXLl/H222+jZs2aCA4Oxptvvonz589H2Wbx4sVo2bIlKlSogLZt25rz0RMlRts1b948xrn3/vvvwxM5237Hjx9H7969Ua1aNdSvX9/c9+HDh1G2mTJlCpo0aWLOvS5dumDfvn3wRK5uu0ePHpk2i37u8T3T0/38889xvr9fvXrV/O1Wr14dNWrUwGeffYY7d+4kz/tehHikESNGRAQHB0esWrUqYv/+/REvvvhiRPPmzSPu3bsXY9ubN29GXLhwIcrlP//5T0SlSpUiQkNDzTaHDx+OKF++fMSwYcPM/8eNGxdRpkyZiH/++SfCE7m6/ahWrVoRv//+e5Ttrl69GuHt7Uddu3aN6NSpU8S+ffsi9u7dG9GxY8eIdu3aRd6+YcOGiLJly0ZMnDjRnH9Dhw6NKFeunPm/p3F12926dSsiKCjI7M/63Lt+/XqEJ3Km/cLDwyNq165t2nDPnj0RmzdvjggJCYkYMGBA5DazZs2KqFChQsTcuXMjDh06FPHuu+9G1KhRI+Ly5csRnsbVbce/z5IlS5p9WZ97fM/0ZJMnTzZ/c2yb2PB2/q2y/fhZ2qhRo4j33nsvWd73FAx6IP7hVq5cOWLKlCmR1127ds28oc2fPz/O+/MDhScg3wQtPv7444j27dtH2e6tt94ybxaeJjHa79KlS+ZNkbd5Omfbj7exbVasWBF53fLly811lmCZ51m/fv2i3O/ZZ58156UnSYy227lzp/mdH96eztn2Gz9+vPnSZh3YbdmyxbTXqVOnzO8Mhr766qvI2x88eBDRoEGDiNGjR0d4ksRou4ULF0ZUqVIlwlucO3cu4qWXXjLtwsA4tmBw27Ztpq2sA7t169ZFlCpVyuwnqd/31E3sgUJDQ3Hr1i3UqlUr8rrMmTOjTJky2Lx5c5z3//zzz03a/+mnn468bsuWLVH2R+yW2rp1K79QwJMkRvsdOHAAqVKlQrFixeDpnG2/dOnSIUOGDJgzZw5u3rxpLnPnzjVtxfux62rbtm0xzj92iTryenhz21nOvZw5cyJLlizwdM6234kTJ1C8eHFkz5498jpua3nPYxc8u0Kt95cmTRrz9+3t515cbWc590qUKAFvsXfvXvj6+mLevHlmOFVs2Ea5cuWK0j7sKubnBD9Xk/p9L43L9yjJ7ty5c+Znvnz5olyfO3fuyNvsWbVqFbZv324+XKLvM2/evDH2x/ENHPdg/YaQ0iVG+x08eBCZMmUygeLff/+N9OnTm3GXr776KtKmTQtP4mz78fkPHToUn3zyifmQ5Zsht508eTJSp06N8PBw3L592+b5F9frkdK4uu0sH8g83/r27Ws+XLJly4Z27drh+eefj9zGW9uP11+4cMGMbfPx8THXnT592vxkIBjb/hg8eRJXt53lfY9jCHv06GHaK0+ePOjWrRvatGkDT9S4cWNzcQTH9UZva/49Z82aFWfPnsX169eT9H3Ps94JxLAMQI0eZPj5+eHevXux3nf8+PFo1KgRSpcuHeX6u3fvxtif5ff79+/DkyRG+/FNkfflIOBx48bhlVdewfTp0/HRRx/B0zjbfsws79+/H5UrVzYD9SdOnIj8+fObQJmZLp57zuwvJXN129GhQ4fMB0uLFi3wyy+/oHPnzvjhhx88chC/s+33xBNPmC8bQ4YMMR+8ly5dwhdffGGyfw8ePEjQe4G3t53l3OM2nEjBc4/nICfVzZgxA97uzp07NhMBlvZO6vc9ZQY9ELuOLEGa5f/EE8jf39/u/c6cOYNNmzZhzJgxMW7jCRg96LP8Hts+U6LEaD9mBPv37x/ZVVeyZEnTncCZn++9957pxvPW9uNsOWaymFXNmDGjuW706NEmqOaHhiWLEP38i+v1SIlc3Xbdu3fH2LFjzf2ZmSbO5mSg+NNPP6FPnz4elR10tv2KFi1qAmNmVhlMM4PKNjl8+LBpL+v9WdO5F3fb0YIFC0zmkEMZKCgoyLxPMjBs3749vFm6dOlsJlLY3mxLfuYm5bnnOe8CEsmSemYK3xp/Z5renuXLl5vu3jp16tjcp6398aS1/OF7isRoP35bjj5mKzAw0Pz0tK5OZ9uPY2c4xs0SzBDbitdxXBK7TXieOft6pESubjtLZiH63yi/jDCbc+3aNXj73y679davX481a9aYsh0dO3Y0Wa5ChQrF+70gJXJ121mPaY1+7nnae158sPs3elsz8GMmlV3BSf2+p2DQA/HbFz8cmKWyYDcRa2OxnpE9/GDhAFYGLtFxPNK///4b5bqNGzeiSpUqHpVZSKz2YzeJdc1B2r17t8kO8hu2N7cf3xQZuFh3fTBQCQsLM23DcXA8z6Kff9w/z0tP4uq2Yzdy06ZNMXLkyBjnHgevc/ygN7cf/2b5t8lxbfwAZuC8bNkyk3nhOZcjRw4TWFvvj9vyfrG9F6RErm473pfvh7NmzYpx7lm+CHuz6tWrm6DY8qWNLO9xVatWTfr3PZfPTxa3wHqArIXFMhPW9aLu378f8fDhQ1Pr6c6dO1Hu06RJk4hRo0bZ3N/BgwdNuZSvv/7aTIX/5ZdfPLrOoKvb77fffosoXbq0qTN48uRJU3KB9bz4ON7efufPnzfbvvzyy2ZbXlieoV69epG18Fhyge3366+/mvOPdRxZ8sIT6wy6uu1Ym4ylLnjOnThxImLq1Kmm7f78888IT+RM+7EsSvXq1SO++OIL83f5119/RVStWjXip59+itwf24ntxVJRljqD/Nv1xDqDrm67Pn36RNStWzdi9erVEceOHYv4+eefzd/x2rVrIzxd//79o5SWid5+jx8/NvVBn376aVP+iTUFWWfw/fffj7xPUr7vKRj0UDzxWBurZs2a5oOgV69ekbWf+JP1jWbOnBnlPjzJGKzYs2bNmojWrVubopesocQPF0+VGO3HQqRPPPGEaT/+0fNN89GjRxGeyNn245sbgxh+EPE+r7/+euT2FrNnz45o1qyZKX7ON1BP/SLi6rZjXbyRI0eaLyv8QteiRQuPDQTj035bt26N6NChg/n7ZRuxfl50LLJfv359s02XLl1MgW9P5Oq2u3HjRsTgwYNNXUa+77Vp08YEjd6gf7Rg0Fb7sf4sA2a2Nb9gDBw4MOLu3bvJ8r6Xiv+4Pt8oIiIiIimBZw32EhERERGnKBgUERER8WIKBkVERES8mIJBERERES+mYFBERETEiykYFBEREfFiCgZFREREvFjMdbNERMRhXJIr+pJRXEqK64pySbhu3bqhTZs2yXZ8IiJxUTAoIpJAZcqUwcCBAyN/f/TokVl3dMKECXjvvffMovMNGjRI1mMUEbFHwaCISAJlzJgRlSpVinF9/fr1UatWLcyaNUvBoIi4LY0ZFBFJJH5+fkibNq3pNnam2/mTTz7BqFGjUK9ePVSsWBG9evXCpUuXMHPmTDRr1gyVK1dG9+7dERYWFiUbOWbMGLRu3RoVKlQwwWmnTp2wceNGc/vNmzfRqFEjhISE4P79++Y6rkb6/PPPo06dOrhy5UoitICIpAQKBkVEEohB1cOHDyMv9+7dw9GjRzFgwADcunXL6TGDCxYswIYNG/Dll1/iww8/NP/v2rUrJk2ahP79++Pzzz/Hzp07zU+Lb775xgSQzz77LMaNG4dBgwYhPDwc/fr1w507d0z2kvs7fvw4Ro8ebe7D/W3atAmDBw9G9uzZXd4uIpIyqJtYRCSBNm/ejLJly0a5jtnAkiVL4ocffjAZOWcwoBw5ciSyZMlifl+2bBnWrVuH5cuXo1ChQua6HTt2YO7cuZH3uXDhAt58802TWbTOTPbp0wcHDhwwmcLatWubYJEZRGYchw0bhueee05d2CJeTsGgiEgCMRD87LPPIoOy77//Hg8ePDA/ixcv7vT+SpQoERkIUs6cOZEtW7bIQJA4KeXGjRuRv3/77bfmJ7t7mZU8ceIEVq1aZa6zdAsTJ7SsX78eL7/8MooVK2Z+FxHvpmBQRCSBMmTIgPLly0f+zqzbU089hRdffNFMHnG2C5ZdutGxVE1sdu/ebQJS/vT390dAQADy588f2Y1tfazNmzfHr7/+aia3pEuXzqljExHPozGDIiIuxkweJ4GcPXvWjNNLbJwc0rNnTxMwLly4ENu2bcOMGTPQrl27GNsePHgQv/32G0qXLo0//vjDjD0UEe+mYFBEJBFw1i5nA3MySPSi1K7GbmFOFuHMYGYEU6f+71v72rVrzc/Hjx9HjkV8//33UbhwYUydOhVBQUFmQgonvIiI91IwKCKSSD744AP4+vriiy++MKVfEgvH/rFrmbOEV69ebcYEfvzxx/j999/N7ZxNTLx937595njYPcwZxydPnsR3332XaMcmIu5PwaCISCLh5BHO7uVsXnbJJpZMmTKZsjIcG8hSMpwUcubMGUyePNmMEdyyZQtCQ0NNMNi5c2dUqVIlcuILs4kTJ07E1q1bE+34RMS9pYqwHlksIiIiIl5Fs4lFRBIZv3M70k3s4+Pj1GolIiKuoGBQRCSRzZ4926xGEheuCBIcHJwkxyQiYqFuYhGRRHb16tUo6wjHNRFERCQpKRgUERER8WKaTSwiIiLixRQMioiIiHgxBYMiIiIiXkzBoIiIiIgXUzAoIiIi4sUUDIqIiIh4MQWDIiIiIl5MwaCIiIgIvNf/A1UiRtG/4HP7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 5 (corrected): Oster-style sensitivity (approximate, robust to non-numeric cols)\n",
    "# WARNING: OLS here is illustrative for Oster calculations; main DML is primary.\n",
    "\n",
    "# 1) Build ols_df and coerce expected numeric covariates to numeric (coerce errors -> NaN)\n",
    "ols_df = df[[idcol, timecol, Y_col, T_col] + covariates_to_use].copy()\n",
    "\n",
    "# Coerce the columns that should be numeric to numeric (this will convert stray strings to NaN)\n",
    "numeric_cols = [Y_col, T_col] + covariates_to_use\n",
    "for c in numeric_cols:\n",
    "    ols_df[c] = pd.to_numeric(ols_df[c], errors='coerce')\n",
    "\n",
    "# Optional diagnostic: show columns that remain non-numeric (e.g., iso3c)\n",
    "print(\"Remaining non-numeric columns:\", ols_df.select_dtypes(exclude=[np.number]).columns.tolist())\n",
    "\n",
    "# 2) Mean-impute only numeric columns (safe: compute mean for numeric columns only)\n",
    "numeric_means = ols_df.select_dtypes(include=[np.number]).mean()\n",
    "# fill numeric columns with their means; non-numeric columns (iso3c) are untouched\n",
    "ols_df[numeric_means.index] = ols_df[numeric_means.index].fillna(numeric_means)\n",
    "\n",
    "# 3) Baseline OLS: Y ~ T + year dummies\n",
    "X_base = pd.get_dummies(ols_df[timecol], prefix='yr').astype(float)\n",
    "X_base = X_base.join(ols_df[[T_col]])\n",
    "X_base = sm.add_constant(X_base)\n",
    "olsm_base = sm.OLS(ols_df[Y_col], X_base).fit()\n",
    "beta_base = olsm_base.params[T_col]\n",
    "R_base = olsm_base.rsquared\n",
    "\n",
    "# 4) Full OLS: Y ~ T + X + year dummies\n",
    "X_full = pd.get_dummies(ols_df[timecol], prefix='yr').astype(float).join(ols_df[covariates_to_use])\n",
    "X_full = X_full.join(ols_df[[T_col]])\n",
    "X_full = sm.add_constant(X_full)\n",
    "olsm_full = sm.OLS(ols_df[Y_col], X_full).fit()\n",
    "beta_full = olsm_full.params[T_col]\n",
    "R_full = olsm_full.rsquared\n",
    "\n",
    "print(\"OLS baseline beta:\", beta_base, \"R2:\", R_base)\n",
    "print(\"OLS full beta:\", beta_full, \"R2:\", R_full)\n",
    "print(\"DML theta:\", theta_hat)\n",
    "\n",
    "# 5) Oster adjustment (approx) over R_max grid\n",
    "def oster_adjust(beta_full, beta_base, R_full, R_base, R_max):\n",
    "    denom = (R_full - R_base)\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    adj = beta_full - (R_max - R_full) / denom * (beta_full - beta_base)\n",
    "    return adj\n",
    "\n",
    "R_max_grid = np.linspace(R_full, min(1.0, R_full*1.5), 20)\n",
    "oster_results = [(Rmax, oster_adjust(beta_full, beta_base, R_full, R_base, Rmax)) for Rmax in R_max_grid]\n",
    "oster_df = pd.DataFrame(oster_results, columns=['R_max','beta_adj'])\n",
    "oster_df.to_csv(os.path.join(fold_output_dir,'oster_adjustments.csv'), index=False)\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(oster_df['R_max'], oster_df['beta_adj'], marker='o')\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.xlabel('R_max')\n",
    "plt.ylabel('Oster-adjusted beta (approx)')\n",
    "plt.title('Oster-style sensitivity of OLS beta (illustrative)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40fd74d",
   "metadata": {},
   "source": [
    "CELL 6 — Permutation test (shuffle ND-GAIN across countries)\n",
    "\n",
    "This builds an empirical null distribution of the DML theta by permuting gain across countries (preserves time structure within country). It re-runs the whole cross-fit DML loop for each permutation — may take time; set n_permutations accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bda89d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 20/200 permutations — elapsed 588s\n",
      "Completed 40/200 permutations — elapsed 1838s\n",
      "Completed 60/200 permutations — elapsed 2459s\n",
      "Completed 80/200 permutations — elapsed 3186s\n",
      "Completed 100/200 permutations — elapsed 3948s\n",
      "Completed 120/200 permutations — elapsed 4438s\n",
      "Completed 140/200 permutations — elapsed 5297s\n",
      "Completed 160/200 permutations — elapsed 6599s\n",
      "Completed 180/200 permutations — elapsed 7132s\n",
      "Completed 200/200 permutations — elapsed 8602s\n",
      "Completed permutations: 200\n",
      "Empirical permutation p-value: 0.004975124378109453\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CORRECTED CELL 6: robust permutation test (shuffle gain within each year) + robust DML function\n",
    "\n",
    "import time\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "def dml_theta_on_df(df_local, covariates_list, n_trees_local=300, random_seed_local=2025):\n",
    "    \"\"\"\n",
    "    Compact DML run (pooled with year FE), robust to NaNs in train/test by dropping obs where y or t are missing.\n",
    "    Returns theta estimate (float). Does NOT persist models to disk to keep it fast in permutations.\n",
    "    \"\"\"\n",
    "    years_local = sorted(df_local[timecol].unique())\n",
    "    folds_local = [(df_local.index[df_local[timecol] != y].tolist(), df_local.index[df_local[timecol] == y].tolist()) for y in years_local]\n",
    "\n",
    "    u_list_loc = []\n",
    "    v_list_loc = []\n",
    "\n",
    "    for fnum,(train_idx,test_idx) in enumerate(folds_local):\n",
    "        train = df_local.loc[train_idx].copy()\n",
    "        test  = df_local.loc[test_idx].copy()\n",
    "\n",
    "        # Preprocess (no FE partial-out for pooled)\n",
    "        prep = fold_aware_preprocess(train, test, covariates_list,\n",
    "                                     idcol=idcol, ycol=Y_col, tcol=T_col,\n",
    "                                     imputer=KNNImputer(n_neighbors=5),\n",
    "                                     scaler=StandardScaler(),\n",
    "                                     include_country_fe=False,\n",
    "                                     save_prefix=None)  # do not save artifacts in permutation runs\n",
    "\n",
    "        X_train = prep['X_train']; X_test = prep['X_test']\n",
    "        y_train = prep['y_train']; y_test = prep['y_test']\n",
    "        t_train = prep['t_train']; t_test = prep['t_test']\n",
    "\n",
    "        # Add year dummies fitted on train (same as main loop)\n",
    "        yrs_train = pd.get_dummies(train[timecol], prefix='yr')\n",
    "        yrs_test  = pd.get_dummies(test[timecol], prefix='yr').reindex(columns=yrs_train.columns, fill_value=0)\n",
    "        yrs_train.index = train.index; yrs_test.index = test.index\n",
    "\n",
    "        X_train_fe = pd.concat([X_train.reset_index(drop=True), yrs_train.reset_index(drop=True)], axis=1); X_train_fe.index = X_train.index\n",
    "        X_test_fe  = pd.concat([X_test.reset_index(drop=True),  yrs_test.reset_index(drop=True)], axis=1); X_test_fe.index = X_test.index\n",
    "        X_test_fe  = X_test_fe.reindex(columns=X_train_fe.columns, fill_value=0)\n",
    "\n",
    "        # --- Drop training rows with missing y or missing t ---\n",
    "        train_mask = (~y_train.isna()) & (~t_train.isna())\n",
    "        if train_mask.sum() < max(10, int(0.05 * len(train_mask))):\n",
    "            # too few train obs with both y and t -> skip this fold (no contribution)\n",
    "            # (this occurs rarely if a year has extremely sparse data)\n",
    "            # Continue to next fold without appending residuals\n",
    "            continue\n",
    "\n",
    "        Xtrain_sub = X_train_fe.loc[train_mask.index[train_mask]].copy()\n",
    "        ytrain_sub = y_train.loc[train_mask.index[train_mask]].copy()\n",
    "        ttrain_sub = t_train.loc[train_mask.index[train_mask]].copy()\n",
    "\n",
    "        # Fit p(X) on the training subset; handle degenerate cases\n",
    "        try:\n",
    "            # if ttrain_sub is constant, LassoCV will fail; check variance\n",
    "            if np.nanvar(ttrain_sub) == 0:\n",
    "                # no variation in treatment in this training subset -> skip fold\n",
    "                continue\n",
    "            p_model = LassoCV(cv=5, random_state=random_seed_local).fit(Xtrain_sub, ttrain_sub)\n",
    "        except Exception as e:\n",
    "            # fallback: simple Lasso with default alpha or skip fold\n",
    "            try:\n",
    "                from sklearn.linear_model import Lasso\n",
    "                p_model = Lasso(alpha=1.0).fit(Xtrain_sub, ttrain_sub)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # predict p-hat on the test set (but we'll only use entries with non-missing y and t)\n",
    "        p_hat_test_full = p_model.predict(X_test_fe)\n",
    "\n",
    "        # Fit m(X) on training subset\n",
    "        try:\n",
    "            m_model = RandomForestRegressor(n_estimators=n_trees_local, n_jobs=-1, random_state=random_seed_local)\n",
    "            m_model.fit(Xtrain_sub, ytrain_sub)\n",
    "        except Exception as e:\n",
    "            # if RF fails for some reason, fallback to simple linear model\n",
    "            m_model = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "            # wrap predict function to match API\n",
    "            def m_predict(X): \n",
    "                return m_model.predict(sm.add_constant(X))\n",
    "            m_hat_test_full = m_predict(X_test_fe)\n",
    "        else:\n",
    "            m_hat_test_full = m_model.predict(X_test_fe)\n",
    "\n",
    "        # --- For the test fold, only keep indices where both y_test and t_test are observed (no NaNs) ---\n",
    "        test_mask = (~y_test.isna()) & (~t_test.isna())\n",
    "        if test_mask.sum() == 0:\n",
    "            continue  # nothing to add from this fold\n",
    "\n",
    "        index_keep = test_mask.index[test_mask]\n",
    "        u_hat = y_test.loc[index_keep].values - m_hat_test_full[np.isin(X_test_fe.index, index_keep)]\n",
    "        v_hat = t_test.loc[index_keep].values - p_hat_test_full[np.isin(X_test_fe.index, index_keep)]\n",
    "\n",
    "        # Append\n",
    "        u_list_loc.append(pd.Series(u_hat, index=index_keep))\n",
    "        v_list_loc.append(pd.Series(v_hat, index=index_keep))\n",
    "\n",
    "    # end folds\n",
    "    if len(u_list_loc) == 0:\n",
    "        # nothing to estimate (very unlikely)\n",
    "        return np.nan\n",
    "\n",
    "    u_all_loc = pd.concat(u_list_loc).sort_index()\n",
    "    v_all_loc = pd.concat(v_list_loc).sort_index()\n",
    "    theta_loc = (v_all_loc * u_all_loc).sum() / (v_all_loc**2).sum()\n",
    "    return float(theta_loc)\n",
    "\n",
    "\n",
    "# Permutation: shuffle gain across countries within each year\n",
    "perm_thetas = []\n",
    "start_time = time.time()\n",
    "for perm in range(n_permutations):\n",
    "    # build shuffled df by year: for each year, shuffle gain among countries present that year\n",
    "    shuffled = df.copy()\n",
    "    shuffled['gain_perm'] = np.nan\n",
    "    for yr in shuffled[timecol].unique():\n",
    "        mask = shuffled[timecol] == yr\n",
    "        vals = shuffled.loc[mask, T_col].values\n",
    "        # if all NaN, skip year\n",
    "        if np.all(pd.isna(vals)):\n",
    "            continue\n",
    "        np.random.shuffle(vals)  # in-place shuffle\n",
    "        shuffled.loc[mask, 'gain_perm'] = vals\n",
    "\n",
    "    # ensure there are no NaNs in gain_perm where original had a value (if some years had fewer obs, we still align)\n",
    "    # set the treatment column temporarily\n",
    "    shuffled_temp = shuffled.copy()\n",
    "    shuffled_temp[T_col] = shuffled_temp['gain_perm']\n",
    "\n",
    "    # Optionally: drop rows where shuffled_temp[T_col] is NaN (rare)\n",
    "    # but dml_theta_on_df will handle missing by skipping folds with insufficient data, so we can proceed.\n",
    "\n",
    "    theta_perm = dml_theta_on_df(shuffled_temp, covariates_to_use, n_trees_local=n_trees, random_seed_local=random_seed)\n",
    "    perm_thetas.append(theta_perm)\n",
    "\n",
    "    if (perm+1) % 20 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Completed {perm+1}/{n_permutations} permutations — elapsed {elapsed:.0f}s\")\n",
    "\n",
    "# Remove NaN thetas if any (folds might have been skipped)\n",
    "perm_thetas_clean = np.array([t for t in perm_thetas if not pd.isna(t)])\n",
    "if len(perm_thetas_clean) == 0:\n",
    "    print(\"No valid permutation thetas computed — check data coverage.\")\n",
    "else:\n",
    "    p_emp = (np.sum(np.abs(perm_thetas_clean) >= np.abs(theta_hat)) + 1) / (len(perm_thetas_clean) + 1)\n",
    "    print(\"Completed permutations:\", len(perm_thetas_clean))\n",
    "    print(\"Empirical permutation p-value:\", p_emp)\n",
    "\n",
    "    # plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.histplot(perm_thetas_clean, kde=True, bins=30)\n",
    "    plt.axvline(theta_hat, color='red', linestyle='--', label='Observed theta')\n",
    "    plt.legend()\n",
    "    plt.title('Permutation null distribution of DML theta')\n",
    "    plt.show()\n",
    "\n",
    "    # save\n",
    "    pd.Series(perm_thetas_clean).to_csv(os.path.join(fold_output_dir,'perm_thetas_clean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fcb45c",
   "metadata": {},
   "source": [
    "Cell 7 Placebo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dec58403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placebo shape: (1468, 65)\n",
      "Columns preview: ['year', 'iso3c', 'yield_with_spread', 'sovereign_spread', 'cpi_yoy', 'gdp_annual_growth_rate', 'gdp_per_capita', 'gross gdp', 'debt_to_gdp', 'deficit_to_gdp', 'current_account_balance', 'vulnerability', 'wgi_cc', 'wgi_ge', 'wgi_pv', 'wgi_rl', 'wgi_rq', 'wgi_va', 'gain', 'country_mean', 'gain_diff1', 'ln_gdp_per_capita', 'ln_gross_gdp', 'sovereign_spread_lag1', 'sovereign_spread_lag2', 'cpi_yoy_lag1', 'cpi_yoy_lag2', 'gdp_annual_growth_rate_lag1', 'gdp_annual_growth_rate_lag2', 'ln_gdp_per_capita_lag1']\n",
      "Does gain_lead1 exist and non-missing count: 1468\n",
      "Sample rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3c</th>\n",
       "      <th>year</th>\n",
       "      <th>gain</th>\n",
       "      <th>gain_lead1</th>\n",
       "      <th>sovereign_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2010</td>\n",
       "      <td>46.299003</td>\n",
       "      <td>45.844055</td>\n",
       "      <td>15.604236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2012</td>\n",
       "      <td>45.844055</td>\n",
       "      <td>45.512061</td>\n",
       "      <td>9.079577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2013</td>\n",
       "      <td>45.512061</td>\n",
       "      <td>45.076998</td>\n",
       "      <td>6.987068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2014</td>\n",
       "      <td>45.076998</td>\n",
       "      <td>44.899691</td>\n",
       "      <td>7.833954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2015</td>\n",
       "      <td>44.899691</td>\n",
       "      <td>46.512091</td>\n",
       "      <td>5.376118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2016</td>\n",
       "      <td>46.512091</td>\n",
       "      <td>46.441575</td>\n",
       "      <td>1.361908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2017</td>\n",
       "      <td>46.441575</td>\n",
       "      <td>48.315080</td>\n",
       "      <td>4.101448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2018</td>\n",
       "      <td>48.315080</td>\n",
       "      <td>48.720793</td>\n",
       "      <td>14.894352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso3c  year       gain  gain_lead1  sovereign_spread\n",
       "0   ARG  2010  46.299003   45.844055         15.604236\n",
       "1   ARG  2012  45.844055   45.512061          9.079577\n",
       "2   ARG  2013  45.512061   45.076998          6.987068\n",
       "3   ARG  2014  45.076998   44.899691          7.833954\n",
       "4   ARG  2015  44.899691   46.512091          5.376118\n",
       "5   ARG  2016  46.512091   46.441575          1.361908\n",
       "6   ARG  2017  46.441575   48.315080          4.101448\n",
       "7   ARG  2018  48.315080   48.720793         14.894352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dtypes of key cols:\n",
      "gain                float64\n",
      "sovereign_spread    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. recreate placebo lead column safely and inspect\n",
    "df_placebo = df.copy()\n",
    "\n",
    "# create gain_lead1 (future ND-GAIN)\n",
    "df_placebo['gain_lead1'] = df_placebo.groupby('iso3c')['gain'].shift(-1)\n",
    "\n",
    "# drop rows where lead is missing (optional for placebo)\n",
    "df_placebo_pl = df_placebo.dropna(subset=['gain_lead1']).copy()\n",
    "\n",
    "# reset index to ensure unique integer index (very important)\n",
    "df_placebo_pl = df_placebo_pl.reset_index(drop=True)\n",
    "\n",
    "# check\n",
    "print(\"placebo shape:\", df_placebo_pl.shape)\n",
    "print(\"Columns preview:\", df_placebo_pl.columns[:30].tolist())\n",
    "print(\"Does gain_lead1 exist and non-missing count:\", df_placebo_pl['gain_lead1'].notna().sum())\n",
    "print(\"Sample rows:\")\n",
    "display(df_placebo_pl[[ 'iso3c','year','gain','gain_lead1', Y_col ]].head(8))\n",
    "print(\"\\nDtypes of key cols:\")\n",
    "print(df_placebo_pl[[T_col, Y_col]].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e8820e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (holdout year 1995): USED, n_train_ok=1438, n_test_ok=30, train_var=True\n",
      "Fold 1 (holdout year 1996): USED, n_train_ok=1436, n_test_ok=32, train_var=True\n",
      "Fold 2 (holdout year 1997): USED, n_train_ok=1434, n_test_ok=34, train_var=True\n",
      "Fold 3 (holdout year 1998): USED, n_train_ok=1432, n_test_ok=36, train_var=True\n",
      "Fold 4 (holdout year 1999): USED, n_train_ok=1430, n_test_ok=38, train_var=True\n",
      "Fold 5 (holdout year 2000): USED, n_train_ok=1428, n_test_ok=40, train_var=True\n",
      "Fold 6 (holdout year 2001): USED, n_train_ok=1426, n_test_ok=42, train_var=True\n",
      "Fold 7 (holdout year 2002): USED, n_train_ok=1424, n_test_ok=44, train_var=True\n",
      "Fold 8 (holdout year 2003): USED, n_train_ok=1422, n_test_ok=46, train_var=True\n",
      "Fold 9 (holdout year 2004): USED, n_train_ok=1421, n_test_ok=47, train_var=True\n",
      "Fold 10 (holdout year 2005): USED, n_train_ok=1420, n_test_ok=48, train_var=True\n",
      "Fold 11 (holdout year 2006): USED, n_train_ok=1420, n_test_ok=48, train_var=True\n",
      "Fold 12 (holdout year 2007): USED, n_train_ok=1417, n_test_ok=51, train_var=True\n",
      "Fold 13 (holdout year 2008): USED, n_train_ok=1414, n_test_ok=54, train_var=True\n",
      "Fold 14 (holdout year 2009): USED, n_train_ok=1413, n_test_ok=55, train_var=True\n",
      "Fold 15 (holdout year 2010): USED, n_train_ok=1411, n_test_ok=57, train_var=True\n",
      "Fold 16 (holdout year 2011): USED, n_train_ok=1412, n_test_ok=56, train_var=True\n",
      "Fold 17 (holdout year 2012): USED, n_train_ok=1405, n_test_ok=63, train_var=True\n",
      "Fold 18 (holdout year 2013): USED, n_train_ok=1404, n_test_ok=64, train_var=True\n",
      "Fold 19 (holdout year 2014): USED, n_train_ok=1404, n_test_ok=64, train_var=True\n",
      "Fold 20 (holdout year 2015): USED, n_train_ok=1403, n_test_ok=65, train_var=True\n",
      "Fold 21 (holdout year 2016): USED, n_train_ok=1404, n_test_ok=64, train_var=True\n",
      "Fold 22 (holdout year 2017): USED, n_train_ok=1404, n_test_ok=64, train_var=True\n",
      "Fold 23 (holdout year 2018): USED, n_train_ok=1403, n_test_ok=65, train_var=True\n",
      "Fold 24 (holdout year 2019): USED, n_train_ok=1404, n_test_ok=64, train_var=True\n",
      "Fold 25 (holdout year 2020): USED, n_train_ok=1403, n_test_ok=65, train_var=True\n",
      "Fold 26 (holdout year 2021): USED, n_train_ok=1402, n_test_ok=66, train_var=True\n",
      "Fold 27 (holdout year 2022): USED, n_train_ok=1402, n_test_ok=66, train_var=True\n",
      "Done. theta=0.387633. folds_used=28/28. elapsed=7.3s\n",
      "\n",
      "Per-fold diagnostics (first 20 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>year_holdout</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_train_ok</th>\n",
       "      <th>train_variation</th>\n",
       "      <th>n_test_ok</th>\n",
       "      <th>used</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1438</td>\n",
       "      <td>30</td>\n",
       "      <td>1438</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>1436</td>\n",
       "      <td>32</td>\n",
       "      <td>1436</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1997</td>\n",
       "      <td>1434</td>\n",
       "      <td>34</td>\n",
       "      <td>1434</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>1432</td>\n",
       "      <td>36</td>\n",
       "      <td>1432</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1999</td>\n",
       "      <td>1430</td>\n",
       "      <td>38</td>\n",
       "      <td>1430</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>1428</td>\n",
       "      <td>40</td>\n",
       "      <td>1428</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>1426</td>\n",
       "      <td>42</td>\n",
       "      <td>1426</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>1424</td>\n",
       "      <td>44</td>\n",
       "      <td>1424</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2003</td>\n",
       "      <td>1422</td>\n",
       "      <td>46</td>\n",
       "      <td>1422</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2004</td>\n",
       "      <td>1421</td>\n",
       "      <td>47</td>\n",
       "      <td>1421</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2005</td>\n",
       "      <td>1420</td>\n",
       "      <td>48</td>\n",
       "      <td>1420</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>1420</td>\n",
       "      <td>48</td>\n",
       "      <td>1420</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>1417</td>\n",
       "      <td>51</td>\n",
       "      <td>1417</td>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2008</td>\n",
       "      <td>1414</td>\n",
       "      <td>54</td>\n",
       "      <td>1414</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2009</td>\n",
       "      <td>1413</td>\n",
       "      <td>55</td>\n",
       "      <td>1413</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2010</td>\n",
       "      <td>1411</td>\n",
       "      <td>57</td>\n",
       "      <td>1411</td>\n",
       "      <td>True</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2011</td>\n",
       "      <td>1412</td>\n",
       "      <td>56</td>\n",
       "      <td>1412</td>\n",
       "      <td>True</td>\n",
       "      <td>56</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2012</td>\n",
       "      <td>1405</td>\n",
       "      <td>63</td>\n",
       "      <td>1405</td>\n",
       "      <td>True</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2013</td>\n",
       "      <td>1404</td>\n",
       "      <td>64</td>\n",
       "      <td>1404</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2014</td>\n",
       "      <td>1404</td>\n",
       "      <td>64</td>\n",
       "      <td>1404</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  year_holdout  n_train  n_test  n_train_ok  train_variation  \\\n",
       "0      0          1995     1438      30        1438             True   \n",
       "1      1          1996     1436      32        1436             True   \n",
       "2      2          1997     1434      34        1434             True   \n",
       "3      3          1998     1432      36        1432             True   \n",
       "4      4          1999     1430      38        1430             True   \n",
       "5      5          2000     1428      40        1428             True   \n",
       "6      6          2001     1426      42        1426             True   \n",
       "7      7          2002     1424      44        1424             True   \n",
       "8      8          2003     1422      46        1422             True   \n",
       "9      9          2004     1421      47        1421             True   \n",
       "10    10          2005     1420      48        1420             True   \n",
       "11    11          2006     1420      48        1420             True   \n",
       "12    12          2007     1417      51        1417             True   \n",
       "13    13          2008     1414      54        1414             True   \n",
       "14    14          2009     1413      55        1413             True   \n",
       "15    15          2010     1411      57        1411             True   \n",
       "16    16          2011     1412      56        1412             True   \n",
       "17    17          2012     1405      63        1405             True   \n",
       "18    18          2013     1404      64        1404             True   \n",
       "19    19          2014     1404      64        1404             True   \n",
       "\n",
       "    n_test_ok  used reason  \n",
       "0          30  True         \n",
       "1          32  True         \n",
       "2          34  True         \n",
       "3          36  True         \n",
       "4          38  True         \n",
       "5          40  True         \n",
       "6          42  True         \n",
       "7          44  True         \n",
       "8          46  True         \n",
       "9          47  True         \n",
       "10         48  True         \n",
       "11         48  True         \n",
       "12         51  True         \n",
       "13         54  True         \n",
       "14         55  True         \n",
       "15         57  True         \n",
       "16         56  True         \n",
       "17         63  True         \n",
       "18         64  True         \n",
       "19         64  True         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Placebo theta: 0.3876333422616326\n"
     ]
    }
   ],
   "source": [
    "# Paste and run this whole cell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "\n",
    "def dml_theta_on_df_debug(df_local, covariates_list, n_trees_local=100, random_seed_local=2025, verbose=True):\n",
    "    \"\"\"\n",
    "    Robust pooled DML (year-FE) with fold-level diagnostics.\n",
    "    Returns (theta, diagnostics_df)\n",
    "    diagnostics_df has one row per fold with counts and reasons for skipping.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    df_local = df_local.reset_index(drop=True).copy()   # ensure integer index\n",
    "    years_local = sorted(df_local['year'].unique())\n",
    "    folds_local = [(df_local.index[df_local['year'] != y].tolist(), df_local.index[df_local['year'] == y].tolist()) for y in years_local]\n",
    "\n",
    "    u_list = []\n",
    "    v_list = []\n",
    "    diag_rows = []\n",
    "\n",
    "    for fnum, (train_idx, test_idx) in enumerate(folds_local):\n",
    "        train = df_local.loc[train_idx].reset_index(drop=True).copy()\n",
    "        test  = df_local.loc[test_idx].reset_index(drop=True).copy()\n",
    "\n",
    "        # Minimal diagnostics\n",
    "        n_train = len(train)\n",
    "        n_test  = len(test)\n",
    "\n",
    "        # Preprocess (impute & scale on train only)\n",
    "        prep = fold_aware_preprocess(train, test, covariates_list,\n",
    "                                     idcol='iso3c', ycol=Y_col, tcol=T_col,\n",
    "                                     imputer=KNNImputer(n_neighbors=5),\n",
    "                                     scaler=StandardScaler(),\n",
    "                                     include_country_fe=False,\n",
    "                                     save_prefix=None)\n",
    "\n",
    "        X_train = prep['X_train']; X_test = prep['X_test']\n",
    "        y_train = prep['y_train']; y_test = prep['y_test']\n",
    "        t_train = prep['t_train']; t_test = prep['t_test']\n",
    "\n",
    "        # Year dummies fitted on train\n",
    "        yrs_train = pd.get_dummies(train['year'], prefix='yr')\n",
    "        yrs_test  = pd.get_dummies(test['year'], prefix='yr').reindex(columns=yrs_train.columns, fill_value=0)\n",
    "        yrs_train = yrs_train.reset_index(drop=True)\n",
    "        yrs_test  = yrs_test.reset_index(drop=True)\n",
    "\n",
    "        X_train_fe = pd.concat([X_train.reset_index(drop=True), yrs_train], axis=1)\n",
    "        X_test_fe  = pd.concat([X_test.reset_index(drop=True),  yrs_test], axis=1)\n",
    "        X_test_fe  = X_test_fe.reindex(columns=X_train_fe.columns, fill_value=0)\n",
    "\n",
    "        # use numpy arrays for masks\n",
    "        y_train_arr = y_train.to_numpy()\n",
    "        t_train_arr = t_train.to_numpy()\n",
    "        train_mask = (~pd.isna(y_train_arr)) & (~pd.isna(t_train_arr))\n",
    "        n_train_ok = int(train_mask.sum())\n",
    "        train_variation = False\n",
    "        if n_train_ok > 0:\n",
    "            # check variation in treatment among usable rows\n",
    "            ttrain_sub = t_train.iloc[np.where(train_mask)[0]]\n",
    "            train_variation = (np.nanvar(ttrain_sub.to_numpy()) > 0)\n",
    "\n",
    "        reason = ''\n",
    "        if n_train_ok < max(10, int(0.05 * len(train_mask))):\n",
    "            reason = 'too_few_train_rows'\n",
    "        elif not train_variation:\n",
    "            reason = 'no_t_variation_in_train'\n",
    "\n",
    "        if reason != '':\n",
    "            # skip fold but record diagnostics\n",
    "            diag_rows.append({\n",
    "                'fold': fnum, 'year_holdout': years_local[fnum],\n",
    "                'n_train': n_train, 'n_test': n_test,\n",
    "                'n_train_ok': n_train_ok, 'train_variation': train_variation,\n",
    "                'used': False, 'reason': reason\n",
    "            })\n",
    "            if verbose:\n",
    "                print(f\"Fold {fnum} (holdout year {years_local[fnum]}): SKIPPED ({reason}), n_train_ok={n_train_ok}, n_test={n_test}\")\n",
    "            continue\n",
    "\n",
    "        # get integer positions of usable training rows\n",
    "        train_pos = np.where(train_mask)[0]\n",
    "        Xtrain_sub = X_train_fe.iloc[train_pos, :].copy()\n",
    "        ytrain_sub = y_train.iloc[train_pos].copy()\n",
    "        ttrain_sub = t_train.iloc[train_pos].copy()\n",
    "\n",
    "        # Fit p(X)\n",
    "        try:\n",
    "            p_model = LassoCV(cv=5, random_state=random_seed_local).fit(Xtrain_sub, ttrain_sub)\n",
    "        except Exception:\n",
    "            from sklearn.linear_model import Lasso\n",
    "            p_model = Lasso(alpha=1.0).fit(Xtrain_sub, ttrain_sub)\n",
    "        p_hat_test_full = p_model.predict(X_test_fe)\n",
    "\n",
    "        # Fit m(X)\n",
    "        try:\n",
    "            m_model = RandomForestRegressor(n_estimators=n_trees_local, n_jobs=-1, random_state=random_seed_local)\n",
    "            m_model.fit(Xtrain_sub, ytrain_sub)\n",
    "            m_hat_test_full = m_model.predict(X_test_fe)\n",
    "        except Exception:\n",
    "            m_ols = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "            m_hat_test_full = m_ols.predict(sm.add_constant(X_test_fe))\n",
    "\n",
    "        # test mask — positions where both y_test and t_test are not NaN\n",
    "        y_test_arr = y_test.to_numpy()\n",
    "        t_test_arr = t_test.to_numpy()\n",
    "        test_mask = (~pd.isna(y_test_arr)) & (~pd.isna(t_test_arr))\n",
    "        n_test_ok = int(test_mask.sum())\n",
    "        if n_test_ok == 0:\n",
    "            diag_rows.append({\n",
    "                'fold': fnum, 'year_holdout': years_local[fnum],\n",
    "                'n_train': n_train, 'n_test': n_test,\n",
    "                'n_train_ok': n_train_ok, 'train_variation': train_variation,\n",
    "                'n_test_ok': n_test_ok, 'used': False, 'reason': 'no_test_obs'\n",
    "            })\n",
    "            if verbose:\n",
    "                print(f\"Fold {fnum} (holdout year {years_local[fnum]}): SKIPPED (no usable test obs)\")\n",
    "            continue\n",
    "\n",
    "        test_pos = np.where(test_mask)[0]\n",
    "        p_hat_kept = p_hat_test_full[test_pos]\n",
    "        m_hat_kept = m_hat_test_full[test_pos]\n",
    "\n",
    "        index_keep = test.index[test_pos]\n",
    "        u_hat = y_test_arr[test_pos] - m_hat_kept\n",
    "        v_hat = t_test_arr[test_pos] - p_hat_kept\n",
    "\n",
    "        u_list.append(pd.Series(u_hat, index=index_keep))\n",
    "        v_list.append(pd.Series(v_hat, index=index_keep))\n",
    "\n",
    "        diag_rows.append({\n",
    "            'fold': fnum, 'year_holdout': years_local[fnum],\n",
    "            'n_train': n_train, 'n_test': n_test,\n",
    "            'n_train_ok': n_train_ok, 'train_variation': train_variation,\n",
    "            'n_test_ok': n_test_ok, 'used': True, 'reason': ''\n",
    "        })\n",
    "        if verbose:\n",
    "            print(f\"Fold {fnum} (holdout year {years_local[fnum]}): USED, n_train_ok={n_train_ok}, n_test_ok={n_test_ok}, train_var={train_variation}\")\n",
    "\n",
    "    # end folds\n",
    "    if len(u_list) == 0:\n",
    "        if verbose:\n",
    "            print(\"No folds contributed; returning NaN\")\n",
    "        return np.nan, pd.DataFrame(diag_rows)\n",
    "\n",
    "    u_all = pd.concat(u_list).sort_index()\n",
    "    v_all = pd.concat(v_list).sort_index()\n",
    "    theta = (v_all * u_all).sum() / (v_all**2).sum()\n",
    "    if verbose:\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"Done. theta={theta:.6g}. folds_used={sum([1 for r in diag_rows if r.get('used')])}/{len(diag_rows)}. elapsed={elapsed:.1f}s\")\n",
    "    return float(theta), pd.DataFrame(diag_rows)\n",
    "\n",
    "# Now run the debug DML on your placebo panel\n",
    "theta_placebo, diag_df = dml_theta_on_df_debug(df_placebo_pl, covariates_to_use, n_trees_local=100, random_seed_local=2025, verbose=True)\n",
    "\n",
    "print(\"\\nPer-fold diagnostics (first 20 rows):\")\n",
    "display(diag_df.head(20))\n",
    "\n",
    "print(\"\\nPlacebo theta:\", theta_placebo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a2e7da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placebo theta (calc): 0.37548554967258607\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.119\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.119\n",
      "Method:                 Least Squares   F-statistic:                              1.903\n",
      "Date:                Fri, 22 Aug 2025   Prob (F-statistic):                       0.262\n",
      "Time:                        10:38:53   Log-Likelihood:                         -4690.7\n",
      "No. Observations:                1468   AIC:                                      9383.\n",
      "Df Residuals:                    1467   BIC:                                      9389.\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:              cluster                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.3755      0.272      1.379      0.168      -0.158       0.909\n",
      "==============================================================================\n",
      "Omnibus:                     3047.188   Durbin-Watson:                   2.041\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         16576314.797\n",
      "Skew:                          16.475   Prob(JB):                         0.00\n",
      "Kurtosis:                     522.535   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "# === Compute SE for placebo theta ===\n",
    "import pickle\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Make a copy and set temporary treatment name\n",
    "df_temp = df_placebo_pl.copy().reset_index(drop=True).rename(columns={'gain_lead1':'gain_temp'})\n",
    "\n",
    "# prepare fold list (leave-one-year-out)\n",
    "years = sorted(df_temp['year'].unique())\n",
    "folds = [(df_temp.index[df_temp['year'] != y].tolist(), df_temp.index[df_temp['year'] == y].tolist()) for y in years]\n",
    "\n",
    "u_list = []\n",
    "v_list = []\n",
    "\n",
    "for fnum,(train_idx,test_idx) in enumerate(folds):\n",
    "    train = df_temp.loc[train_idx].reset_index(drop=True).copy()\n",
    "    test  = df_temp.loc[test_idx].reset_index(drop=True).copy()\n",
    "\n",
    "    # preprocess (train-only impute/scale), note tcol uses 'gain_temp'\n",
    "    prep = fold_aware_preprocess(train, test, covariates=covariates_to_use,\n",
    "                                 idcol='iso3c', ycol=Y_col, tcol='gain_temp',\n",
    "                                 imputer=KNNImputer(n_neighbors=5), scaler=StandardScaler(),\n",
    "                                 include_country_fe=False, save_prefix=None)\n",
    "\n",
    "    X_train = prep['X_train']; X_test = prep['X_test']\n",
    "    y_train = prep['y_train']; y_test = prep['y_test']\n",
    "    t_train = prep['t_train']; t_test = prep['t_test']\n",
    "\n",
    "    # year dummies fitted on train\n",
    "    yrs_train = pd.get_dummies(train['year'], prefix='yr')\n",
    "    yrs_test  = pd.get_dummies(test['year'], prefix='yr').reindex(columns=yrs_train.columns, fill_value=0)\n",
    "    yrs_train = yrs_train.reset_index(drop=True); yrs_test = yrs_test.reset_index(drop=True)\n",
    "    X_train_fe = pd.concat([X_train.reset_index(drop=True), yrs_train], axis=1)\n",
    "    X_test_fe  = pd.concat([X_test.reset_index(drop=True), yrs_test], axis=1)\n",
    "    X_test_fe = X_test_fe.reindex(columns=X_train_fe.columns, fill_value=0)\n",
    "\n",
    "    # drop rows with missing y or t on train\n",
    "    train_mask = (~y_train.isna()) & (~t_train.isna())\n",
    "    if train_mask.sum() < max(10, int(0.05 * len(train_mask))):\n",
    "        continue\n",
    "    train_pos = np.where(train_mask)[0]\n",
    "    Xtrain_sub = X_train_fe.iloc[train_pos, :].copy()\n",
    "    ytrain_sub = y_train.iloc[train_pos].copy()\n",
    "    ttrain_sub = t_train.iloc[train_pos].copy()\n",
    "    if np.nanvar(ttrain_sub) == 0:\n",
    "        continue\n",
    "\n",
    "    # fit p(X) and m(X)\n",
    "    p_model = LassoCV(cv=5, random_state=random_seed).fit(Xtrain_sub, ttrain_sub)\n",
    "    m_model = RandomForestRegressor(n_estimators=200, random_state=random_seed).fit(Xtrain_sub, ytrain_sub)\n",
    "    p_hat_test = p_model.predict(X_test_fe)\n",
    "    m_hat_test = m_model.predict(X_test_fe)\n",
    "\n",
    "    # keep test rows where both y and t observed\n",
    "    test_mask = (~y_test.isna()) & (~t_test.isna())\n",
    "    if test_mask.sum() == 0:\n",
    "        continue\n",
    "    test_pos = np.where(test_mask)[0]\n",
    "    index_keep = test.index[test_pos]\n",
    "\n",
    "    p_hat_kept = p_hat_test[test_pos]\n",
    "    m_hat_kept = m_hat_test[test_pos]\n",
    "    u_hat = y_test.to_numpy()[test_pos] - m_hat_kept\n",
    "    v_hat = t_test.to_numpy()[test_pos] - p_hat_kept\n",
    "\n",
    "    u_list.append(pd.Series(u_hat, index=index_keep))\n",
    "    v_list.append(pd.Series(v_hat, index=index_keep))\n",
    "\n",
    "# stack residuals and estimate theta + cluster SE\n",
    "u_all = pd.concat(u_list).sort_index()\n",
    "v_all = pd.concat(v_list).sort_index()\n",
    "\n",
    "theta_placebo_calc = (v_all * u_all).sum() / (v_all**2).sum()\n",
    "print(\"Placebo theta (calc):\", theta_placebo_calc)\n",
    "\n",
    "# OLS for cluster-robust SE (cluster by iso3c)\n",
    "res_placebo = sm.OLS(u_all.values, v_all.values).fit(cov_type='cluster', cov_kwds={'groups': df_temp.loc[u_all.index,'iso3c']})\n",
    "print(res_placebo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8614fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead thetas: {0: 0.3466555825510748, 1: 0.3850055098700622, 2: 0.3935410222940255}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAE/CAYAAADPKCMMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7sUlEQVR4nO3dB3gU1doH8JeEkEIv0kUQJHSQjvSrFxG5fogocAkCEsSrggKiqIgIXkFBkSIgCoIgokiz0BSB65VLb0pTekR6QgjpZb/nf2DG3c3uZibZyWaT/+95luzOnt09e3aYd06ZcwrZbDabEBERkSEBxpIRERERMHASERGZwMBJRERkAgMnERGRCQycREREJjBwEhERmcDASUREZAIDJxERkQkMnEQWsmp+key+r5XznXAuFSooGDjJ7/Tv31/dfGnMmDHyt7/9zWOa2bNny/z5873+2cuXL5e3337b9Ouc8zNz5kwJDw/3aZ6ceTNP9lauXKne948//pC8sn+Q/2LgJLLI9OnTJTEx0evvO2fOHLl27VqeyU9O8kTkjxg4iYiITGDgpHxr9+7dEhERIY0bN5aWLVvKSy+9JNHR0Q5pdu3aJYMHD5YWLVpIgwYNVPMamgszMjL0NLGxsfLyyy+r90C6KVOmODzvitbcOGvWLIemx99++02GDh0qTZs2VbdnnnlGoqKiHF67aNEi6dq1qzRs2FDat28v48ePlxs3bqjnkL9z587JqlWrHJoecR/Ng2bzA1u2bJGHHnpIfd79998vq1evdngeNclx48bJPffco9I89thj8r///U9/3l2ejJStOz/88IPKCz7v0Ucf1T8vLS1N2rVrJ6NGjcr0mi5dusjYsWPFH/YP8m8MnJQv4YA3cOBACQkJkffff19eeeUV2blzpzz++OOSlJSk0hw9elSlKVWqlEybNk01NzZv3lwFl3Xr1qk0OABGRkbK1q1b1YF18uTJsnfvXlm7dq3Hz//iiy/U3169eun3T506JX369JGrV6+q/sB///vfKmj27dtXbYNvv/1WHXj79eun+iMRWNesWSMTJ05UzyNvt912m3Ts2FG9b/ny5fXPe/rpp03lR4OgiHLA969YsaIKwCgbSE5OlgEDBsimTZtkxIgR6vORBmWiBTNXeTJStp68+uqr6rdCkCpatKgMGTJEfvnlFylcuLD06NFDBVbtZAL27NkjZ86ckZ49e4o/7B/k57CsGJE/iYiIUDdPevfubevevbstLS1N33by5Elb3bp1bUuWLFGPV61aZYuMjLSlp6fraXC/WbNmttdee0093rx5s6127dq2rVu36mni4+NtrVq1snXu3NljHvC6GTNm6I9Hjhxpu+eee2xxcXH6tpiYGPV5kydPVo/xuffff79DntasWWP79NNP9cf43JdeeimLUso6P7jv/N3OnDmjti1atEg9/uKLL9Tj/fv362kyMjJs/fr1s/Xs2dNtnoyUrStantatW6dvS0pKsrVt29Y2bNgw/XdEmq+++kpPM3bsWFuXLl3cvu+KFSvUa6KiovLM/kH+izVOyncwAObAgQOqBoRLJNC8h9vtt98uNWvWlJ9//lmlQ83lo48+ktTUVFW72LBhg8yYMUPS09PVNq05LygoSDWZasLCwtR7m7V9+3bVnIdajpanYsWKqVrMtm3bVJrWrVurmilqTqjZoJb1j3/8w9JRxPh8TdWqVdXf69evq7+oVaI2Wb9+fT3PKJ/OnTvLr7/+qpopXTFStu6gvNHsqgkODpYOHTqoWiLUqFFDmjVrpmrigBoiaoBGa5t5df8g/1HY1xkg8jYc9NGEhoMebs5wINYOuGgCxQEYB04Ejbvvvls1B2rXJCIwoKmuUKFCDu+BYGIW+grRhOeqGa9MmTLqb7du3VTely5dqi4fQVNllSpV5IUXXlDPWQEHek1AwM1zae37I8+XL19WgdMVPFeyZMlM242UrTulS5fW86EpW7asHsy1Jmc0r54/f14108bHx6tA58/7B/kPBk7Kd9AnhgMZ+qcefPDBTM+Hhoaqv+hjRC0CfVwY+KIFkDZt2jgcxGNiYlQtIzAwUN+enUsvihcvrj5n0KBBmZ7DwVjTvXt3dYuLi5P//ve/6uA+evRoVcuqUKGC5CbkuXr16jJ16lSXz2s1VGdGytYdfG8EJvtgdOXKFf3kAjB46s0335T169erWl/btm0Nl01e3T/If7CplvIdNH/Wq1dPTp48qUZlare77rpL1eB27Nih0qGm0qpVK7nvvvv0gyKaHzGyUhsViYMkahsYjKJJSUnRm/M8ca41oZn2+PHjUrduXT1PGKm5cOFC+f7771Wa559/Xg0I0oLWAw88oAb9IA+XLl1y+b5GZed1yDNqdajx2Zclvv/HH3+sBwvn9zZStp6aUtGsrUFtEiN/8X4avCdq4BhMhbwYbabNS/sH+S/WOMkvXbhwQQUcZ7Vr11a1g5EjR8qTTz6pLlvApRaoESxYsED1bWmjTxs1aqT6xj7//HPVt4V+LIycRG1EmygAB0Zc/oDLHDDyFc2mn376qTp4Iph4UqJECTXCEn1z6EfE52JULS5HwUhaNAliFCoOuug70/o4X3/9dTXqFv16aFZEXydqfXXq1NHf9/Dhw2oUKL4D+kz379+vamTVqlUznB8jEJCWLFmiaslPPfWUVKpUSfXHohaMSznQv+cqT0bK1h28J5ph8RsiyM2bN081mzqPGkZzbe/evVVTMYKbGXlh/yD/VQgjhHydCSIzMFAGB2hXcDBFE5s2sAVBB7UEHIzRTzds2DA9aKA5DX1YaA5FLQHNjrhmELXCH3/8UV1igBoVDpJoqvzuu+/U5Rmo6aAGgks0kM6dTz75RPVTYiAJ+jUrV64shw4dUpc2IIDhvx4CPQ7g9957r/66xYsXy7Jly9T1kAiKODijqRYHZUAt66233lJNmvgMfB9cP/nwww+ryyGM5mfFihWqfI4dO+aQDu/17LPPqrICBIR3331X1frwmcgHyvmJJ57Qa5rOeapVq5ahsnWGGh+m73vxxRflvffeU32ouM4S10m66mdFjRC/B042sppyD++B30xrXvb1/kH+i4GTiPwSaoeYjAGDd7TaOFFuYFMtEfkV9EHihhmO0EzKoEm5jYODiMivYBQrmoPLlSunRtYS5TY21RIREZnAGicREZEJDJxEREQmMHASERGZUOBH1e7bt09dT6ddyE1ERAVTamqqmuACcxJ7UuBrnAia3hgfhffARdIca2UNlq+1WL7WYvn6R/kajQcFvsap1TQxV2VOJCQkyJEjR9SMKfarTZB3sHytxfK1FsvXP8oXy/gZ4fMaJyZLxjydWM+uSZMmaqX3qKgoQ6/9+uuv1fRgmJqMiIgoN/g8cGLuTKw9iDkhMT8nAmlkZKSqdnty7tw5mTBhQq7lk4iIyOeBE8ERKxIMHz5cOnXqpKbOwgTYWPli48aNbl+H4IpJr90trktERJQvAyeW6cFae/YLw2J5IqyVh6WP3Jk7d64a/YTlmYiIqOBKz7DJoVPR8svpBPUXj63m08FBqFkC1vizV758ef05ZwcPHlS11K+++kouXrzolXxgFBU6l3NCW58vq7UGKXtYvtZi+VqL5WuNHYcuysK1xyT6erJ6vGJbtJQp8asM7BYurepXyFYswOUoeTpwajtRkSJFHLZjgd/Y2NhM6RHcXnjhBXXDwr7eCpyovWJEljecPn3aK+9DrrF8rcXytRbL13sORyXKlz9dzbQdQfS9ZQflsfZlpd7toabf1zke5bnAiUV6tb5O7T5gMdjQ0MxfGCsh1KhRQ/r06eP1S1IwjDmnJwH4T4GA7irvlDMsX2uxfK3F8vWujAybzPj2J49pNh28IQ/fd7cEBGRdg9RgkXIjfBo4tSbaS5cuSbVq1fTteIzLTJxhxXqcDWizOqSnp6u/3bt3l6eeekrdsgNVc29dW4X/FLxOyzosX2uxfK1V0MvXZrNJWrpNUtPSJTUtQ9LSM9Rf+/tGtkVdjNObZ925Gpsspy4kSsNa5Qznz0gzrc8DJ0bRFitWTC1KqwXO69evy+HDhyUiIiJTeueRtlgBHqNr582bJ7Vr1861fBPlx8EVh04nSEZItDStGyqBJs7SKe8FJ9TI3AUhh/vpGZKWZn8/3XG7FriyuJ/m8B6Z76el430RNDNytSyirydZ8r4+DZyoPSJATp06VcqUKSNVqlSRKVOmSMWKFaVLly6qRhkdHS3FixdXTbl33HGHw+u1AUSVK1eWUqVK+ehbEPmvbQf/lHmrf5GrsUn64IqyJQ/Jkz0ayj2NKvs6e3maCk72gUIPSOmZalU34hPlVFSiRKdekIDAwoZrWg7P6wErXdLS8Nm33t9FwPKXmf0CCokULhwoQYUDJCgwQArb/3W6Xzjwr21xCSmy77fLWb5/mRJ/dQF6k8+n3MM1nGlpaTJ27FhJSkqSFi1ayPz581W/I2YEuvfee2XSpEnSs2dPX2eVKN8FzUmLMl/2hSCK7S8PaOHz4HmzaS+LgJKt5/8Kbm6DUBY1rOxd9pB5MEtuCHIKPnoQcnP/r22BUjiwkMPfIHev8RTs3Lxndls2UPaD39yon/C5Uq5UqNS7s6zky8AZGBiomltxc1a1alU5duyY29e2atXK4/NE5P7Ag5qmJ3NXHpRKZYuqtO6b+Zya9kwEnrzYtJcTN4OB6+ATUMgmqSnJUrx4UQkpEmQgYHkITup+oBQuXEiCAm/99RDQEJyM9t35i8CAQqpVxNWJn2bI/zWwrMvB54GTiKyvtd1ITJXLMYly5VqiXI5JkMOnrno8W4eYuGQZ/t4WyUswQjKrQJOd2lRQYKHMTYbO9z28d2BAgMfRm9ok5HXr1i3Qg4O8Ca0haBWx72rQapoImla2ljBwEvm5lNR0uRKb+FdgVMHxZoDUtiel3ByBblZocKCEhQQZCz45DWh6bUq7n7k2xUFLZA/BsVWDSrL3yDk5dPSU1K9TQ5rWrWL5fsLASZTHB6DE3kj+KxiqwJig30egvBbneVi+plSxYClXKkRuKx0mOKxs++V8lq957YnWpobzE+U2BMn6NcpIQNJFqVujTK6cXDFwEvlQQlKqYy3xVjC8eT9BrlxLMtTPF1wkUG4rFaqaqfAXwfE2/X6olC0VKsFBgXlmcAWRP2PgJLIIAl50bNKtWuLNplPHwJgo8YmpWb4PTqAxrB7B8K/AePOvelw6TIqHBZkaAOLrwRVE/oyBkyibA27iEjDgJsFNjTFBXXxt5IqFoqFBejB0VWMsUzJE9e/lp8EVRP6MgZPI3YAbh35FpxrjtURJNjDgBgNnbgbDMKfA+FeNEYNvCtrgCiJ/xsBJBXLAzTUMuLkVCB1Ho97cFnsjxfiAm9KOwVALkrhfsliwqUmmC8rgCiJ/xsBJ+XLAjcMoVKfm1KuxiWrWGCMDbsqjlljyVtOpQ7/ize1F7AbcEFHBwMBJfjfg5mL0rUBoV2O071uMT0ozNuAGAdGp6VQfgFM6VIqFmhtwQ0QFAwMn5akBN9fjUzKNPEUwvBQdL+ev3JAbSX8YmsAaQe9mMEQgvDki1X4ATtkSIRJowYAbIsr/GDgp1yTrA260GqPjaFTcMCgnKxhhmnkUquMAnNBg7tpEZA0eXchrA25i4pLspntLvDXd218jUQ0PuCke7BAMEQhLhgVIXMwFad6kjlQsVyrPD7ghovyLgZMMwYX6ziNP7WuLV68lGlpmKQQz3NjVDu0H22jNqpib1PUk2dFqFCuDJhH5EgMnqWWcMNLU3YX8uJ9gZMBNQCEpWzLk1ihUpwv5bz3Gxf4ccENE/oyBs6AMuHEzQTjuo4nVyIAbTOumNZ3+FRi1fsYwKVMimANuiCjfY+D0AjRRHjoVLYdOJ0hGSLQ0rRuaaxeRJ6Wk6QHQscb41wCclLSsJwnHsk3aQBv7plP75lQOuCEiYuDMsW0H/3SY63PFtmgpW/KQmkA7p3N9IiBfw4CbW4NtXNUYUZs0ojQG3DiNPLWvMZYsyr5DIiIjGDhzGDRdrS6BIIrtmEDbXfBEEyou1He+kN9+AA7ex8iAGyw2XM6udug89Rv6HV0NuCEiIvMYOLMJAQ01TU/mrjqoBsMgAGo1Rfvm1MRkYwNuymHAjf0cqE6raBQNKcwBN0REuYSBM5sOn7zqcRFgiLmeLGPnbvOYpnhYEbsaouO1i7hfGjPcsAmViCjPYODMJqy1aPRi/jsqFnesMWoDcEqFSggH3BAR+RUetbOpTIkQQ+lejGguDWuVszw/RESUO3jRXTbVu7OsGnTjCWqVSEdERPkHA2c2od8Rl5x4MuT/GrB/kogon2HgzAFcaoJLTpxrnqhperoUhYiI/Bf7OHMIwbFVg0qy98g5OXT0lNSvU0Oa1q3CmiYRUT7FwOkFCJL1a5SRgKSLUrdGGQZNIqJ8jE21REREJjBwEhERmcDASUREZAIDJxERkQkMnERERCYwcBIREZnAwElERGQCAycREZEJDJxEREQmMHASERGZwMBJRERkAgMnERGRCQycRERE/hQ4MzIyZMaMGdK+fXtp0qSJDBkyRKKiotymP3TokAwYMEDuvvtuad26tYwbN07i4uJyNc9ERFRw+Txwzp49W5YuXSoTJ06UZcuWqUAaGRkpKSkpmdJeuXJFBg0aJFWqVJGVK1eq1+7Zs0fGjBnjk7wTEVHB49PAieC4YMECGT58uHTq1Enq1Kkj06ZNkwsXLsjGjRszpT937py0a9dOJkyYIDVq1JCmTZvKY489Jj///LNP8k9ERAWPTwPn0aNHJT4+Xtq0aaNvK1GihNSrV0927dqVKX3jxo3lvffek8KFb66/feLECVmzZo20bds2V/NNREQF180I5COoWUKlSpUctpcvX15/zp37779fTp8+rZptZ82alaN82Gw2SUhIyNF7JCYmOvwl72L5Wovlay2Wr3+UL2JBoUKF8nbg1L5kkSJFHLYHBwdLbGysx9dOnTpVvX7KlCny+OOPq5pn0aJFs5WP1NRUOXLkiHgDgjlZh+VrLZavtVi+eb98neNRngucISEhel+ndh+Sk5MlNDTU42sbNmyo/qK22bFjR/n++++lR48e2cpHUFCQ1KpVS3ICQRw/WvXq1bPMO5nH8rUWy9daLF//KN/jx48bSufTwKk10V66dEmqVaumb8fj8PDwTOlPnjwpZ8+eVQOJNBUqVJBSpUrJxYsXs50PVM3DwsLEG/Cjeeu9KDOWr7VYvtZi+ebt8jXSTOvzwUEYRVusWDHZsWOHvu369ety+PBhadGiRab027ZtUyNwkUaDQBoTEyM1a9bMtXwTEVHB5dPAibbkiIgI1V+5adMmNcp2xIgRUrFiRenSpYukp6fL5cuXJSkpSaXv3r27ql2OHj1afv/9d9m9e7cKpI0aNZLOnTv78qsQEVEB4fMJEBD4evXqJWPHjpW+fftKYGCgzJ8/X/U7nj9/Xl23uXbtWpUWQXPRokXqPtI+88wz6tIVpMfriIiIrObTPk5AwEMNEjdnVatWlWPHjjlsw8QHH374YS7mkIiIKA/VOImIiPwJAycREZEJDJxEREQmMHASERGZwMBJRERkAgMnERGRCQycREREJjBwEhERmcDASUREZAIDJxERkQkMnERERCYwcBIREfkqcCYkJMh//vMfb74lERGRf6+Ocu7cORk/frzs3LlTUlJSXKY5cuSIN/JGRETk/4Fz0qRJsnfvXnn00UfV39DQUGnSpIn8/PPP8ttvv8nMmTOtySkREZE/NtXu2rVLRowYoRae7tmzpwQHB6u1NFesWCEtWrSQTZs2WZNTIiIifwyc8fHxEh4eru7feeedcvjwYX1B6n/+85+yfft27+eSiIjIXwNn+fLl5cqVK+r+HXfcIbGxsXL58mX1uFSpUnL16lXv55KIiMhfA2fHjh3l/fffl3379kmVKlWkYsWKsmDBArlx44Zqrq1QoYI1OSUiIvLHwDl8+HApUaKETJ8+XT1Gf+eiRYtU/+Y333wjgwYNsiKfRERE/jmqtnTp0rJ8+XK5dOmSevzQQw9J5cqVZf/+/dKoUSNp2bKlFfkkIiLyzxrnrFmz5OLFi6qvU9O8eXOJjIxUAXTChAneziMREZH/Bs4PPvhABU5XDhw4oGqjREREBbqptk+fPioogs1mk969e7tN27BhQ+/ljoiIyB8D55tvvinr169XQRM1zkceeUSNprUXEBCgBg116dLFqrwSERH5R+CsVauWPPvss+p+oUKF1HR7vOyEiIgKItOjarUAeuLECTU/LUbX9u/fX6KioqROnTpSrFgxK/JJRETkn4ETzbWvvfaamuwA91EDfeCBB2T27Nly9uxZWbJkSaZmXCIiogI9qhYTHaDfEzVOBE/ARO8ZGRkybdo0K/JJRETkn4ETNU3MHoQBQpibVlO3bl21HcGUiIgovzIdODHBO4KkKxgwdP36dW/ki4iIKH8ETqyIsnXrVpfP7dy5Uz1PRESUX5keHDRgwAAZN26cpKamSufOndXgoDNnzsiOHTvUKiljxoyxJqdERET+GDhxDWd0dLTMmTNHPv/8czU4aOTIkRIUFKTmq+3bt681OSUiIvLHwAlDhw6Vfv36yd69e9VC1pgxqHHjxg6DhYiIiPKjbAVOwEQHHTp08G5uiIiI8lvgTExMlJkzZ8r27dslLi5OXbtpD32eP/zwgzfzSERE5L+Bc9KkSfLll19Ks2bN5K677lKTuxMRERUUpgPnhg0b5LnnnpN//etf1uSIiIgoDzNdXcRlKE2bNrUmN0RERPktcLZv3162bNliTW6IiIjyQ1Pt6tWr9fv169eXGTNmqOXE0M8ZFhaWKX2PHj28m0siIiJ/CpyuZgP67rvv1M0ZRtWaCZwYlTtr1ixZvny5GqXbokULNTPR7bff7jL977//LlOmTJEDBw6ogUlIj/xVrlzZ8GcSERFZGjg3bdokVsE6nkuXLpXJkyerdTwRFDEDEZYuK1KkiEPamJgYGTRokOpjXbx4saSkpKjXIf2qVaskODjYsnwSEREZ7uOsUqWKftu1a5dqnrXfpt0Q6NauXWu4ZBH4ML8tliPr1KmT1KlTR63neeHCBdm4cWOm9Lg+NCEhQd555x2pXbu2NGjQQAXaEydOqFmMiIiI8tzgoJdfflmioqJcPnfkyBHV/2nU0aNHJT4+Xtq0aaNvw/R99erVUwHaGdKhhhoSEvLXF7h1HSmXMyMiojzTVPvkk0+qWh1gUvdnnnkmUzMqXL16VapVq2b4w1GzhEqVKjlsL1++vP6cvapVq6qbvXnz5qlAir7O7MJ3Qk02JzCjkv1f8i6Wr7VYvtZi+fpH+SIWYJyOVwLnU089pQbvAPoSUSMsU6aMQxrU/FBb7Nmzp+FMal/SOQijrxKTx2cF/ZxLliyRsWPHZsqP2WtTUVv2htOnT3vlfcg1lq+1WL7WYvnm/fJ1VSnMVuDEYBz7SQ+efvppt6NezdCaXNHXad/8mpycLKGhoR7PCqZPn66WNsMMRv37989RPrAkWq1atXL0HjgJwI9WvXp1j3mn7GH5Wovlay2Wr3+U7/Hjx62bq9ZbtCZaXBNq38SLx+Hh4W5rh+hn/fbbb9XfgQMH5jgfqJq7uh41O/Cjeeu9KDOWr7VYvtZi+ebt8jXSTAs+naEdo2ixPNmOHTv0bRjkc/jwYbd9li+++KKsX79e3n33Xa8ETSIiolxZj9Mb0JYcEREhU6dOVX2UuKQFl5fges4uXbpIenq6REdHS/HixVVT7sqVK9XlLgieLVu2lMuXL+vvpaUhIiKyks/XBMM1nL169VIDfPr27SuBgYEyf/581e94/vx5adeunX5tKJpnAddxYrv9zcz1o0RERHmixnnw4EHZtm2bGoVrFALl6NGj1c0ZLj05duyY/hiTJRAREeWbGue+ffvUaFciIqL8yudNtURERP6EgZOIiMgEBk4iIiITGDiJiIi8PaoWM/R4c7oiIiKifB047Wf2yYrzSidEREQFLnD++OOP1ueEiIjID7CPk4iIyFd9nNrs8m+99ZaZPBAREeWvwInFqxEQK1SooBas9sayLERERPk2cD7wwAOyZcsWteB0165d5cEHH5RmzZpZnzsiIiJ/DJzTpk1TK2xv3rxZrUIyaNAgKVeunHTr1k0F0bp161qfUyIiIn9aHQUrayNQ4nbjxg35/vvvVRBduHChWsWke/fuKojWqFHD2hwTERH527JixYoVk4cffljdrl27poLounXrZO7cuVK7dm214DQREVF+lOPLUZKTk1UzblJSkqSnp8u5c+e8kzMiIqL8UuO8ePGirF+/Xt0OHDggYWFhct9998nQoUOlbdu23s8lERGRvwVO+2C5f/9+1efZuXNniYyMlPbt20uRIkWszSkREZG/BM6+ffuqmmVwcLB07NhRpk+frv7iMRERUUFiKHDu27dPAgMDpVatWhIdHS1LlixRN3cTICxatMjb+SQiIvKfwNmiRQv9vs1m85g2q+eJiIjyfeBcvHix9TkhIiLKr6NqMzIy1PWbULp0ac5PS0REBYapwPntt9/KsmXL1EChtLQ0tS0kJESaNm2qBhDhkhQiIiIp6IETExuMGjVKXYqCFVIwtR7mqkV/5oULF2Tnzp0ybNgw+b//+z+ZPHmy9bkmIiLKy4Fz6dKlsnHjRnn11VclIiIiU9MsAitqoliHs3nz5tKrVy+r8ktERJT3p9xbvXq19OnTR/r37++yPxOXqvTr108ee+wxtXYnERFRgQ6cp06dkg4dOmSZDjMI/fbbb97IFxERkf8GTkziXrJkySzTYYRtfHy8N/JFRETkv4ETg4DQHJvlmwUEcAIEIiLK13K8rBgREVFBYvg6zvHjx6sFrD25ceOGN/JERESUP+aqzaoZtmjRoupyFCIiovyKc9USERGZwD5OIiIiExg4iYiITGDgJCIiMoGBk4iIyAQGTiIiIhMYOImIiExg4CQiIvKnwJmRkSEzZsxQK6s0adJEhgwZIlFRUYZeFxkZKTNnzsyVfBIREeWJwDl79my1UPbEiRPVYthaQExJSXH7Gjz3yiuvyE8//ZSreSUiIvJp4EQAXLBggQwfPlw6deokderUkWnTpsmFCxdk48aNLl+zd+9e6dmzp+zevVtKlCiR63kmIqKCzaeB8+jRo2r9zjZt2ujbEAzr1asnu3btcvmarVu3qmbd1atXS/HixXMxt0RERCZWR7ECapZQqVIlh+3ly5fXn3M2YsQIr+cDk9cnJCTk6D2w2Lf9X/Iulq+1WL7WYvn6R/kiFhQqVChvB07tSxYpUsRhe3BwsMTGxuZaPlJTU+XIkSNeea/Tp0975X3INZavtVi+1mL55v3ydY5HeS5whoSE6H2d2n1ITk6W0NDQXMtHUFCQ1KpVK8cnAfjRqlevnqt5LyhYvtZi+VqL5esf5Xv8+HFD6XwaOLUm2kuXLkm1atX07XgcHh6ea/lA1TwsLMwr74UfzVvvRZmxfK3F8rUWyzdvl6+RZlqfDw7CKNpixYrJjh079G3Xr1+Xw4cP64tnExER5SU+rXGiLTkiIkKmTp0qZcqUkSpVqsiUKVOkYsWK0qVLF0lPT5fo6Gg1eta+KZeIiKjAToCAazh79eolY8eOlb59+0pgYKDMnz9f9TueP39e2rVrJ2vXrvV1NomIiHxf4wQEytGjR6ubs6pVq8qxY8fcvvbHH3+0OHdERER5rMZJRETkTxg4iYiITGDgJCIiMoGBk4iIyAQGTiIiIhMYOImIiExg4CQiIjKBgZOIiMgEBk4iIiITGDiJiIhMYOAkIiIygYGTiIjIBAZOIiIiExg4iYiITGDgJCIiMoGBk4iIyAQGTiIiIhMYOImIiExg4CQiIjKBgZOIiMgEBk4iIiITGDiJiIhMYOAkIiIygYGTiIjIBAZOIiIiExg4iYiITGDgJCIiMoGBk4iIyAQGTiIiIhMYOImIiExg4CQiIjKBgZOIiMgEBk4iIiITGDiJiIhMYOAkIiIygYGTiIjIBAZOIiIiExg4iYiITGDgJCIiMoGBk4iIyAQGTiIiIn8KnBkZGTJjxgxp3769NGnSRIYMGSJRUVFu08fExMioUaOkRYsW0rJlS3njjTckMTExV/NMREQFl88D5+zZs2Xp0qUyceJEWbZsmQqkkZGRkpKS4jL98OHD5cyZM7Jw4UKZPn26bN26VcaPH5/r+SYiooLJp4ETwXHBggUqGHbq1Enq1Kkj06ZNkwsXLsjGjRszpd+3b5/s3LlT3n77balfv760adNGJkyYIGvWrJGLFy/65DsQEVHBUtiXH3706FGJj49XAVBTokQJqVevnuzatUu6d+/ukH737t1y2223Sc2aNfVtaK4tVKiQ7NmzR7p165atfNhsNklISHD5XEBAgISEhOiP3aXD9uTk5Ezb3EGeQ0ND9cdobkY+cjMthIWFZSttUlKSah3wRlrkF/kGlGF6enqmNChLvI99/tyl1eB3w++nnaSlpaV5JW1wcLAEBgaaTpuamqpu7hQpUkQKFy5sOi0+310LDQQFBambp7Ra+dp/JsrWeZ+2h89HPsymxb6Az/JGWpQtyhiwb3jqtjGT1uj/e6NptfLFzf7/Bo8R3jlGaOWLv0aOJ+7+3+O7aa/Ns4ETNUuoVKmSw/by5cvrz9lDrdI5Lf6DlSpVSs6fP5/tfKBP9YEHHnD5XMeOHeXjjz/WHzdq1Mjtf7gGDRqoZmf7oI4+WVcaNmwoK1eu1B+jxn3u3DmXaWvVqiXr1q3THyOvx48fd5m2SpUqsmXLFv1xz5495ZdffnGZtnTp0qoGr+nXr5/DY3vYGQ8ePKg/RnM6msnd+f333/X7w4YNk/Xr17tNe+DAAf0/0YsvviirVq1ymxbfDd8R0ET/2WefuU27efNmqVq1qro/efJkmT9/vtu0a9eulbvuukvdR5/7zJkz3aZdsWKF2g/go48+knfeecdt2iVLlkirVq30++iTd2fevHnSuXNn/TPGjBnjNi3yqO2z2DfQauMOvvsjjzyil8mTTz7pNu0rr7wigwYNUvd37NghERERbtPit8KYBMC+oX2GK9gHtDxi3/B0kjt48GD9u//xxx96mbiCfVbrqrl69aq0bt3abdqHH35Y/61wgG3cuLHbtF27dnXYB7R9I6fHiObNm8vnn3+uP+YxwvvHiO3bt0vZsmWzdYzA/9Vq1apJng6c2s6lnV1qcFYYGxvrMr1zWi29p7PdnECN+MiRI/pjT2dFcPr0af2+pzMdfBf79/VUu8B3s0/r6bvifezTejqrRv7s03o6+8X3tk+LcvHEPu3169c9pj127Jh+xu7qd3c+ydHez90BR4MDR1xcnLofHR3tMe3Jkyf1muPly5ez/I21GtylS5c8pkV/PFpRwNXJoPN308otqxNBBBQtLe57gvfS0noaeKcFHy0t8u4JvruW1n6/dwVlqqU9e/asx7T4rbS0WXXBYB/Q0ma17+B5La2nWixgH7Pfh711jMDn2qflMcL7xwgEZO3/pTePEfYK2TzVuy22YcMGdRaKswn7po7nnntOVZvnzJnjkB4DiHBGs3z5coftaOodOnSoDBw40HQecKaFH1yrxXhq3vG042Dnw0EpPDxcbwYx07xjVTOMN5tL7NNm1QRiJq2RphV8ZxxwUb7ae7Op1ntNtVr5ohtEC/QFuanW6P97o2m18q1evbqqxRl5Xx4jjB8jtPJFbbFMmTLZbqrFySIeo7afZ2ucWrMrzg7sq8d4jAOks4oVK8oPP/zgsA1f9tq1a6p5N7tQUOXKlTOU1v7Htof/AMg3fmAtjbu0Zt6XaR3LF8/7a/nmZVr5Imjaf6fixYsbfg8zaYsVK2ZJ2qJFi1qSNqf7hFa+CJr2z+eF/TI/pE24Vb5oos1J+WbVIpMnRtViFC3+U6Avxb7KfvjwYXWdpjNsQ3OXfROS1t7erFmzXMo1EREVZD6tcaI5BoMPpk6dqqrXaC6dMmWKqll26dJFVbHR7owzWVSp0ZnftGlTGTFihOr0xVnGuHHjpEePHlKhQgVffhUiIiogfD4BAvo4e/XqJWPHjpW+ffuq/gKMfkSfDAY1tGvXTo14BLRbz5o1S42CGjBggDz//PPSoUMHToBAREQFo8YJCJSjR49WN2cIkBhNZQ9t2BiKT0REVCBrnERERP6EgZOIiMgEBk4iIiITfDoBQl6wd+9edaGwqxmJzMB74IJ1DGoyMtchmcPytRbL11osX/8oX8wLgNfj6o08PTjI17y1E+N9chp8yT2Wr7VYvtZi+fpH+eJ9jMSEAl/jJCIiMoN9nERERCYwcBIREZnAwElERGQCAycREZEJDJxEREQmMHASERGZwMBJRERkAgMnERGRCQycREREJjBwEhERmcDASUREZAIDJxERkQkMnAZlZGTIjBkzpH379tKkSRMZMmSIREVFuU0fExMjo0aNkhYtWkjLli3ljTfekMTExFzNc34u36+//lrCw8Mz3f74449czbc/+vDDD6V///4e03D/tbZ8uf+ac+3aNRk3bpx06NBBLfnVt29f2b17t9v0KMehQ4eqtO3atZP3339f0tPTxVsK/LJiRs2ePVuWLl0qkydPlooVK8qUKVMkMjJSvvnmG5fL2QwfPlwdaBYuXCjXr1+XV199VRISEuTtt9/2Sf7zW/keO3ZMHdDfe+89h+1lypTJxVz7n88++0wdRJo3b+4xHfdfa8uX+685I0eOlMuXL6vyKlu2rCxevFgGDx4sq1atkjvvvNMhLdblxHPVq1eXZcuWydmzZ9X+GxAQoPZrr8CyYuRZcnKy7e6777Z99tln+rbY2Fhbo0aNbN98802m9Hv37rXVrl3bdvz4cX3bTz/9ZAsPD7dduHAh1/KdX8sXIiMjbRMnTszFXPo37HdDhw61NWnSxNa1a1dbRESE27Tcf60tX+D+a9zp06fV/rh79259W0ZGhu2+++6zvf/++5nS45jRoEED27Vr1/Rty5YtszVt2lQda7yBTbUGHD16VOLj46VNmzb6thIlSki9evVk165dmdKjCeG2226TmjVr6ttwdokFUvfs2ZNr+c6v5audsduXL3l26NAhCQoKUk2EjRs39piW+6+15Qvcf40rXbq0zJs3Txo2bJhpwWm0hrjaf+vXry8lS5bUt7Vu3Vpu3LghR44cEW9g4DTgwoUL6m+lSpUctpcvX15/zt7FixczpUVzY6lSpeT8+fMW5zb/l29sbKwqY/wH+cc//qH6MJ5++mk5depUruXZ3/ztb3+TmTNnyu23355lWu6/1pYv919zcBLdsWNHhy6bDRs2yJkzZ9SYCGc4ZqC7x/lYAt7afxk4DdAGRTj3tQUHB0tycrLL9K765dylL+jMlu/vv/+u/tpsNpk0aZLqU0K6f/7zn3LlypVcynX+xf3XWtx/c2bv3r3y8ssvS5cuXaRTp06Znk9KSnJ5LAFv7b8cHGRASEiI+puSkqLf136E0NBQl+mR1hnSh4WFWZzb/F++GHjxv//9TzXhoLkGZs2apf4TrVy5Up588slczH3+w/3XWtx/s++HH36QF154QY2WnTp1quH9VwuY3tp/WeM0QGu2unTpksN2PK5QoUKm9GgmcE6LHxJDqrUmA8p++WqjD7WDDiDAVq1aVTWBUc5w/7Ue91/zlixZIsOGDZPOnTvL3Llz9Vqkkf1Xe+zueGIWA6cBderUkWLFismOHTv0beiUPnz4sLrOzRm2oZ0dbfCanTt3qr/NmjXLpVzn3/L94osvpFWrVuryCA06/k+fPi21atXKtXznV9x/rcX91zxcqjZx4kTp16+fuiTFVVeC/f6LYwfKVLN9+3YpWrSoOtZ4AwOnAfiRIiIiVNPApk2b1CjQESNGqDMbtLPjwlpcY4S2dcCoOjQlIM3BgwfVj4aLd3v06OG1M56CXL64CBoTJrz44ouqv+iXX35RZ6I4i+/Zs6evv47f4f5rLe6/OYNBU2+99Zb8/e9/V5MaoB8Y5YlbXFycag3Bfa159r777lOjwp9//nl1LEHzLoLtE0884THgmuKVi1oKgLS0NNs777xja926tbpWa8iQIbaoqCj1HP7iOqMVK1bo6a9cuWIbNmyYStuqVSvb66+/bktKSvLhN8hf5fvrr7/aBg0aZGvWrJm6Pgtl/eeff/rwG/iPl156yeE6Q+6/uV++3H+NmzNnjio/VzeU9fbt29V9/LW/9hPl27BhQ1u7du3U9Z7p6ek2bymEf7wTgomIiPI/NtUSERGZwMBJRERkAgMnERGRCQycREREJjBwEhERmcDASUREZAIDJ5EP+eJqsLx4BVpezFNewHLJmxg4KZP+/furmy+NGTNGLdVkxFNPPSXLly839LqTJ0+q512t4+cMM+bcf//90qBBA4mMjBRvQ57ffvttyS2YWQUzsHzzzTeSl8yePVvmz58vedkff/wh4eHhahJ2K2CGpgcffFBNCYfPwv6JmYWw9Jg384nJ5Bs1aiSjRo3iSjc5wMBJfg0HCEyM/cgjjxhKf+edd8q9994rb775ZpZp33nnHTU1GhbRHT16tHjbnDlz1MTpuQUTXS9atEjS0tIkL5k+fbq+tFxehcntMcesq2WsvFUGWNXjk08+UZ+FBZfXrFmj9j9v6tWrl/z73/+WtWvXyvr167363gUJAyf5Lcz9ifltUeMMCDC+K2PZpu+++04OHTrkMR2CGuZsveeee9RZPBVcmOO0SZMmaj5ZK5w9e1YtytymTRtD86miRQitK2Zh/mcsno25XLkoefYxcFK2oRkJk7NjUvCWLVvKSy+9JNHR0Q5pdu3aJYMHD1YrFqDJE82kM2fOdDiTjo2NVQvT4j2QbsqUKYbOtFesWKGam7DMkDtYJQHrHw4ZMkSfBBoHjdatW8uHH37osbnr3Llzsnr1anVfW7kFE3Lj+2B1CwRVBG1tYWJAOqRftmyZyhfS/Pzzz5k+A+WA91+1apVKj89E7blevXqqCbdt27aqPI4fP67SY6JqTADesGFD9RxqzPara2hpsBjy3Xffrcq6a9eu8tlnn+nfCTVtQFlrzdk4+OL7oDaFybHRjNenTx81sfbmzZvVQRa/76OPPqpqQWZ+f+37HDhwQHr37q3yjjKxb5bVTkjQhOju5ET7PdzdsupWQBl369ZNff5DDz2k1sJEvuybM7PaT52bQI18NzPQCqAFTOxDjz/+uLqPvznpNkEfKX5v/K7//e9/9e1BQUEu11wlY7iQNWULDjSDBg1SAQgr2CP4obkJ/9G/+uor1eyElQkGDhyoDuDTpk1T/4nRv4aDJJpM0aeDAxP6DxFEcOAtVaqUfPzxxypAZbX249dff62aztydoZ84cUIdDHFg/+CDDxzSIU9vvPGGxMfHq+WGXDXLPfvss+rg+PTTT6vlntDnibwiaKKvEEEbwReB5ssvv5SaNWvq74HvOHbsWFUrRiBzhudR89XeX/uuWEljwYIFqjktJiZGvSfKDIv3IohhxQeUFcoTQRVNe1jXccuWLfLMM8+o8sdKG/hcLMU0YcIEFQjq1q2rPhPf6V//+pdadUazb98+1YyLIIrvNH78eJU3vO/w4cPVWpGvv/66ygNq6kZ/f8DvizxjP8BfPIcm8Nq1a6saFsoZgQdNiAjOrmi/hztYks4dnPjge+G9EUDQl4jyRjlrjOynrmT13cxAn6b2PerXr69Wo8Fvh7/Y38C+iR15xE3bht8qMDAw0/viBOvbb79V+3+7du307SVLllQri1A2eW26eMo3sLKD/eoOrvTu3dvWvXt3taqJ5uTJk7a6devalixZoh6vWrXKFhkZ6bAqAe5jRYjXXntNPd68ebNa2WDr1q16mvj4eLUiR+fOnd1+flxcnPqsTz75xGE7VkvA686ePatWRRg4cKDLVT2OHDmiPnfLli1uPwPvg/fT9OrVy9atWzeH7xwbG2tr2bKlbfjw4eqxtlLDBx984KH0XL8/Vs/Aa1evXq1vy8jIsHXo0ME2ePBgh9du27ZNpUX5wUcffeTwXhATE6PSfPjhh25X6cBrsO348eP6tnHjxqlt+AzN/Pnz1TZ8X6O/v/Z9vvzySz1NcnKyWrFiwoQJ+jakmTFjhs0KnTp1sg0dOtRhG8rDvhyM7KfOZWf0u2UFr1m6dKmtfv36thMnTujbXa344W6FENy0/yv2+Zw6dap6X20fsYfyRtngd8c+RuawxkmmYSAHmqhQm7M/67399ttVDQlNk1hwFus34oZaDJr+sDAymvtwtp+amqo396HZyP4MPSwsTDp27KhqNe6gfwbvU7Vq1UzPoRaJWgDW6ENTpauV4qtUqaI3wRmBZlHUglFjsz+zL1GihGqi27p1q0N61PCyy/61GAWMRaWxDqF9jQNNiqihoKxR69ZG/eK7o6zRZ4b8QlZNcqh92NeWy5Urp/6ipq5BS4BWM8LvZeT319jXuFHrRz+hczNzVjwNaHJX28L+9ueff8pzzz3nsB01yHfffVd/bGQ/dSen3w3dEp9//rnMnTtX1W49QY1WgxYA1MTRyqB9tj3s97/++qv6Xq4GNOF12K/QhI1aeU7214KIgZNMw8ETzVQfffSRujnTAhWaC7FqO0YH4sCHIIcDTeHChfXr09DEh4MyDn720A/pidbMhCDralAPDkLIJw5M6KtyhuZHsF8lPqvPQ561oGIP25ybvVzlyyj712qjbtGsjJszNLEC+hZxMEU/J8ryjjvuUH27Rq4FdNfU6e47GP39NVqzrQYDucxcn2jfP+sK+lcXL16cabvW31q2bFmH7c6/oZH91J2cfjf0X+IED4EcTbI4KXEH/agadC/g/439NntofkbTLJppBwwYoLoE7O3fv1+NrEVzcPXq1Q3nl25i4CTT8J8WB2fU6lz1/2hBCf10GzZsUH1gGJmqHYgxclBTunRp1ZeHs3v7WkNWl2ngdeDqekytnxR9oOivQzDBwBd72uu098lK8eLF1XfG6vPOcODTamTehhot4Jo+BAhXtUVA/yNqpwsXLlQHfdRA0DKAvldf/f7egpqVfW3LVX7cjSCFq1evOmx3fmxkP7VKtWrVVNBGC8K2bdtUS4s3oJaN/mb8Puhrx4Az+/9fn376qfos9C+TeRxVS6ahhoIzWByoccar3e666y5Vu9NGoO7Zs0edRSNoaQcjNB+hJqCNVsTBCWf5CG4aNC26Golqr0KFCupAgOYmVwdS3HBQwCUEqKk51wi111WuXNnQd0b+Mchm3bp1DgNL8L4YmNOsWTMxy8glNKg5o8aEWpd9WeP7o5aCUcNaWWPAD8pba7b7z3/+o/5qZe2qOdPK399b5YDvY/85zjd3TZwInAhM33//vcP2jRs3Ojw2sp9aCSdlOIFDeWpy+luhVo3aMAYX4bIrDCJzHjiHpnXKHtY4ySUEFtRenGHEIM7KR44cqUZeYgYSDPHXRoOi7wujFgFD4BFo0IeDvi80H+Gif9RWtAveETjRpISzYtQE0PeIs2EctJyb2OzhAIdLPXDQQ83H3QEZQROTI6DJFs1SGrwONSOtOdMIfFf06+F747IP9H9hcgQEeq2vyWxtEoFv586dqqxcwQF0xIgR6gCI++hPRW0Zs+1g4geMwAS8HiNB8RgBY+/evSpv9mWNAzTgcgz8HvZ9mGYZ+f3NlAPyiz5t/B7OzfbZpY0KRm0czdh///vf1T6IEab2AdvIfmo1BDn0T2u03wonZWhVwIxC9lw1TbuCWiVGC+OEBrNgacESzdNGrhcl1xg4ySUMLpk0aVKm7bhsAIETwQ7XrGHIPg5O6JvBQRtntqjlAS4DQHBBExiCC/qOcCkELqP48ccf9eZZvAcmMpgxY4YaoIEBC4899phs2rTJYx5xIMABAa9xNQAIcMBBkxXyhcs50CSm1cYwaMK5j8oTBHm8D/KJwIEDDw70mDYPtS2znnjiCXVZC4Kxc43AHi6lQA0azc+4LEM7aUCZaQfCyZMnqyY/3AD9VjhpQHO1Nm0baoq4hATvgcFMWdXqPTHy+xuFa2FxIoBrbdHvZrQVwAj85hisg7ziul/8Tq+++qq6abVLI/up1fD/wL5vFPns3r27GuTz008/qb7K7HrllVfUNZyvvfaafjKM7+StE5SCqBCG1vo6E0TZgdoAmtcwHR5GDxqF6yBR+0C/mfOgCcpfEHDwG9s356IWh1HKGAzkXJPzFQR4nMihBp8bcP0tRmJbMQdzQcA+TvJbaGrFxf6oTZipFaBJEc1XDJr5H2rcqMmiGRs1b9Q60WyLgVZWBk30jaLvPqubBs3mmKkJzehWzuiDLhg0SWNAntbMT+axxkl+DwdGXK6AGXyygkEROMvGNGxWjYSlvAMBAoOo0DSPfnMMmkETP5qX3Y3G9QZ0IaAZOyvojkDTMLpGMPsQ+lcxeMnV9cneyhcuIUIffXbmuqWbGDiJiLwMA7e0a2w9wfy3HKTjfxg4iYiITGAfJxERkQkMnERERCYwcBIREZnAwElERGQCAycREZEJDJxEREQmMHASERGZwMBJRERkwv8DskO9PKayo10AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute DML theta for lead 0 (current), lead1 and lead2 using the same function but minimal output\n",
    "def compute_lead_theta(k):\n",
    "    df_k = df.copy().reset_index(drop=True)\n",
    "    df_k[f'gain_lead{k}'] = df_k.groupby('iso3c')['gain'].shift(-k)\n",
    "    df_k = df_k.dropna(subset=[f'gain_lead{k}', Y_col]).reset_index(drop=True)\n",
    "    df_k = df_k.rename(columns={f'gain_lead{k}':'gain_temp'})\n",
    "    try:\n",
    "        theta_k = dml_theta_on_df_debug(df_k, covariates_to_use, n_trees_local=150, random_seed_local=random_seed, verbose=False)[0]\n",
    "    except Exception:\n",
    "        theta_k = np.nan\n",
    "    return theta_k\n",
    "\n",
    "leads = [0,1,2]\n",
    "lead_thetas = {k: compute_lead_theta(k) for k in leads}\n",
    "print(\"Lead thetas:\", lead_thetas)\n",
    "\n",
    "# quick plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(list(lead_thetas.keys()), list(lead_thetas.values()), marker='o')\n",
    "plt.xlabel('Lead (k) for treatment = gain_{t+k}')\n",
    "plt.ylabel('DML theta')\n",
    "plt.title('Lead test: theta by lead')\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed92c9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: artifacts/dml_results_full\n",
      "Files saved (manifest):\n",
      " - summary_overview.csv / .json\n",
      " - dml_regression_summary.txt\n",
      " - p_oos_r2_folds.csv\n",
      " - m_oos_r2_folds.csv\n",
      " - stacked_residuals_uv_all.csv\n",
      " - per_fold_artifacts.json\n",
      " - perm_thetas_clean.csv\n",
      " - oster_adjustments.csv\n",
      " - placebo_diag_df.csv\n",
      " - placebo_theta.csv\n",
      " - fold_models/ (copied from fold_output_dir)\n",
      " - dml_placebo_fold_diagnostics.csv\n",
      " - analysis_panel_snapshot.csv\n",
      " - env_versions.json\n"
     ]
    }
   ],
   "source": [
    "# Save a comprehensive results package for the DML project\n",
    "import os, json, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "OUT_DIR = \"artifacts/dml_results_full\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def safe_pickle(obj, path):\n",
    "    try:\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(obj, f)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Could not pickle to {path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def safe_csv(df, path):\n",
    "    try:\n",
    "        df.to_csv(path, index=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save CSV {path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def safe_text(txt, path):\n",
    "    try:\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(txt)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save text {path}: {e}\")\n",
    "        return False\n",
    "\n",
    "manifest = []\n",
    "\n",
    "# 1) main summary (if exists)\n",
    "try:\n",
    "    summary = {\n",
    "        'dml_theta': float(theta_hat) if 'theta_hat' in globals() else None,\n",
    "        'dml_coef': float(res.params[0]) if 'res' in globals() and hasattr(res,'params') else None,\n",
    "        'cluster_se': float(res.bse[0]) if 'res' in globals() and hasattr(res,'bse') else None,\n",
    "        't_stat': float(res.tvalues[0]) if 'res' in globals() and hasattr(res,'tvalues') else None,\n",
    "        'p_val': float(res.pvalues[0]) if 'res' in globals() and hasattr(res,'pvalues') else None,\n",
    "        'median_p_oos_r2': float(np.nanmedian(p_oos_r2_folds)) if 'p_oos_r2_folds' in globals() else None,\n",
    "        'median_m_oos_r2': float(np.nanmedian(m_oos_r2_folds)) if 'm_oos_r2_folds' in globals() else None,\n",
    "        'mde80': float(mde80) if 'mde80' in globals() else None,\n",
    "        'perm_pval': float(p_emp) if 'p_emp' in globals() else None,\n",
    "        'placebo_theta': float(theta_placebo) if 'theta_placebo' in globals() else None\n",
    "    }\n",
    "    pd.Series(summary).to_csv(os.path.join(OUT_DIR, \"summary_overview.csv\"))\n",
    "    with open(os.path.join(OUT_DIR, \"summary_overview.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    manifest.append(\"summary_overview.csv / .json\")\n",
    "except Exception as e:\n",
    "    print(\"Could not save main summary:\", e)\n",
    "\n",
    "# 2) Save DML regression text summary (statsmodels res)\n",
    "if 'res' in globals():\n",
    "    try:\n",
    "        txt = res.summary().as_text()\n",
    "        safe_text(txt, os.path.join(OUT_DIR, \"dml_regression_summary.txt\"))\n",
    "        manifest.append(\"dml_regression_summary.txt\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to save res.summary():\", e)\n",
    "\n",
    "# 3) Save per-fold nuisance metrics (p_oos_r2_folds, m_oos_r2_folds)\n",
    "if 'p_oos_r2_folds' in globals():\n",
    "    try:\n",
    "        pd.DataFrame({'p_oos_r2': p_oos_r2_folds}).to_csv(os.path.join(OUT_DIR, \"p_oos_r2_folds.csv\"), index_label=\"fold\")\n",
    "        manifest.append(\"p_oos_r2_folds.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save p_oos_r2_folds:\", e)\n",
    "\n",
    "if 'm_oos_r2_folds' in globals():\n",
    "    try:\n",
    "        pd.DataFrame({'m_oos_r2': m_oos_r2_folds}).to_csv(os.path.join(OUT_DIR, \"m_oos_r2_folds.csv\"), index_label=\"fold\")\n",
    "        manifest.append(\"m_oos_r2_folds.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save m_oos_r2_folds:\", e)\n",
    "\n",
    "# 4) Save stacked residuals (u_all, v_all) if present\n",
    "if 'u_all' in globals() and 'v_all' in globals():\n",
    "    try:\n",
    "        stacked = pd.DataFrame({'u_hat': u_all, 'v_hat': v_all})\n",
    "        stacked.to_csv(os.path.join(OUT_DIR, \"stacked_residuals_uv_all.csv\"))\n",
    "        manifest.append(\"stacked_residuals_uv_all.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save stacked residuals:\", e)\n",
    "\n",
    "# 5) Save per-fold artifacts list if present (per_fold_artifacts)\n",
    "if 'per_fold_artifacts' in globals():\n",
    "    try:\n",
    "        # try to save as JSON-friendly structure\n",
    "        pf = per_fold_artifacts\n",
    "        with open(os.path.join(OUT_DIR, \"per_fold_artifacts.json\"), \"w\") as f:\n",
    "            json.dump(pf, f, indent=2)\n",
    "        manifest.append(\"per_fold_artifacts.json\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save per_fold_artifacts:\", e)\n",
    "\n",
    "# 6) Save covariate manifest if exists\n",
    "if os.path.exists(\"artifacts/covariate_manifest.csv\"):\n",
    "    try:\n",
    "        os.replace(\"artifacts/covariate_manifest.csv\", os.path.join(OUT_DIR, \"covariate_manifest.csv\"))\n",
    "        manifest.append(\"covariate_manifest.csv\")\n",
    "    except Exception:\n",
    "        # if replace fails, copy instead\n",
    "        try:\n",
    "            df_cov = pd.read_csv(\"artifacts/covariate_manifest.csv\")\n",
    "            df_cov.to_csv(os.path.join(OUT_DIR, \"covariate_manifest.csv\"), index=False)\n",
    "            manifest.append(\"covariate_manifest.csv\")\n",
    "        except Exception as e:\n",
    "            print(\"Could not move covariate_manifest.csv:\", e)\n",
    "\n",
    "# 7) Save permutation results if present (perm_thetas_clean or perm_thetas)\n",
    "if 'perm_thetas_clean' in globals():\n",
    "    pd.Series(perm_thetas_clean).to_csv(os.path.join(OUT_DIR, \"perm_thetas_clean.csv\"), index=False)\n",
    "    manifest.append(\"perm_thetas_clean.csv\")\n",
    "elif 'perm_thetas' in globals():\n",
    "    pd.Series(perm_thetas).to_csv(os.path.join(OUT_DIR, \"perm_thetas.csv\"), index=False)\n",
    "    manifest.append(\"perm_thetas.csv\")\n",
    "\n",
    "# 8) Save Oster adjustments if present (oster_df)\n",
    "if 'oster_df' in globals():\n",
    "    try:\n",
    "        oster_df.to_csv(os.path.join(OUT_DIR, \"oster_adjustments.csv\"), index=False)\n",
    "        manifest.append(\"oster_adjustments.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save oster_df:\", e)\n",
    "\n",
    "# 9) Save placebo diagnostics and theta if present (diag_df, theta_placebo)\n",
    "if 'diag_df' in globals():\n",
    "    try:\n",
    "        diag_df.to_csv(os.path.join(OUT_DIR, \"placebo_diag_df.csv\"), index=False)\n",
    "        manifest.append(\"placebo_diag_df.csv\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if 'theta_placebo' in globals():\n",
    "    try:\n",
    "        pd.Series({'theta_placebo': float(theta_placebo)}).to_csv(os.path.join(OUT_DIR, \"placebo_theta.csv\"))\n",
    "        manifest.append(\"placebo_theta.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save placebo theta:\", e)\n",
    "\n",
    "# 10) Save per-fold model pickles if they exist in fold_output_dir (those were saved by earlier loop)\n",
    "if 'fold_output_dir' in globals() and os.path.exists(fold_output_dir):\n",
    "    try:\n",
    "        # copy all pickles and files in fold_output_dir to OUT_DIR/folds/\n",
    "        import shutil\n",
    "        dest_folddir = os.path.join(OUT_DIR, \"fold_models\")\n",
    "        if os.path.exists(dest_folddir):\n",
    "            shutil.rmtree(dest_folddir)\n",
    "        shutil.copytree(fold_output_dir, dest_folddir)\n",
    "        manifest.append(\"fold_models/ (copied from fold_output_dir)\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not copy fold_output_dir artifacts:\", e)\n",
    "\n",
    "# 11) Save DML diagnostics table if exists (diag_df from debug run or main per-fold diag)\n",
    "if 'diag_df' in globals():\n",
    "    try:\n",
    "        diag_df.to_csv(os.path.join(OUT_DIR, \"dml_placebo_fold_diagnostics.csv\"), index=False)\n",
    "        manifest.append(\"dml_placebo_fold_diagnostics.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save diag_df:\", e)\n",
    "\n",
    "# 12) Save the main data snapshot used for analysis (optional, may be large)\n",
    "if 'df' in globals():\n",
    "    try:\n",
    "        df.to_csv(os.path.join(OUT_DIR, \"analysis_panel_snapshot.csv\"), index=False)\n",
    "        manifest.append(\"analysis_panel_snapshot.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save data snapshot (might be large):\", e)\n",
    "\n",
    "# 13) Save environment/versions info\n",
    "try:\n",
    "    versions = {\n",
    "        'python': sys.version.replace('\\n',' '),\n",
    "        'pandas': pd.__version__,\n",
    "        'numpy': np.__version__,\n",
    "        'sklearn': None\n",
    "    }\n",
    "    try:\n",
    "        import sklearn\n",
    "        versions['sklearn'] = sklearn.__version__\n",
    "    except Exception:\n",
    "        pass\n",
    "    with open(os.path.join(OUT_DIR, \"env_versions.json\"), \"w\") as f:\n",
    "        json.dump(versions, f, indent=2)\n",
    "    manifest.append(\"env_versions.json\")\n",
    "except Exception as e:\n",
    "    print(\"Could not save env versions:\", e)\n",
    "\n",
    "# 14) Write README manifest\n",
    "readme_lines = [\n",
    "    \"DML Project - Results package\",\n",
    "    f\"Generated: {datetime.utcnow().isoformat()} UTC\",\n",
    "    \"\",\n",
    "    \"Files included (best-effort):\",\n",
    "]\n",
    "for m in manifest:\n",
    "    readme_lines.append(\"- \" + m)\n",
    "readme_lines.append(\"\")\n",
    "readme_lines.append(\"Notes:\")\n",
    "readme_lines.append(\"- summary_overview contains key scalars to inspect quickly.\")\n",
    "readme_lines.append(\"- dml_regression_summary contains the statsmodels OLS on residuals (clustered SEs).\")\n",
    "readme_lines.append(\"- stacked_residuals_uv_all.csv contains the u and v residuals used in the final orthogonal regression.\")\n",
    "readme_lines.append(\"- fold_models/ holds per-fold pickled nuisances (if they were saved during modeling).\")\n",
    "readme_lines.append(\"- analysis_panel_snapshot.csv is a CSV snapshot of the data used; remove if too large or sensitive.\")\n",
    "safe_text(\"\\n\".join(readme_lines), os.path.join(OUT_DIR, \"README.txt\"))\n",
    "\n",
    "print(\"Saved results to:\", OUT_DIR)\n",
    "print(\"Files saved (manifest):\")\n",
    "for m in manifest:\n",
    "    print(\" -\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "948d68cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap and SMD diagnostics saved to: artifacts/dml_pooled\n"
     ]
    }
   ],
   "source": [
    "# CELL 9 (UPDATED): Overlap & SMD plots (robust)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LassoCV\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Defensive copy\n",
    "ols_df = df[[idcol, timecol, Y_col, T_col] + covariates_to_use].copy()\n",
    "\n",
    "# 1) Coerce expected numeric covariates to numeric (errors -> NaN)\n",
    "# We'll treat the covariates_to_use as numeric candidates; convert them safely\n",
    "for c in covariates_to_use:\n",
    "    ols_df[c] = pd.to_numeric(ols_df[c], errors='coerce')\n",
    "\n",
    "# Also ensure outcome and treatment are numeric\n",
    "ols_df[Y_col] = pd.to_numeric(ols_df[Y_col], errors='coerce')\n",
    "ols_df[T_col] = pd.to_numeric(ols_df[T_col], errors='coerce')\n",
    "\n",
    "# 2) Mean-impute only numeric columns (for this diagnostic only)\n",
    "numeric_cols = ols_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_means = ols_df[numeric_cols].mean()\n",
    "ols_df[numeric_cols] = ols_df[numeric_cols].fillna(numeric_means)\n",
    "\n",
    "# 3) Build X_ov for p(X) overlap visualization: year dummies + numeric covariates\n",
    "year_dummies = pd.get_dummies(ols_df[timecol], prefix='yr').astype(float)\n",
    "X_ov = pd.concat([year_dummies.reset_index(drop=True), ols_df[covariates_to_use].reset_index(drop=True)], axis=1)\n",
    "# final safety: ensure no NaNs remain in X_ov numeric columns\n",
    "X_ov = X_ov.fillna(X_ov.mean())\n",
    "\n",
    "# 4) Fit a single p(X) (Lasso) on full sample for overlap approx (diagnostic only)\n",
    "try:\n",
    "    p_full = LassoCV(cv=5, random_state=random_seed).fit(X_ov, ols_df[T_col])\n",
    "    p_hat_full = p_full.predict(X_ov)\n",
    "    ols_df['p_hat_full'] = p_hat_full\n",
    "except Exception as e:\n",
    "    # fallback to simple linear model if LassoCV fails\n",
    "    print(\"LassoCV failed, falling back to OLS for p_hat. Error:\", e)\n",
    "    lm_px = sm.OLS(ols_df[T_col], sm.add_constant(X_ov)).fit()\n",
    "    ols_df['p_hat_full'] = lm_px.predict(sm.add_constant(X_ov))\n",
    "\n",
    "# 5) Overlap plot: density of predicted p(X) by treated vs control (above/below median of T)\n",
    "ols_df['treated_flag'] = (ols_df[T_col] >= np.nanmedian(ols_df[T_col])).astype(int)\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.kdeplot(data=ols_df, x='p_hat_full', hue='treated_flag', fill=True, common_norm=False,\n",
    "            palette=['C0','C1'], alpha=0.5)\n",
    "plt.title('Approx. overlap (density of predicted p(X)) by above/below median treatment')\n",
    "plt.xlabel('Predicted p(X)')\n",
    "plt.legend(title='T >= median', labels=['Control','Treated'])\n",
    "plt.show()\n",
    "\n",
    "# 6) SMD before/after residualisation\n",
    "# Choose covariates to show in SMD plot: take first 10 numeric covariates from covariates_to_use\n",
    "covariates_for_smd = [c for c in covariates_to_use if c in ols_df.select_dtypes(include=[np.number]).columns][:10]\n",
    "if len(covariates_for_smd) == 0:\n",
    "    raise ValueError(\"No numeric covariates available for SMD calculation. Check covariates_to_use.\")\n",
    "\n",
    "def compute_smd(df_in, treat_col, covs):\n",
    "    treated = df_in[df_in[treat_col] >= df_in[treat_col].median()]\n",
    "    control = df_in[df_in[treat_col] < df_in[treat_col].median()]\n",
    "    smd = {}\n",
    "    for c in covs:\n",
    "        m_t = treated[c].mean()\n",
    "        m_c = control[c].mean()\n",
    "        sd_pooled = np.sqrt((treated[c].var(ddof=1) + control[c].var(ddof=1)) / 2)\n",
    "        smd[c] = np.abs(m_t - m_c) / (sd_pooled + 1e-8)\n",
    "    return pd.Series(smd)\n",
    "\n",
    "smd_before = compute_smd(ols_df, T_col, covariates_for_smd)\n",
    "\n",
    "# Residualise each covariate on p_hat_full (approximate effect of adjusting for X)\n",
    "resid_df = ols_df.copy()\n",
    "for c in covariates_for_smd:\n",
    "    # regress covariate on p_hat_full and take residuals\n",
    "    try:\n",
    "        lm = sm.OLS(resid_df[c].astype(float), sm.add_constant(resid_df['p_hat_full'])).fit()\n",
    "        resid_df[c + '_res'] = lm.resid\n",
    "    except Exception:\n",
    "        # if regression fails (e.g., constant column), set residuals to zero\n",
    "        resid_df[c + '_res'] = 0.0\n",
    "\n",
    "smd_after = compute_smd(resid_df, T_col, [c + '_res' for c in covariates_for_smd])\n",
    "\n",
    "# Build SMD table and plot top 10 covariates by before-SMD\n",
    "smd_plot = pd.DataFrame({'before': smd_before, 'after': smd_after.values}, index=smd_before.index)\n",
    "smd_plot = smd_plot.sort_values('before', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "smd_plot.plot.bar(figsize=(10,5))\n",
    "plt.ylabel('Absolute Standardized Mean Difference')\n",
    "plt.title('SMD before and approx after residualisation (top covariates)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7) Save the computed p_hat_full and SMD table for record (if desired)\n",
    "save_dir = fold_output_dir if 'fold_output_dir' in globals() else \"artifacts\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "ols_df[['p_hat_full', 'treated_flag'] + covariates_for_smd].to_csv(os.path.join(save_dir, \"overlap_p_hat_full_sample.csv\"), index=False)\n",
    "smd_plot.to_csv(os.path.join(save_dir, \"smd_before_after_top10.csv\"))\n",
    "\n",
    "print(\"Overlap and SMD diagnostics saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10d0ee",
   "metadata": {},
   "source": [
    "# Attempt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e968b08",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a858a",
   "metadata": {},
   "source": [
    "\t1.\tRun Step 1 (lead tests k=0..3) and compute ND-GAIN autocorr. Post results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "662d7d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ND-GAIN lag-1 autocorrelation summary (per-country):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.855970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.233551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.816893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.824241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.922249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.963503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.990227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.922249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iqr</th>\n",
       "      <td>0.139262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gain\n",
       "count   67.000000\n",
       "mean     0.855970\n",
       "std      0.233551\n",
       "min     -0.816893\n",
       "25%      0.824241\n",
       "50%      0.922249\n",
       "75%      0.963503\n",
       "max      0.990227\n",
       "median   0.922249\n",
       "iqr      0.139262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell A: ND-GAIN autocorrelation by country (lag-1)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# compute lag-1 autocorrelation for each country\n",
    "autocorrs = df.groupby('iso3c')['gain'].apply(lambda s: s.autocorr(lag=1)).dropna()\n",
    "autocorr_summary = autocorrs.describe().to_frame().T\n",
    "autocorr_summary['median'] = autocorrs.median()\n",
    "autocorr_summary['iqr'] = autocorrs.quantile(0.75) - autocorrs.quantile(0.25)\n",
    "\n",
    "print(\"ND-GAIN lag-1 autocorrelation summary (per-country):\")\n",
    "display(autocorr_summary.T)\n",
    "\n",
    "# Save to CSV\n",
    "autocorrs.to_csv(os.path.join(fold_output_dir, \"gain_autocorr_by_country.csv\"))\n",
    "autocorr_summary.to_csv(os.path.join(fold_output_dir, \"gain_autocorr_summary.csv\"))\n",
    "\n",
    "# Quick histogram\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(autocorrs.dropna(), bins=30, edgecolor='k')\n",
    "plt.axvline(autocorrs.median(), color='red', linestyle='--', label=f\"median={autocorrs.median():.3f}\")\n",
    "plt.title(\"Distribution of country-level ND-GAIN lag-1 autocorrelation\")\n",
    "plt.xlabel(\"autocorr (lag 1)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73b01d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell B: helper to compute DML theta and cluster-robust SE (pooled, LOYO cross-fit).\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def compute_dml_theta_and_se(df_local,\n",
    "                             covariates_list,\n",
    "                             idcol='iso3c',\n",
    "                             timecol='year',\n",
    "                             ycol='sovereign_spread',\n",
    "                             tcol='gain_temp',\n",
    "                             n_trees=200,\n",
    "                             random_seed=2025,\n",
    "                             min_train_frac=0.05):\n",
    "    \"\"\"\n",
    "    Runs pooled cross-fitted DML (leave-one-year-out) and returns:\n",
    "      - theta (point estimate)\n",
    "      - cluster-robust OLS result on residuals (res object)\n",
    "      - u_all (pd.Series), v_all (pd.Series), groups (pd.Series of iso3c for u_all index)\n",
    "    Requires fold_aware_preprocess in the notebook.\n",
    "    \"\"\"\n",
    "    years = sorted(df_local[timecol].unique())\n",
    "    folds = [(df_local.index[df_local[timecol] != y].tolist(), df_local.index[df_local[timecol] == y].tolist()) for y in years]\n",
    "\n",
    "    u_list = []\n",
    "    v_list = []\n",
    "    groups_list = []\n",
    "\n",
    "    for fnum, (train_idx, test_idx) in enumerate(folds):\n",
    "        train = df_local.loc[train_idx].reset_index(drop=True).copy()\n",
    "        test  = df_local.loc[test_idx].reset_index(drop=True).copy()\n",
    "\n",
    "        # Preprocess: impute & scale on train only, no FE partial-out (pooled)\n",
    "        prep = fold_aware_preprocess(train, test, covariates=covariates_list,\n",
    "                                     idcol=idcol, ycol=ycol, tcol=tcol,\n",
    "                                     imputer=KNNImputer(n_neighbors=5),\n",
    "                                     scaler=StandardScaler(),\n",
    "                                     include_country_fe=False, save_prefix=None)\n",
    "\n",
    "        X_train = prep['X_train']; X_test = prep['X_test']\n",
    "        y_train = prep['y_train']; y_test = prep['y_test']\n",
    "        t_train = prep['t_train']; t_test = prep['t_test']\n",
    "\n",
    "        # Year dummies fitted on train\n",
    "        yrs_train = pd.get_dummies(train[timecol], prefix='yr')\n",
    "        yrs_test  = pd.get_dummies(test[timecol], prefix='yr').reindex(columns=yrs_train.columns, fill_value=0)\n",
    "        yrs_train = yrs_train.reset_index(drop=True); yrs_test = yrs_test.reset_index(drop=True)\n",
    "\n",
    "        X_train_fe = pd.concat([X_train.reset_index(drop=True), yrs_train], axis=1)\n",
    "        X_test_fe  = pd.concat([X_test.reset_index(drop=True),  yrs_test], axis=1)\n",
    "        X_test_fe  = X_test_fe.reindex(columns=X_train_fe.columns, fill_value=0)\n",
    "\n",
    "        # Use numpy arrays for masks; safe selection by positions\n",
    "        y_train_arr = y_train.to_numpy()\n",
    "        t_train_arr = t_train.to_numpy()\n",
    "        train_mask_arr = (~pd.isna(y_train_arr)) & (~pd.isna(t_train_arr))\n",
    "        n_train_ok = int(train_mask_arr.sum())\n",
    "        if n_train_ok < max(10, int(min_train_frac * len(train_mask_arr))):\n",
    "            # skip fold if too few usable train rows\n",
    "            continue\n",
    "\n",
    "        train_pos = np.where(train_mask_arr)[0]\n",
    "        Xtrain_sub = X_train_fe.iloc[train_pos, :].copy()\n",
    "        ytrain_sub = y_train.iloc[train_pos].copy()\n",
    "        ttrain_sub = t_train.iloc[train_pos].copy()\n",
    "\n",
    "        # require variation in t\n",
    "        if np.nanvar(ttrain_sub.to_numpy()) == 0:\n",
    "            continue\n",
    "\n",
    "        # fit p(X) and m(X)\n",
    "        try:\n",
    "            p_model = LassoCV(cv=5, random_state=random_seed).fit(Xtrain_sub, ttrain_sub)\n",
    "        except Exception:\n",
    "            from sklearn.linear_model import Lasso\n",
    "            p_model = Lasso(alpha=1.0).fit(Xtrain_sub, ttrain_sub)\n",
    "        p_hat_test_full = p_model.predict(X_test_fe)\n",
    "\n",
    "        try:\n",
    "            m_model = RandomForestRegressor(n_estimators=n_trees, n_jobs=-1, random_state=random_seed)\n",
    "            m_model.fit(Xtrain_sub, ytrain_sub)\n",
    "            m_hat_test_full = m_model.predict(X_test_fe)\n",
    "        except Exception:\n",
    "            m_ols = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "            m_hat_test_full = m_ols.predict(sm.add_constant(X_test_fe))\n",
    "\n",
    "        # test mask: require y_test and t_test present\n",
    "        y_test_arr = y_test.to_numpy(); t_test_arr = t_test.to_numpy()\n",
    "        test_mask_arr = (~pd.isna(y_test_arr)) & (~pd.isna(t_test_arr))\n",
    "        if test_mask_arr.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        test_pos = np.where(test_mask_arr)[0]\n",
    "\n",
    "        # predictions for kept positions\n",
    "        p_hat_kept = p_hat_test_full[test_pos]\n",
    "        m_hat_kept = m_hat_test_full[test_pos]\n",
    "\n",
    "        u_hat = y_test_arr[test_pos] - m_hat_kept\n",
    "        v_hat = t_test_arr[test_pos] - p_hat_kept\n",
    "\n",
    "        # groups for cluster (iso3c) - pick values from test DataFrame for kept positions\n",
    "        groups_kept = test.loc[test_pos, idcol].reset_index(drop=True)\n",
    "\n",
    "        # build Series indexed by a unique label: use cumulative counter index to avoid duplicates\n",
    "        # we will use incremental integer keys to avoid index alignment issues later\n",
    "        base_idx = len(u_list) * 10**6  # large offset to keep uniqueness (simple)\n",
    "        idxs = [base_idx + i for i in range(len(u_hat))]\n",
    "        u_list.append(pd.Series(u_hat, index=idxs))\n",
    "        v_list.append(pd.Series(v_hat, index=idxs))\n",
    "        groups_list.append(pd.Series(groups_kept.values, index=idxs))\n",
    "\n",
    "    if len(u_list) == 0:\n",
    "        return dict(theta=np.nan, res=None, u_all=None, v_all=None, groups=None)\n",
    "\n",
    "    u_all = pd.concat(u_list).sort_index()\n",
    "    v_all = pd.concat(v_list).sort_index()\n",
    "    groups_all = pd.concat(groups_list).sort_index()\n",
    "\n",
    "    # DML theta\n",
    "    theta = (v_all * u_all).sum() / (v_all**2).sum()\n",
    "\n",
    "    # cluster-robust inference: regress u on v, cluster by groups_all\n",
    "    res = sm.OLS(u_all.values, v_all.values).fit(cov_type='cluster', cov_kwds={'groups': groups_all.values})\n",
    "    return dict(theta=float(theta), res=res, u_all=u_all, v_all=v_all, groups=groups_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66274aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0: theta=0.346826, se=0.2812348209763999, t=1.2332248136467794, p=0.2174919000940182\n",
      "Lead 1: theta=0.375486, se=0.26426121167154176, t=1.4208878680965422, p=0.1553493604689083\n",
      "Lead 2: theta=0.374388, se=0.26844240928770957, t=1.394666680790342, p=0.16311637690748737\n",
      "Lead 3: theta=0.387155, se=0.2849786858848831, t=1.3585405748734805, p=0.17429221683149765\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lead results to: artifacts/dml_pooled/lead_thetas_k0_3.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell C: loop over leads 0..3, compute theta and cluster SE\n",
    "lead_results = []\n",
    "for k in [0,1,2,3]:\n",
    "    # create dataset with lead k: gain_{t+k} (future gain for k>=1); for k=0 use current gain\n",
    "    df_k = df.copy().reset_index(drop=True)\n",
    "    if k == 0:\n",
    "        df_k['gain_temp'] = df_k['gain']\n",
    "    else:\n",
    "        df_k['gain_temp'] = df_k.groupby('iso3c')['gain'].shift(-k)\n",
    "\n",
    "    # drop rows without treatment or outcome\n",
    "    df_k = df_k.dropna(subset=['gain_temp', Y_col]).reset_index(drop=True)\n",
    "\n",
    "    out = compute_dml_theta_and_se(df_k, covariates_to_use,\n",
    "                                   idcol='iso3c', timecol='year',\n",
    "                                   ycol=Y_col, tcol='gain_temp',\n",
    "                                   n_trees=200, random_seed=2025)\n",
    "\n",
    "    theta = out['theta']\n",
    "    res = out['res']\n",
    "    if res is not None:\n",
    "        se = float(res.bse[0])\n",
    "        tstat = float(res.tvalues[0])\n",
    "        pval = float(res.pvalues[0])\n",
    "    else:\n",
    "        se = np.nan; tstat = np.nan; pval = np.nan\n",
    "\n",
    "    lead_results.append({'lead_k': k, 'theta': theta, 'se': se, 'tstat': tstat, 'pval': pval})\n",
    "\n",
    "    print(f\"Lead {k}: theta={theta:.6g}, se={se}, t={tstat}, p={pval}\")\n",
    "\n",
    "# aggregate results to DataFrame and save\n",
    "lead_df = pd.DataFrame(lead_results)\n",
    "lead_df.to_csv(os.path.join(fold_output_dir, \"lead_thetas_k0_3.csv\"), index=False)\n",
    "\n",
    "# plot with error bars\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,3.5))\n",
    "plt.errorbar(lead_df['lead_k'], lead_df['theta'], yerr=lead_df['se'], fmt='o-', capsize=4)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.xticks(lead_df['lead_k'])\n",
    "plt.xlabel('Lead k (treatment = gain_{t+k})')\n",
    "plt.ylabel('DML theta')\n",
    "plt.title('Lead test: DML theta by lead (with cluster SE)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(os.path.join(fold_output_dir, \"lead_theta_plot_k0_3.png\"), dpi=200, bbox_inches='tight')\n",
    "print(\"Saved lead results to:\", os.path.join(fold_output_dir, \"lead_thetas_k0_3.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eea88f",
   "metadata": {},
   "source": [
    "A — Run lagged-treatment DML (gain_{t−1}) — High priority\n",
    "\n",
    "Why: uses pre-treatment exposure, removes mechanical persistence problem.\n",
    "What to run: the lagged DML cell I gave (CELL 1).\n",
    "Save: dml_lag1_summary.csv (theta, SE, p).\n",
    "What to paste here: the printed theta, SE, p from the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08daf4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagged treatment DML (gain_{t-1})\n",
      "theta_lag1 = 0.4607589973175241\n",
      "SE (cluster): 0.33710072376720807 t: 1.3668288580587884 p: 0.1716789551307546\n"
     ]
    }
   ],
   "source": [
    "# CELL: DML with lagged treatment (gain_{t-1})\n",
    "df_lag1 = df.copy().reset_index(drop=True)\n",
    "df_lag1['gain_lag1'] = df_lag1.groupby('iso3c')['gain'].shift(1)\n",
    "\n",
    "# drop rows with missing lagged treatment or outcome\n",
    "df_lag1 = df_lag1.dropna(subset=['gain_lag1', Y_col]).reset_index(drop=True)\n",
    "\n",
    "# rename for compatibility with helper (tcol = 'gain_temp')\n",
    "df_lag1 = df_lag1.rename(columns={'gain_lag1': 'gain_temp'})\n",
    "\n",
    "out_lag1 = compute_dml_theta_and_se(df_lag1, covariates_to_use,\n",
    "                                    idcol='iso3c', timecol='year',\n",
    "                                    ycol=Y_col, tcol='gain_temp',\n",
    "                                    n_trees=200, random_seed=2025)\n",
    "\n",
    "theta_lag1 = out_lag1['theta']\n",
    "res_lag1 = out_lag1['res']\n",
    "print(\"Lagged treatment DML (gain_{t-1})\")\n",
    "print(\"theta_lag1 =\", theta_lag1)\n",
    "if res_lag1 is not None:\n",
    "    print(\"SE (cluster):\", float(res_lag1.bse[0]), \"t:\", float(res_lag1.tvalues[0]), \"p:\", float(res_lag1.pvalues[0]))\n",
    "else:\n",
    "    print(\"Cluster result NA (likely no folds contributed).\")\n",
    "\n",
    "# save\n",
    "import pandas as pd, os\n",
    "pd.DataFrame([{'spec':'lag1','theta':theta_lag1,\n",
    "               'se': float(res_lag1.bse[0]) if res_lag1 is not None else None,\n",
    "               'pval': float(res_lag1.pvalues[0]) if res_lag1 is not None else None}]\n",
    "            ).to_csv(os.path.join(fold_output_dir, \"dml_lag1_summary.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe62c9f",
   "metadata": {},
   "source": [
    "B — Distributed-lag residual regression — High priority (run right after A)\n",
    "\n",
    "Why: separates immediate vs delayed associations (gain_t vs gain_{t−1}, gain_{t−2}).\n",
    "What to run: the distributed-lag cell I gave (CELL 2). It uses LOYO residualisation then OLS y_res ~ gain_t + gain_lag1 + gain_lag2 with clustered SEs.\n",
    "Save: distributed_lag_results.csv and the regression text (or paste the summary).\n",
    "What to paste here: the coefficients, SEs, p-values for gain_t, gain_lag1, gain_lag2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c77b545f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in resid_df: 1535\n",
      "Rows after dropping missing y_res: 1535\n",
      "\n",
      "=== Regression: distlag_model_A_gain_t  (N= 1535 ) ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  y_res   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                     3.302\n",
      "Date:                Fri, 22 Aug 2025   Prob (F-statistic):             0.0737\n",
      "Time:                        11:53:23   Log-Likelihood:                -4978.7\n",
      "No. Observations:                1535   AIC:                             9961.\n",
      "Df Residuals:                    1533   BIC:                             9972.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8063      0.530      1.521      0.128      -0.233       1.846\n",
      "gain_t        -0.0142      0.008     -1.817      0.069      -0.029       0.001\n",
      "==============================================================================\n",
      "Omnibus:                     2522.223   Durbin-Watson:                   1.984\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         20024837.453\n",
      "Skew:                           9.410   Prob(JB):                         0.00\n",
      "Kurtosis:                     562.230   Cond. No.                         311.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "Saved coef table to fold_output_dir.\n",
      "\n",
      "Correlation(gain_t, gain_lag1) in Model B sample: 0.9958286660222403\n",
      "\n",
      "=== Regression: distlag_model_B_gain_t_lag1  (N= 1468 ) ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  y_res   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.508\n",
      "Date:                Fri, 22 Aug 2025   Prob (F-statistic):              0.229\n",
      "Time:                        11:53:23   Log-Likelihood:                -4735.8\n",
      "No. Observations:                1468   AIC:                             9478.\n",
      "Df Residuals:                    1465   BIC:                             9493.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.5188      0.429      1.210      0.226      -0.322       1.359\n",
      "gain_t        -0.0251      0.091     -0.276      0.783      -0.204       0.153\n",
      "gain_lag1      0.0171      0.095      0.179      0.858      -0.169       0.204\n",
      "==============================================================================\n",
      "Omnibus:                     2484.090   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         23856271.157\n",
      "Skew:                           9.963   Prob(JB):                         0.00\n",
      "Kurtosis:                     627.198   Cond. No.                         442.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "Saved coef table and VIF to fold_output_dir.\n",
      "\n",
      "Correlation matrix of lags in Model C sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gain_t</th>\n",
       "      <th>gain_lag1</th>\n",
       "      <th>gain_lag2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gain_t</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995683</td>\n",
       "      <td>0.991107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_lag1</th>\n",
       "      <td>0.995683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_lag2</th>\n",
       "      <td>0.991107</td>\n",
       "      <td>0.995645</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gain_t  gain_lag1  gain_lag2\n",
       "gain_t     1.000000   0.995683   0.991107\n",
       "gain_lag1  0.995683   1.000000   0.995645\n",
       "gain_lag2  0.991107   0.995645   1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Regression: distlag_model_C_gain_t_lag1_lag2  (N= 1401 ) ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  y_res   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.002\n",
      "Method:                 Least Squares   F-statistic:                    0.9301\n",
      "Date:                Fri, 22 Aug 2025   Prob (F-statistic):              0.431\n",
      "Time:                        11:53:23   Log-Likelihood:                -3956.6\n",
      "No. Observations:                1401   AIC:                             7921.\n",
      "Df Residuals:                    1397   BIC:                             7942.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0635      0.440     -0.144      0.885      -0.927       0.800\n",
      "gain_t        -0.0514      0.068     -0.753      0.452      -0.185       0.082\n",
      "gain_lag1     -0.0149      0.138     -0.108      0.914      -0.285       0.255\n",
      "gain_lag2      0.0668      0.090      0.743      0.458      -0.109       0.243\n",
      "==============================================================================\n",
      "Omnibus:                     3335.907   Durbin-Watson:                   1.953\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         35294583.134\n",
      "Skew:                         -22.703   Prob(JB):                         0.00\n",
      "Kurtosis:                     779.245   Cond. No.                         545.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "Saved coef table and VIF to fold_output_dir.\n",
      "\n",
      "Sample sizes: Model A (gain_t) = 1535 ; Model B (t, t-1) = 1468 ; Model C (t,t-1,t-2) = 1401\n",
      "Saved sample CSVs and model outputs to: artifacts/dml_pooled\n"
     ]
    }
   ],
   "source": [
    "# FIXED CELL: run distributed-lag regressions on nested samples + diagnostics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Ensure resid_df exists from previous cell\n",
    "print(\"Rows in resid_df:\", len(resid_df))\n",
    "\n",
    "# Make sure lag columns are numeric and finite\n",
    "for col in ['gain_t','gain_lag1','gain_lag2']:\n",
    "    if col in resid_df.columns:\n",
    "        resid_df[col] = pd.to_numeric(resid_df[col], errors='coerce')\n",
    "        resid_df.loc[np.isinf(resid_df[col]), col] = np.nan\n",
    "    else:\n",
    "        resid_df[col] = np.nan\n",
    "\n",
    "# Drop rows with missing y_res (should not happen)\n",
    "resid_df = resid_df.dropna(subset=['y_res']).reset_index(drop=True)\n",
    "print(\"Rows after dropping missing y_res:\", len(resid_df))\n",
    "\n",
    "# Helper to run clustered OLS and save + print results\n",
    "def run_cluster_ols(df_sub, regressors, cluster_col='iso3c', save_prefix='model'):\n",
    "    X = df_sub[regressors].astype(float)\n",
    "    X = sm.add_constant(X)\n",
    "    y = df_sub['y_res'].astype(float)\n",
    "    clusters = df_sub[cluster_col].astype(object)\n",
    "    model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': clusters})\n",
    "    print(\"\\n=== Regression:\", save_prefix, \" (N=\", len(df_sub), \") ===\")\n",
    "    print(model.summary())\n",
    "    # save coef table\n",
    "    coef_tbl = pd.DataFrame({'coef': model.params, 'se': model.bse, 'pval': model.pvalues})\n",
    "    coef_tbl.to_csv(os.path.join(fold_output_dir, f\"{save_prefix}_coef_table.csv\"))\n",
    "    # VIF if more than 1 regressor (excluding constant)\n",
    "    if len(regressors) > 1:\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df['variable'] = ['const'] + regressors\n",
    "        try:\n",
    "            # compute VIF for regressors (exclude constant for VIF calc)\n",
    "            X_vif = df_sub[regressors].astype(float).dropna()\n",
    "            # add constant column to compute VIFs in usual way\n",
    "            X_vif_const = sm.add_constant(X_vif)\n",
    "            vif_vals = [variance_inflation_factor(X_vif_const.values, i) for i in range(X_vif_const.shape[1])]\n",
    "            vif_df['VIF'] = vif_vals\n",
    "        except Exception as e:\n",
    "            vif_df['VIF'] = np.nan\n",
    "        vif_df.to_csv(os.path.join(fold_output_dir, f\"{save_prefix}_vif.csv\"))\n",
    "        print(\"Saved coef table and VIF to fold_output_dir.\")\n",
    "    else:\n",
    "        print(\"Saved coef table to fold_output_dir.\")\n",
    "    return model\n",
    "\n",
    "# Model A: y_res ~ gain_t (drop rows missing gain_t)\n",
    "df_A = resid_df.dropna(subset=['gain_t']).copy().reset_index(drop=True)\n",
    "model_A = None\n",
    "if len(df_A) > 0:\n",
    "    model_A = run_cluster_ols(df_A, ['gain_t'], save_prefix='distlag_model_A_gain_t')\n",
    "\n",
    "# Model B: y_res ~ gain_t + gain_lag1 (require both)\n",
    "df_B = resid_df.dropna(subset=['gain_t','gain_lag1']).copy().reset_index(drop=True)\n",
    "model_B = None\n",
    "if len(df_B) > 0:\n",
    "    # display correlation between gain_t and gain_lag1\n",
    "    corr12 = df_B['gain_t'].corr(df_B['gain_lag1'])\n",
    "    print(\"\\nCorrelation(gain_t, gain_lag1) in Model B sample:\", corr12)\n",
    "    model_B = run_cluster_ols(df_B, ['gain_t','gain_lag1'], save_prefix='distlag_model_B_gain_t_lag1')\n",
    "\n",
    "# Model C: y_res ~ gain_t + gain_lag1 + gain_lag2 (require all 3)\n",
    "df_C = resid_df.dropna(subset=['gain_t','gain_lag1','gain_lag2']).copy().reset_index(drop=True)\n",
    "model_C = None\n",
    "if len(df_C) > 0:\n",
    "    corr_mat = df_C[['gain_t','gain_lag1','gain_lag2']].corr()\n",
    "    print(\"\\nCorrelation matrix of lags in Model C sample:\")\n",
    "    display(corr_mat)\n",
    "    model_C = run_cluster_ols(df_C, ['gain_t','gain_lag1','gain_lag2'], save_prefix='distlag_model_C_gain_t_lag1_lag2')\n",
    "\n",
    "# Summarize sample sizes\n",
    "print(\"\\nSample sizes: Model A (gain_t) =\", len(df_A), \"; Model B (t, t-1) =\", len(df_B), \"; Model C (t,t-1,t-2) =\", len(df_C))\n",
    "\n",
    "# Save the three datasets for inspection\n",
    "df_A.to_csv(os.path.join(fold_output_dir, \"distlag_sample_A_gain_t.csv\"), index=False)\n",
    "df_B.to_csv(os.path.join(fold_output_dir, \"distlag_sample_B_gain_t_lag1.csv\"), index=False)\n",
    "df_C.to_csv(os.path.join(fold_output_dir, \"distlag_sample_C_gain_t_lag1_lag2.csv\"), index=False)\n",
    "\n",
    "print(\"Saved sample CSVs and model outputs to:\", fold_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50874cc",
   "metadata": {},
   "source": [
    "CELL 3 — FE-DML (within-country DML)\n",
    "\n",
    "This reuses the DML routine but sets include_country_fe=True in preprocessing so the nuisances are estimated on demeaned data (country FE partial-out). I provide a modified helper wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "caa4139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FE-DML (country fixed effects) using treatment = gain\n",
      "FE-DML completed in 19.7s: theta=-0.439007. folds considered=29, folds used=29\n",
      "\n",
      "FE-DML summary:\n",
      "theta_FE = -0.43900733250253493\n",
      "cluster SE: 0.4419756320303412 t: -0.9932840199488586 p: 0.3205715628398762\n",
      "Diagnostics and residuals saved to: artifacts/dml_pooled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>year_holdout</th>\n",
       "      <th>n_train_total</th>\n",
       "      <th>n_test_total</th>\n",
       "      <th>n_train_valid</th>\n",
       "      <th>n_test_valid</th>\n",
       "      <th>used</th>\n",
       "      <th>reason</th>\n",
       "      <th>n_kept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1505</td>\n",
       "      <td>30</td>\n",
       "      <td>1318</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>1503</td>\n",
       "      <td>32</td>\n",
       "      <td>1316</td>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1997</td>\n",
       "      <td>1501</td>\n",
       "      <td>34</td>\n",
       "      <td>1314</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>1499</td>\n",
       "      <td>36</td>\n",
       "      <td>1312</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1999</td>\n",
       "      <td>1497</td>\n",
       "      <td>38</td>\n",
       "      <td>1310</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>1495</td>\n",
       "      <td>40</td>\n",
       "      <td>1308</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>1493</td>\n",
       "      <td>42</td>\n",
       "      <td>1306</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>1491</td>\n",
       "      <td>44</td>\n",
       "      <td>1304</td>\n",
       "      <td>41</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2003</td>\n",
       "      <td>1489</td>\n",
       "      <td>46</td>\n",
       "      <td>1304</td>\n",
       "      <td>41</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2004</td>\n",
       "      <td>1488</td>\n",
       "      <td>47</td>\n",
       "      <td>1303</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2005</td>\n",
       "      <td>1487</td>\n",
       "      <td>48</td>\n",
       "      <td>1302</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>1487</td>\n",
       "      <td>48</td>\n",
       "      <td>1302</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>1484</td>\n",
       "      <td>51</td>\n",
       "      <td>1300</td>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2008</td>\n",
       "      <td>1481</td>\n",
       "      <td>54</td>\n",
       "      <td>1297</td>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2009</td>\n",
       "      <td>1480</td>\n",
       "      <td>55</td>\n",
       "      <td>1296</td>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2010</td>\n",
       "      <td>1478</td>\n",
       "      <td>57</td>\n",
       "      <td>1294</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2011</td>\n",
       "      <td>1479</td>\n",
       "      <td>56</td>\n",
       "      <td>1295</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2012</td>\n",
       "      <td>1472</td>\n",
       "      <td>63</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2013</td>\n",
       "      <td>1471</td>\n",
       "      <td>64</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2014</td>\n",
       "      <td>1471</td>\n",
       "      <td>64</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2015</td>\n",
       "      <td>1470</td>\n",
       "      <td>65</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2016</td>\n",
       "      <td>1471</td>\n",
       "      <td>64</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1471</td>\n",
       "      <td>64</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2018</td>\n",
       "      <td>1470</td>\n",
       "      <td>65</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>1470</td>\n",
       "      <td>65</td>\n",
       "      <td>1281</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2020</td>\n",
       "      <td>1470</td>\n",
       "      <td>65</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2021</td>\n",
       "      <td>1469</td>\n",
       "      <td>66</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2022</td>\n",
       "      <td>1469</td>\n",
       "      <td>66</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2023</td>\n",
       "      <td>1469</td>\n",
       "      <td>66</td>\n",
       "      <td>1290</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  year_holdout  n_train_total  n_test_total  n_train_valid  \\\n",
       "0      0          1995           1505            30           1318   \n",
       "1      1          1996           1503            32           1316   \n",
       "2      2          1997           1501            34           1314   \n",
       "3      3          1998           1499            36           1312   \n",
       "4      4          1999           1497            38           1310   \n",
       "5      5          2000           1495            40           1308   \n",
       "6      6          2001           1493            42           1306   \n",
       "7      7          2002           1491            44           1304   \n",
       "8      8          2003           1489            46           1304   \n",
       "9      9          2004           1488            47           1303   \n",
       "10    10          2005           1487            48           1302   \n",
       "11    11          2006           1487            48           1302   \n",
       "12    12          2007           1484            51           1300   \n",
       "13    13          2008           1481            54           1297   \n",
       "14    14          2009           1480            55           1296   \n",
       "15    15          2010           1478            57           1294   \n",
       "16    16          2011           1479            56           1295   \n",
       "17    17          2012           1472            63           1290   \n",
       "18    18          2013           1471            64           1290   \n",
       "19    19          2014           1471            64           1290   \n",
       "20    20          2015           1470            65           1290   \n",
       "21    21          2016           1471            64           1290   \n",
       "22    22          2017           1471            64           1290   \n",
       "23    23          2018           1470            65           1290   \n",
       "24    24          2019           1470            65           1281   \n",
       "25    25          2020           1470            65           1290   \n",
       "26    26          2021           1469            66           1290   \n",
       "27    27          2022           1469            66           1290   \n",
       "28    28          2023           1469            66           1290   \n",
       "\n",
       "    n_test_valid  used reason  n_kept  \n",
       "0             27  True             27  \n",
       "1             29  True             29  \n",
       "2             31  True             31  \n",
       "3             33  True             33  \n",
       "4             35  True             35  \n",
       "5             37  True             37  \n",
       "6             39  True             39  \n",
       "7             41  True             41  \n",
       "8             41  True             41  \n",
       "9             42  True             42  \n",
       "10            43  True             43  \n",
       "11            43  True             43  \n",
       "12            45  True             45  \n",
       "13            48  True             48  \n",
       "14            49  True             49  \n",
       "15            51  True             51  \n",
       "16            50  True             50  \n",
       "17            55  True             55  \n",
       "18            55  True             55  \n",
       "19            55  True             55  \n",
       "20            55  True             55  \n",
       "21            55  True             55  \n",
       "22            55  True             55  \n",
       "23            55  True             55  \n",
       "24            55  True             55  \n",
       "25            55  True             55  \n",
       "26            55  True             55  \n",
       "27            55  True             55  \n",
       "28            55  True             55  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 3 (FE-DML): within-country Double Machine Learning with leave-one-year-out cross-fitting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "\n",
    "# Parameters (modify if desired)\n",
    "n_trees = 300\n",
    "random_seed = 2025\n",
    "min_train_frac = 0.05   # minimum fraction of train rows required (same as pooled helper)\n",
    "min_train_rows_absolute = 10\n",
    "\n",
    "# Defensive checks\n",
    "assert 'df' in globals(), \"Dataframe `df` not found in the notebook environment.\"\n",
    "assert 'covariates_to_use' in globals(), \"Please ensure `covariates_to_use` is defined.\"\n",
    "assert 'Y_col' in globals() and 'T_col' in globals(), \"Please ensure Y_col and T_col are defined.\"\n",
    "fold_output_dir = fold_output_dir if 'fold_output_dir' in globals() else \"artifacts\"\n",
    "os.makedirs(fold_output_dir, exist_ok=True)\n",
    "\n",
    "def compute_fe_dml(df_local, covariates_list, idcol='iso3c', timecol='year',\n",
    "                   ycol=Y_col, tcol='gain', n_trees_local=n_trees, random_seed_local=random_seed,\n",
    "                   min_train_frac_local=min_train_frac, min_train_rows=min_train_rows_absolute):\n",
    "    \"\"\"\n",
    "    FE-DML: For each LOYO fold:\n",
    "      - compute country means on TRAIN for y, t, and covariates (demean = within-FE)\n",
    "      - apply the train means to both train and test (skip rows where a given country has no train mean)\n",
    "      - impute/scale on train, fit p(X) with Lasso and m(X) with RF on demeaned data\n",
    "      - predict on test, form residuals, stack u and v, cluster by iso3c\n",
    "    Returns dictionary with theta, res (clustered OLS), u_all, v_all, groups_all, and diagnostics_df.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    df_local = df_local.reset_index(drop=True).copy()\n",
    "    years = sorted(df_local[timecol].unique())\n",
    "    folds = [(df_local.index[df_local[timecol] != y].tolist(), df_local.index[df_local[timecol] == y].tolist()) for y in years]\n",
    "\n",
    "    u_list = []\n",
    "    v_list = []\n",
    "    groups_list = []\n",
    "    diag_rows = []\n",
    "\n",
    "    for fnum, (train_idx, test_idx) in enumerate(folds):\n",
    "        year_holdout = years[fnum]\n",
    "        train = df_local.loc[train_idx].reset_index(drop=True).copy()\n",
    "        test  = df_local.loc[test_idx].reset_index(drop=True).copy()\n",
    "\n",
    "        # --- compute within-country means on TRAIN only ---\n",
    "        # columns to demean: y, t, covariates (coerce numeric)\n",
    "        demean_cols = [ycol, tcol] + [c for c in covariates_list if c in train.columns]\n",
    "        # coerce numeric where possible\n",
    "        train_demean = train[demean_cols].apply(pd.to_numeric, errors='coerce')\n",
    "        # group means by country (train only)\n",
    "        country_means = train.groupby(idcol)[demean_cols].mean()\n",
    "\n",
    "        # For train and test, attach country means (NaN if country not in train)\n",
    "        def attach_means(df_part):\n",
    "            # join on country id; result has columns like <col>_mean\n",
    "            means = df_part[[idcol]].merge(country_means.reset_index(), on=idcol, how='left', suffixes=('','_mean'))\n",
    "            # means columns now include idcol plus demean_cols\n",
    "            return means\n",
    "\n",
    "        train_means = attach_means(train)\n",
    "        test_means  = attach_means(test)\n",
    "\n",
    "        # Demean: subtract country means for each column (only where mean present)\n",
    "        # build demeaned DataFrames for y, t, and covariates\n",
    "        # If a row's country mean is NaN => that country had no train observations (rare) -> drop those rows\n",
    "        valid_train_mask = ~train_means[demean_cols].isna().any(axis=1)\n",
    "        valid_test_mask  = ~test_means[demean_cols].isna().any(axis=1)\n",
    "\n",
    "        n_train = len(train); n_test = len(test)\n",
    "        n_train_valid = int(valid_train_mask.sum())\n",
    "        n_test_valid = int(valid_test_mask.sum())\n",
    "\n",
    "        # record diagnostics\n",
    "        diag = {\n",
    "            'fold': fnum, 'year_holdout': year_holdout,\n",
    "            'n_train_total': n_train, 'n_test_total': n_test,\n",
    "            'n_train_valid': n_train_valid, 'n_test_valid': n_test_valid,\n",
    "            'used': False, 'reason': ''\n",
    "        }\n",
    "\n",
    "        if n_train_valid < max(min_train_rows, int(min_train_frac_local * n_train)):\n",
    "            diag['used'] = False\n",
    "            diag['reason'] = 'insufficient_valid_train_rows'\n",
    "            diag_rows.append(diag)\n",
    "            # skip fold\n",
    "            continue\n",
    "\n",
    "        # Subset to valid rows and compute demeaned values\n",
    "        train_valid = train.loc[valid_train_mask].reset_index(drop=True).copy()\n",
    "        test_valid  = test.loc[valid_test_mask].reset_index(drop=True).copy()\n",
    "        train_means_valid = train_means.loc[valid_train_mask, demean_cols].reset_index(drop=True)\n",
    "        test_means_valid  = test_means.loc[valid_test_mask, demean_cols].reset_index(drop=True)\n",
    "\n",
    "        # produce demeaned series\n",
    "        y_train_demean = pd.to_numeric(train_valid[ycol], errors='coerce') - train_means_valid[ycol]\n",
    "        t_train_demean = pd.to_numeric(train_valid[tcol], errors='coerce') - train_means_valid[tcol]\n",
    "\n",
    "        y_test_demean = pd.to_numeric(test_valid[ycol], errors='coerce') - test_means_valid[ycol]\n",
    "        t_test_demean = pd.to_numeric(test_valid[tcol], errors='coerce') - test_means_valid[tcol]\n",
    "\n",
    "        # Demean covariates\n",
    "        covs_present = [c for c in covariates_list if c in train_valid.columns]\n",
    "        X_train = train_valid[covs_present].apply(pd.to_numeric, errors='coerce') - train_means_valid[covs_present].values\n",
    "        X_test  = test_valid[covs_present].apply(pd.to_numeric, errors='coerce') - test_means_valid[covs_present].values\n",
    "\n",
    "        # Impute & scale on TRAIN demeaned covariates, then transform test\n",
    "        try:\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            X_train_imp = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "            X_test_imp  = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "        except Exception:\n",
    "            X_train_imp = X_train.fillna(X_train.mean())\n",
    "            X_test_imp  = X_test.fillna(X_train.mean())\n",
    "\n",
    "        try:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_imp), columns=X_train_imp.columns)\n",
    "            X_test_scaled  = pd.DataFrame(scaler.transform(X_test_imp), columns=X_test_imp.columns)\n",
    "        except Exception:\n",
    "            X_train_scaled = X_train_imp\n",
    "            X_test_scaled = X_test_imp\n",
    "\n",
    "        # Check that we have usable y and t in training subset\n",
    "        train_valid_mask_y_t = (~y_train_demean.isna()) & (~t_train_demean.isna())\n",
    "        if train_valid_mask_y_t.sum() < max(min_train_rows, int(min_train_frac_local * len(train_valid_mask_y_t))):\n",
    "            diag['used'] = False\n",
    "            diag['reason'] = 'insufficient_train_y_t'\n",
    "            diag_rows.append(diag)\n",
    "            continue\n",
    "\n",
    "        # Select train rows by positions\n",
    "        train_pos = np.where(train_valid_mask_y_t)[0]\n",
    "        Xtrain_sub = X_train_scaled.iloc[train_pos, :].copy()\n",
    "        ytrain_sub = y_train_demean.iloc[train_pos].copy()\n",
    "        ttrain_sub = t_train_demean.iloc[train_pos].copy()\n",
    "\n",
    "        # require variation in t in training subset\n",
    "        if np.nanvar(ttrain_sub.to_numpy()) == 0:\n",
    "            diag['used'] = False\n",
    "            diag['reason'] = 'no_t_variation_in_train'\n",
    "            diag_rows.append(diag)\n",
    "            continue\n",
    "\n",
    "        # Fit nuisance p(X) and m(X) on demeaned training subset\n",
    "        try:\n",
    "            p_model = LassoCV(cv=5, random_state=random_seed_local).fit(Xtrain_sub, ttrain_sub)\n",
    "        except Exception:\n",
    "            from sklearn.linear_model import Lasso\n",
    "            p_model = Lasso(alpha=1.0).fit(Xtrain_sub, ttrain_sub)\n",
    "        p_hat_test_full = p_model.predict(X_test_scaled)\n",
    "\n",
    "        try:\n",
    "            m_model = RandomForestRegressor(n_estimators=n_trees_local, n_jobs=-1, random_state=random_seed_local)\n",
    "            m_model.fit(Xtrain_sub, ytrain_sub)\n",
    "            m_hat_test_full = m_model.predict(X_test_scaled)\n",
    "        except Exception:\n",
    "            m_ols = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "            m_hat_test_full = m_ols.predict(sm.add_constant(X_test_scaled))\n",
    "\n",
    "        # For the test_valid rows, we also need y_test_demean and t_test_demean arrays\n",
    "        y_test_arr = y_test_demean.to_numpy()\n",
    "        t_test_arr = t_test_demean.to_numpy()\n",
    "        # keep positions with both y and t observed\n",
    "        test_mask_pos = (~pd.isna(y_test_arr)) & (~pd.isna(t_test_arr))\n",
    "        if test_mask_pos.sum() == 0:\n",
    "            diag['used'] = False\n",
    "            diag['reason'] = 'no_usable_test_obs'\n",
    "            diag_rows.append(diag)\n",
    "            continue\n",
    "\n",
    "        pos_keep = np.where(test_mask_pos)[0]\n",
    "        p_hat_kept = p_hat_test_full[pos_keep]\n",
    "        m_hat_kept = m_hat_test_full[pos_keep]\n",
    "        u_hat = y_test_arr[pos_keep] - m_hat_kept\n",
    "        v_hat = t_test_arr[pos_keep] - p_hat_kept\n",
    "\n",
    "        # collect iso3c groups for the kept test rows (original test_valid rows)\n",
    "        groups_kept = test_valid.loc[pos_keep, idcol].astype(object).values\n",
    "\n",
    "        # create unique integer indices to avoid index collisions\n",
    "        base_idx = fnum * 10**6\n",
    "        idxs = [base_idx + i for i in range(len(u_hat))]\n",
    "        u_list.append(pd.Series(u_hat, index=idxs))\n",
    "        v_list.append(pd.Series(v_hat, index=idxs))\n",
    "        groups_list.append(pd.Series(groups_kept, index=idxs))\n",
    "\n",
    "        diag['used'] = True\n",
    "        diag['reason'] = ''\n",
    "        diag['n_kept'] = int(len(u_hat))\n",
    "        diag_rows.append(diag)\n",
    "\n",
    "    # end folds\n",
    "    if len(u_list) == 0:\n",
    "        return {'theta': np.nan, 'res': None, 'u_all': None, 'v_all': None, 'groups': None, 'diag_df': pd.DataFrame(diag_rows)}\n",
    "\n",
    "    u_all = pd.concat(u_list).sort_index()\n",
    "    v_all = pd.concat(v_list).sort_index()\n",
    "    groups_all = pd.concat(groups_list).sort_index()\n",
    "\n",
    "    theta = (v_all * u_all).sum() / (v_all**2).sum()\n",
    "\n",
    "    # cluster-robust regression of u on v\n",
    "    res = sm.OLS(u_all.values, v_all.values).fit(cov_type='cluster', cov_kwds={'groups': groups_all.values})\n",
    "\n",
    "    diag_df = pd.DataFrame(diag_rows)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"FE-DML completed in {elapsed:.1f}s: theta={theta:.6g}. folds considered={len(folds)}, folds used={diag_df['used'].sum()}\")\n",
    "    return {'theta': float(theta), 'res': res, 'u_all': u_all, 'v_all': v_all, 'groups': groups_all, 'diag_df': diag_df}\n",
    "\n",
    "# Run FE-DML using current gain as treatment\n",
    "print(\"Running FE-DML (country fixed effects) using treatment =\", T_col)\n",
    "out_fe = compute_fe_dml(df, covariates_to_use, idcol='iso3c', timecol='year',\n",
    "                        ycol=Y_col, tcol=T_col, n_trees_local=n_trees, random_seed_local=random_seed,\n",
    "                        min_train_frac_local=min_train_frac, min_train_rows=min_train_rows_absolute)\n",
    "\n",
    "theta_fe = out_fe['theta']\n",
    "res_fe = out_fe['res']\n",
    "diag_df_fe = out_fe['diag_df']\n",
    "\n",
    "# Print key summary\n",
    "print(\"\\nFE-DML summary:\")\n",
    "print(\"theta_FE =\", theta_fe)\n",
    "if res_fe is not None:\n",
    "    try:\n",
    "        print(\"cluster SE:\", float(res_fe.bse[0]), \"t:\", float(res_fe.tvalues[0]), \"p:\", float(res_fe.pvalues[0]))\n",
    "    except Exception:\n",
    "        print(\"Cluster regression produced no standard errors.\")\n",
    "else:\n",
    "    print(\"No cluster regression produced (res is None).\")\n",
    "\n",
    "# Save outputs for inspection\n",
    "diag_df_fe.to_csv(os.path.join(fold_output_dir, \"fe_dml_fold_diagnostics.csv\"), index=False)\n",
    "if out_fe['u_all'] is not None and out_fe['v_all'] is not None:\n",
    "    pd.DataFrame({'u_all': out_fe['u_all'], 'v_all': out_fe['v_all'], 'groups': out_fe['groups']}).to_csv(os.path.join(fold_output_dir, \"fe_dml_uv_groups.csv\"))\n",
    "print(\"Diagnostics and residuals saved to:\", fold_output_dir)\n",
    "\n",
    "# Show first rows of diag_df\n",
    "display(diag_df_fe.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc79ca3",
   "metadata": {},
   "source": [
    "CELL 4 — Quick outlier check (2014 big jumps) and re-run a sensitivity exclusion\n",
    "\n",
    "This lists the largest year-to-year changes and provides an option to exclude those country-year observations (or just 2014) and re-run the lagged DML quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5a74074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top negative year-to-year drops (largest negatives):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3c</th>\n",
       "      <th>year</th>\n",
       "      <th>gain_diff1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BGD</td>\n",
       "      <td>2014</td>\n",
       "      <td>-11.062157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>NGA</td>\n",
       "      <td>2014</td>\n",
       "      <td>-10.871986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>IND</td>\n",
       "      <td>2014</td>\n",
       "      <td>-9.909187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>PAK</td>\n",
       "      <td>2014</td>\n",
       "      <td>-8.339038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>MEX</td>\n",
       "      <td>2014</td>\n",
       "      <td>-7.692216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>CHN</td>\n",
       "      <td>2014</td>\n",
       "      <td>-7.237966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>IDN</td>\n",
       "      <td>2014</td>\n",
       "      <td>-7.195652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>RUS</td>\n",
       "      <td>2014</td>\n",
       "      <td>-5.826981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>CYP</td>\n",
       "      <td>2009</td>\n",
       "      <td>-5.246734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>BRA</td>\n",
       "      <td>2014</td>\n",
       "      <td>-5.023341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iso3c  year  gain_diff1\n",
       "118    BGD  2014  -11.062157\n",
       "1017   NGA  2014  -10.871986\n",
       "639    IND  2014   -9.909187\n",
       "1133   PAK  2014   -8.339038\n",
       "913    MEX  2014   -7.692216\n",
       "264    CHN  2014   -7.237966\n",
       "610    IDN  2014   -7.195652\n",
       "1297   RUS  2014   -5.826981\n",
       "310    CYP  2009   -5.246734\n",
       "164    BRA  2014   -5.023341"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive jumps:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3c</th>\n",
       "      <th>year</th>\n",
       "      <th>gain_diff1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>PAK</td>\n",
       "      <td>2006</td>\n",
       "      <td>4.643101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>LUX</td>\n",
       "      <td>2006</td>\n",
       "      <td>4.566886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>CYP</td>\n",
       "      <td>2006</td>\n",
       "      <td>4.188920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>MLT</td>\n",
       "      <td>2006</td>\n",
       "      <td>4.076457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>LUX</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.020964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>MEX</td>\n",
       "      <td>2006</td>\n",
       "      <td>4.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>JPN</td>\n",
       "      <td>2006</td>\n",
       "      <td>3.980954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>IND</td>\n",
       "      <td>2006</td>\n",
       "      <td>3.873623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>RUS</td>\n",
       "      <td>2006</td>\n",
       "      <td>3.788579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>BGD</td>\n",
       "      <td>2006</td>\n",
       "      <td>3.679263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iso3c  year  gain_diff1\n",
       "1125   PAK  2006    4.643101\n",
       "856    LUX  2006    4.566886\n",
       "307    CYP  2006    4.188920\n",
       "934    MLT  2006    4.076457\n",
       "850    LUX  2000    4.020964\n",
       "905    MEX  2006    4.000531\n",
       "750    JPN  2006    3.980954\n",
       "631    IND  2006    3.873623\n",
       "1289   RUS  2006    3.788579\n",
       "110    BGD  2006    3.679263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagged DML excluding year 2014: theta = 0.47422025187460043\n",
      "SE: 0.345763687779606 p: 0.17021431976986523\n"
     ]
    }
   ],
   "source": [
    "# CELL: find large year-to-year ND-GAIN jumps and optionally drop year 2014 observations\n",
    "df_changes = df.copy().reset_index(drop=True)\n",
    "df_changes['gain_diff1'] = df_changes.groupby('iso3c')['gain'].diff()\n",
    "top_jumps = df_changes[['iso3c','year','gain_diff1']].dropna().sort_values('gain_diff1').head(10)\n",
    "top_jumps_tail = df_changes[['iso3c','year','gain_diff1']].dropna().sort_values('gain_diff1', ascending=False).head(10)\n",
    "print(\"Top negative year-to-year drops (largest negatives):\")\n",
    "display(top_jumps.head(10))\n",
    "print(\"Top positive jumps:\")\n",
    "display(top_jumps_tail.head(10))\n",
    "\n",
    "# Option: exclude year 2014 (or exclude specific country-years)\n",
    "exclude_year = 2014\n",
    "df_no2014 = df[df['year'] != exclude_year].reset_index(drop=True)\n",
    "df_no2014 = df_no2014.dropna(subset=[Y_col]).reset_index(drop=True)\n",
    "\n",
    "# Rerun lagged DML on the filtered dataset (example)\n",
    "df_no2014['gain_lag1'] = df_no2014.groupby('iso3c')['gain'].shift(1)\n",
    "df_no2014 = df_no2014.dropna(subset=['gain_lag1', Y_col]).reset_index(drop=True)\n",
    "df_no2014 = df_no2014.rename(columns={'gain_lag1':'gain_temp'})\n",
    "\n",
    "out_no2014 = compute_dml_theta_and_se(df_no2014, covariates_to_use,\n",
    "                                      idcol='iso3c', timecol='year',\n",
    "                                      ycol=Y_col, tcol='gain_temp',\n",
    "                                      n_trees=200, random_seed=2025)\n",
    "print(\"Lagged DML excluding year 2014: theta =\", out_no2014['theta'])\n",
    "if out_no2014['res'] is not None:\n",
    "    print(\"SE:\", float(out_no2014['res'].bse[0]), \"p:\", float(out_no2014['res'].pvalues[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc160ac",
   "metadata": {},
   "source": [
    "# Trying pooled version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23dc3514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled theta: 0.34682575968960616\n",
      "Pooled SE: 0.2812348209763999 p: 0.2174919000940182\n",
      "Mundlak theta: -0.034804738371167016\n",
      "Mundlak SE: 0.021237227626079387 p: 0.10124344489192784\n",
      "Saved pooled_vs_mundlak_results.csv to artifacts/dml_pooled\n"
     ]
    }
   ],
   "source": [
    "# POOLED DML vs POOLED + MUNDAK (country-means) — LOYO cross-fitting, no leakage\n",
    "import numpy as np, pandas as pd, os\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Parameters\n",
    "idcol = 'iso3c'\n",
    "timecol = 'year'\n",
    "ycol = Y_col\n",
    "tcol = T_col\n",
    "covs = [c for c in covariates_to_use if c in df.columns]\n",
    "mundlak_covs = covs  # choose a subset if you prefer, e.g., economic vars only\n",
    "\n",
    "def run_pooled_and_mundlak(df_local, covariates_list, mundlak_list,\n",
    "                           idcol='iso3c', timecol='year', ycol=Y_col, tcol=T_col,\n",
    "                           n_trees=200, random_seed=2025):\n",
    "    years = sorted(df_local[timecol].unique())\n",
    "    folds = [(df_local.index[df_local[timecol] != y].tolist(), df_local.index[df_local[timecol] == y].tolist()) for y in years]\n",
    "\n",
    "    # holders for pooled residual stacking\n",
    "    u_pooled = []; v_pooled = []; g_pooled = []\n",
    "    u_mund = []; v_mund = []; g_mund = []\n",
    "    for fnum, (train_idx, test_idx) in enumerate(folds):\n",
    "        train = df_local.loc[train_idx].reset_index(drop=True).copy()\n",
    "        test  = df_local.loc[test_idx].reset_index(drop=True).copy()\n",
    "\n",
    "        # ============ POOLED (no Mundlak) ============\n",
    "        # Build X_train / X_test from covariates; impute and scale on train\n",
    "        Xtr = train[covariates_list].apply(pd.to_numeric, errors='coerce')\n",
    "        Xte = test[covariates_list].apply(pd.to_numeric, errors='coerce')\n",
    "        try:\n",
    "            imp = KNNImputer(n_neighbors=5)\n",
    "            Xtr_imp = pd.DataFrame(imp.fit_transform(Xtr), columns=Xtr.columns)\n",
    "            Xte_imp = pd.DataFrame(imp.transform(Xte), columns=Xte.columns)\n",
    "        except:\n",
    "            Xtr_imp = Xtr.fillna(Xtr.mean()); Xte_imp = Xte.fillna(Xtr.mean())\n",
    "        try:\n",
    "            sc = StandardScaler()\n",
    "            Xtr_s = pd.DataFrame(sc.fit_transform(Xtr_imp), columns=Xtr_imp.columns)\n",
    "            Xte_s = pd.DataFrame(sc.transform(Xte_imp), columns=Xte_imp.columns)\n",
    "        except:\n",
    "            Xtr_s = Xtr_imp; Xte_s = Xte_imp\n",
    "\n",
    "        yrs_tr = pd.get_dummies(train[timecol], prefix='yr').reset_index(drop=True)\n",
    "        yrs_te = pd.get_dummies(test[timecol], prefix='yr').reindex(columns=yrs_tr.columns, fill_value=0).reset_index(drop=True)\n",
    "        Xtr_fe = pd.concat([Xtr_s.reset_index(drop=True), yrs_tr], axis=1)\n",
    "        Xte_fe = pd.concat([Xte_s.reset_index(drop=True), yrs_te], axis=1)\n",
    "        Xte_fe = Xte_fe.reindex(columns=Xtr_fe.columns, fill_value=0)\n",
    "\n",
    "        y_tr = pd.to_numeric(train[ycol], errors='coerce'); t_tr = pd.to_numeric(train[tcol], errors='coerce')\n",
    "        y_te = pd.to_numeric(test[ycol], errors='coerce'); t_te = pd.to_numeric(test[tcol], errors='coerce')\n",
    "\n",
    "        # masks\n",
    "        train_mask = (~y_tr.isna()) & (~t_tr.isna())\n",
    "        if train_mask.sum() >= 10 and np.nanvar(t_tr[train_mask].to_numpy()) > 0:\n",
    "            pos = np.where(train_mask)[0]\n",
    "            Xtrain_sub = Xtr_fe.iloc[pos,:].copy(); ytrain_sub = y_tr.iloc[pos].copy(); ttrain_sub = t_tr.iloc[pos].copy()\n",
    "            # fit p and m\n",
    "            try:\n",
    "                p_model = LassoCV(cv=5, random_state=random_seed).fit(Xtrain_sub, ttrain_sub)\n",
    "            except:\n",
    "                from sklearn.linear_model import Lasso\n",
    "                p_model = Lasso().fit(Xtrain_sub, ttrain_sub)\n",
    "            p_hat_test = p_model.predict(Xte_fe)\n",
    "            try:\n",
    "                m_model = RandomForestRegressor(n_estimators=n_trees, random_state=random_seed, n_jobs=-1).fit(Xtrain_sub, ytrain_sub)\n",
    "                m_hat_test = m_model.predict(Xte_fe)\n",
    "            except:\n",
    "                m_ols = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "                m_hat_test = m_ols.predict(sm.add_constant(Xte_fe))\n",
    "            # test mask for pooling\n",
    "            test_mask = (~y_te.isna()) & (~t_te.isna())\n",
    "            if test_mask.sum() > 0:\n",
    "                tp = np.where(test_mask)[0]\n",
    "                u_vals = y_te.to_numpy()[tp] - m_hat_test[tp]\n",
    "                v_vals = t_te.to_numpy()[tp] - p_hat_test[tp]\n",
    "                base = fnum * 1000000\n",
    "                idxs = [base + i for i in range(len(u_vals))]\n",
    "                u_pooled.append(pd.Series(u_vals, index=idxs))\n",
    "                v_pooled.append(pd.Series(v_vals, index=idxs))\n",
    "                g_pooled.append(pd.Series(test.loc[tp, idcol].values, index=idxs))\n",
    "\n",
    "        # ============ MUNDAK: compute country means on TRAIN and append to covariates ============\n",
    "        # Compute train country means for mundlak_list\n",
    "        mund_means = train.groupby(idcol)[mundlak_list].mean().reset_index()\n",
    "        # attach means to train and test (left join), rows with NaN means on test => that country absent in train -> drop\n",
    "        train_with_means = train.merge(mund_means, on=idcol, how='left', suffixes=('','_mean'))\n",
    "        test_with_means  = test.merge(mund_means, on=idcol, how='left', suffixes=('','_mean'))\n",
    "        # drop rows in train/test where any of the newly attached means are NaN (i.e., country not present in train)\n",
    "        cols_mean = [c + '_mean' for c in mundlak_list]\n",
    "        valid_train_mask = ~train_with_means[cols_mean].isna().any(axis=1)\n",
    "        valid_test_mask  = ~test_with_means[cols_mean].isna().any(axis=1)\n",
    "        if valid_train_mask.sum() < 10 or valid_test_mask.sum() == 0:\n",
    "            # not enough valid rows -> skip mundlak for this fold\n",
    "            continue\n",
    "        train_valid = train_with_means.loc[valid_train_mask].reset_index(drop=True)\n",
    "        test_valid  = test_with_means.loc[valid_test_mask].reset_index(drop=True)\n",
    "\n",
    "        # build X matrices for mundlak: original demeaned pipeline (but here pooled; we just append means)\n",
    "        Xtr_m = train_valid[covariates_list].apply(pd.to_numeric, errors='coerce')\n",
    "        Xte_m = test_valid[covariates_list].apply(pd.to_numeric, errors='coerce')\n",
    "        # append mean cols\n",
    "        for cm in cols_mean:\n",
    "            Xtr_m[cm] = train_valid[cm]\n",
    "            Xte_m[cm] = test_valid[cm]\n",
    "\n",
    "        try:\n",
    "            imp2 = KNNImputer(n_neighbors=5)\n",
    "            Xtr_m_imp = pd.DataFrame(imp2.fit_transform(Xtr_m), columns=Xtr_m.columns)\n",
    "            Xte_m_imp = pd.DataFrame(imp2.transform(Xte_m), columns=Xte_m.columns)\n",
    "        except:\n",
    "            Xtr_m_imp = Xtr_m.fillna(Xtr_m.mean()); Xte_m_imp = Xte_m.fillna(Xtr_m.mean())\n",
    "        try:\n",
    "            sc2 = StandardScaler()\n",
    "            Xtr_m_s = pd.DataFrame(sc2.fit_transform(Xtr_m_imp), columns=Xtr_m_imp.columns)\n",
    "            Xte_m_s = pd.DataFrame(sc2.transform(Xte_m_imp), columns=Xte_m_imp.columns)\n",
    "        except:\n",
    "            Xtr_m_s = Xtr_m_imp; Xte_m_s = Xte_m_imp\n",
    "\n",
    "        yrs_tr2 = pd.get_dummies(train_valid[timecol], prefix='yr').reset_index(drop=True)\n",
    "        yrs_te2 = pd.get_dummies(test_valid[timecol], prefix='yr').reindex(columns=yrs_tr2.columns, fill_value=0).reset_index(drop=True)\n",
    "        Xtr_m_fe = pd.concat([Xtr_m_s.reset_index(drop=True), yrs_tr2], axis=1)\n",
    "        Xte_m_fe = pd.concat([Xte_m_s.reset_index(drop=True), yrs_te2], axis=1)\n",
    "        Xte_m_fe = Xte_m_fe.reindex(columns=Xtr_m_fe.columns, fill_value=0)\n",
    "\n",
    "        y_tr2 = pd.to_numeric(train_valid[ycol], errors='coerce'); t_tr2 = pd.to_numeric(train_valid[tcol], errors='coerce')\n",
    "        y_te2 = pd.to_numeric(test_valid[ycol], errors='coerce'); t_te2 = pd.to_numeric(test_valid[tcol], errors='coerce')\n",
    "\n",
    "        train_mask2 = (~y_tr2.isna()) & (~t_tr2.isna())\n",
    "        if train_mask2.sum() >= 10 and np.nanvar(t_tr2[train_mask2].to_numpy()) > 0:\n",
    "            pos2 = np.where(train_mask2)[0]\n",
    "            Xtrain_sub2 = Xtr_m_fe.iloc[pos2,:].copy(); ytrain_sub2 = y_tr2.iloc[pos2].copy(); ttrain_sub2 = t_tr2.iloc[pos2].copy()\n",
    "            try:\n",
    "                p_model2 = LassoCV(cv=5, random_state=random_seed).fit(Xtrain_sub2, ttrain_sub2)\n",
    "            except:\n",
    "                from sklearn.linear_model import Lasso\n",
    "                p_model2 = Lasso().fit(Xtrain_sub2, ttrain_sub2)\n",
    "            p_hat_test2 = p_model2.predict(Xte_m_fe)\n",
    "            try:\n",
    "                m_model2 = RandomForestRegressor(n_estimators=n_trees, random_state=random_seed, n_jobs=-1).fit(Xtrain_sub2, ytrain_sub2)\n",
    "                m_hat_test2 = m_model2.predict(Xte_m_fe)\n",
    "            except:\n",
    "                m_ols2 = sm.OLS(ytrain_sub2.values, sm.add_constant(Xtrain_sub2)).fit()\n",
    "                m_hat_test2 = m_ols2.predict(sm.add_constant(Xte_m_fe))\n",
    "\n",
    "            test_mask2 = (~y_te2.isna()) & (~t_te2.isna())\n",
    "            if test_mask2.sum() > 0:\n",
    "                tp2 = np.where(test_mask2)[0]\n",
    "                u_vals2 = y_te2.to_numpy()[tp2] - m_hat_test2[tp2]\n",
    "                v_vals2 = t_te2.to_numpy()[tp2] - p_hat_test2[tp2]\n",
    "                base2 = fnum * 1000000 + 500000\n",
    "                idxs2 = [base2 + i for i in range(len(u_vals2))]\n",
    "                u_mund.append(pd.Series(u_vals2, index=idxs2))\n",
    "                v_mund.append(pd.Series(v_vals2, index=idxs2))\n",
    "                g_mund.append(pd.Series(test_valid.loc[tp2, idcol].values, index=idxs2))\n",
    "\n",
    "    # end folds\n",
    "    # pooled\n",
    "    if len(u_pooled) > 0:\n",
    "        u_p_all = pd.concat(u_pooled).sort_index(); v_p_all = pd.concat(v_pooled).sort_index(); groups_p = pd.concat(g_pooled).sort_index()\n",
    "        theta_p = (v_p_all * u_p_all).sum() / (v_p_all**2).sum()\n",
    "        res_p = sm.OLS(u_p_all.values, v_p_all.values).fit(cov_type='cluster', cov_kwds={'groups': groups_p.values})\n",
    "    else:\n",
    "        theta_p = np.nan; res_p = None\n",
    "    # mundlak\n",
    "    if len(u_mund) > 0:\n",
    "        u_m_all = pd.concat(u_mund).sort_index(); v_m_all = pd.concat(v_mund).sort_index(); groups_m = pd.concat(g_mund).sort_index()\n",
    "        theta_m = (v_m_all * u_m_all).sum() / (v_m_all**2).sum()\n",
    "        res_m = sm.OLS(u_m_all.values, v_m_all.values).fit(cov_type='cluster', cov_kwds={'groups': groups_m.values})\n",
    "    else:\n",
    "        theta_m = np.nan; res_m = None\n",
    "\n",
    "    return {'theta_pooled': theta_p, 'res_pooled': res_p, 'theta_mundlak': theta_m, 'res_mundlak': res_m}\n",
    "\n",
    "# Run\n",
    "out_both = run_pooled_and_mundlak(df, covs, mundlak_covs, idcol=idcol, timecol=timecol, ycol=ycol, tcol=tcol)\n",
    "print(\"Pooled theta:\", out_both['theta_pooled'])\n",
    "if out_both['res_pooled'] is not None:\n",
    "    print(\"Pooled SE:\", float(out_both['res_pooled'].bse[0]), \"p:\", float(out_both['res_pooled'].pvalues[0]))\n",
    "print(\"Mundlak theta:\", out_both['theta_mundlak'])\n",
    "if out_both['res_mundlak'] is not None:\n",
    "    print(\"Mundlak SE:\", float(out_both['res_mundlak'].bse[0]), \"p:\", float(out_both['res_mundlak'].pvalues[0]))\n",
    "\n",
    "# Save\n",
    "import pandas as pd, os\n",
    "pd.DataFrame([{'spec':'pooled','theta':out_both['theta_pooled'],'se':float(out_both['res_pooled'].bse[0]) if out_both['res_pooled'] is not None else None,\n",
    "               'pval': float(out_both['res_pooled'].pvalues[0]) if out_both['res_pooled'] is not None else None},\n",
    "              {'spec':'mundlak','theta':out_both['theta_mundlak'],'se':float(out_both['res_mundlak'].bse[0]) if out_both['res_mundlak'] is not None else None,\n",
    "               'pval': float(out_both['res_mundlak'].pvalues[0]) if out_both['res_mundlak'] is not None else None}]\n",
    "            ).to_csv(os.path.join(fold_output_dir, \"pooled_vs_mundlak_results.csv\"), index=False)\n",
    "\n",
    "print(\"Saved pooled_vs_mundlak_results.csv to\", fold_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "079b1ba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     df_loco \u001b[38;5;241m=\u001b[39m df_loco\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgain_lag1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgain_temp\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_dml_theta_and_se\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_loco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariates_to_use\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miso3c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimecol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mycol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgain_temp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2025\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     loco_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry_left_out\u001b[39m\u001b[38;5;124m'\u001b[39m: c, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m: out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mse\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbse[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m})\n\u001b[1;32m     15\u001b[0m loco_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(loco_results)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 85\u001b[0m, in \u001b[0;36mcompute_dml_theta_and_se\u001b[0;34m(df_local, covariates_list, idcol, timecol, ycol, tcol, n_trees, random_seed, min_train_frac)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     m_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39mn_trees, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrandom_seed)\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain_sub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     m_hat_test_full \u001b[38;5;241m=\u001b[39m m_model\u001b[38;5;241m.\u001b[39mpredict(X_test_fe)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    479\u001b[0m ]\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LOCO for lagged DML (run quickly; earlier code)\n",
    "countries = sorted(df['iso3c'].unique())\n",
    "loco_results = []\n",
    "for c in countries:\n",
    "    df_loco = df[df['iso3c'] != c].copy().reset_index(drop=True)\n",
    "    df_loco['gain_lag1'] = df_loco.groupby('iso3c')['gain'].shift(1)\n",
    "    df_loco = df_loco.dropna(subset=['gain_lag1', Y_col]).reset_index(drop=True)\n",
    "    if len(df_loco) < 100:\n",
    "        continue\n",
    "    df_loco = df_loco.rename(columns={'gain_lag1': 'gain_temp'})\n",
    "    out = compute_dml_theta_and_se(df_loco, covariates_to_use, idcol='iso3c', timecol='year',\n",
    "                                   ycol=Y_col, tcol='gain_temp', n_trees=200, random_seed=2025)\n",
    "    loco_results.append({'country_left_out': c, 'theta': out['theta'],\n",
    "                         'se': float(out['res'].bse[0]) if out['res'] is not None else None})\n",
    "loco_df = pd.DataFrame(loco_results).sort_values('theta')\n",
    "loco_df.to_csv(os.path.join(fold_output_dir, \"loco_lag1_results.csv\"), index=False)\n",
    "display(loco_df.head(8)); display(loco_df.tail(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ce724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DML with treatment = year-to-year change in gain (gain_diff1)\n",
    "df_diff = df.copy().reset_index(drop=True)\n",
    "df_diff['gain_diff1'] = df_diff.groupby('iso3c')['gain'].diff()\n",
    "# use lagged diff if you want pre-treatment (diff_{t-1})\n",
    "df_diff['gain_diff1_lag1'] = df_diff.groupby('iso3c')['gain_diff1'].shift(1)\n",
    "\n",
    "# Option A: treat contemporaneous change as treatment (gain_diff1)\n",
    "df_d1 = df_diff.dropna(subset=['gain_diff1', Y_col]).reset_index(drop=True)\n",
    "df_d1 = df_d1.rename(columns={'gain_diff1':'gain_temp'})\n",
    "out_d1 = compute_dml_theta_and_se(df_d1, covariates_to_use, idcol='iso3c', timecol='year',\n",
    "                                  ycol=Y_col, tcol='gain_temp', n_trees=200, random_seed=2025)\n",
    "print(\"DML on gain_diff1: theta, se:\", out_d1['theta'], out_d1['res'].bse[0] if out_d1['res'] is not None else None)\n",
    "\n",
    "# Option B: use lagged change (pre-treatment diff)\n",
    "df_dlag = df_diff.dropna(subset=['gain_diff1_lag1', Y_col]).reset_index(drop=True)\n",
    "df_dlag = df_dlag.rename(columns={'gain_diff1_lag1':'gain_temp'})\n",
    "out_dlag = compute_dml_theta_and_se(df_dlag, covariates_to_use, idcol='iso3c', timecol='year',\n",
    "                                    ycol=Y_col, tcol='gain_temp', n_trees=200, random_seed=2025)\n",
    "print(\"DML on lagged gain_diff1: theta, se:\", out_dlag['theta'], out_dlag['res'].bse[0] if out_dlag['res'] is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact runner: run SE-grid and p-learner sensitivity for lagged DML\n",
    "# (this reuses compute_dml_with_fixed_palpha and compute_dml_with_p_learner defined earlier)\n",
    "# Make sure to set df_lag1 or df with gain_lag1 present\n",
    "df_for_tests = df.copy()\n",
    "df_for_tests['gain_lag1'] = df_for_tests.groupby('iso3c')['gain'].shift(1)\n",
    "df_for_tests = df_for_tests.dropna(subset=['gain_lag1', Y_col]).reset_index(drop=True)\n",
    "df_for_tests = df_for_tests.rename(columns={'gain_lag1':'gain_temp'})\n",
    "\n",
    "# 3a. SE-grid (use alpha_grid computed earlier; if not run, compute using LassoCV on this df)\n",
    "# (you can reuse the alpha_grid computation cell from earlier)\n",
    "# Then use compute_dml_with_fixed_palpha(df_for_tests, covariates_to_use, palpha=a) for each a.\n",
    "\n",
    "# 3b. p-learner sensitivity: try ['lasso','elastic','xgb'] if available\n",
    "learners = ['lasso', 'elastic']\n",
    "try:\n",
    "    import xgboost\n",
    "    learners.append('xgb')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "sens = []\n",
    "for learner in learners:\n",
    "    out = compute_dml_with_p_learner(df_for_tests, covariates_to_use, p_learner=learner)\n",
    "    sens.append({'learner': learner, 'theta': out['theta'], 'se': float(out['res'].bse[0]) if out['res'] is not None else None})\n",
    "pd.DataFrame(sens).to_csv(os.path.join(fold_output_dir, \"lagged_p_learner_sensitivity.csv\"), index=False)\n",
    "print(\"Saved p-learner sensitivity for lagged spec.\")\n",
    "display(pd.DataFrame(sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wild cluster bootstrap for lagged DML (use out_lag1 results: u_all, v_all, groups)\n",
    "if 'out_lag1' not in globals() or out_lag1.get('u_all') is None:\n",
    "    raise RuntimeError(\"Please ensure out_lag1 exists in environment from your lagged DML run.\")\n",
    "u_all = out_lag1['u_all']; v_all = out_lag1['v_all']; groups_all = out_lag1['groups']\n",
    "# same bootstrap as before (Rademacher)\n",
    "import numpy as np, random, statsmodels.api as sm\n",
    "res0 = sm.OLS(u_all.values, v_all.values).fit(cov_type='cluster', cov_kwds={'groups': groups_all.values})\n",
    "beta0 = res0.params[0]; t_obs = res0.tvalues[0]\n",
    "cluster_ids = np.unique(groups_all.values)\n",
    "cluster_to_idx = {c: np.where(groups_all.values == c)[0] for c in cluster_ids}\n",
    "def wild_once(u_vals, v_vals, beta_hat):\n",
    "    eps = u_vals - beta_hat * v_vals\n",
    "    ws = {c: random.choice([1.0, -1.0]) for c in cluster_ids}\n",
    "    u_star = u_vals.copy()\n",
    "    for c, idxs in cluster_to_idx.items():\n",
    "        u_star[idxs] = beta_hat * v_vals[idxs] + ws[c] * eps[idxs]\n",
    "    resb = sm.OLS(u_star, v_vals).fit()\n",
    "    return (resb.params[0] - beta_hat) / resb.bse[0]\n",
    "B = 999\n",
    "t_stars = [wild_once(u_all.values, v_all.values, beta0) for _ in range(B)]\n",
    "p_boot = np.mean(np.abs(t_stars) >= np.abs(t_obs))\n",
    "print(\"Wild cluster bootstrap p-value:\", p_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute country contributions to numerator = sum_i v_i * u_i, and denominator = sum v_i^2\n",
    "df_uv = pd.DataFrame({'u': out_lag1['u_all'], 'v': out_lag1['v_all'], 'iso3c': out_lag1['groups']})\n",
    "df_uv['contrib'] = df_uv['u'] * df_uv['v']    # contribution to numerator\n",
    "country_contrib = df_uv.groupby('iso3c').agg(n_obs=('u','size'), sum_contrib=('contrib','sum'), sum_v2=('v', lambda s: (s**2).sum()))\n",
    "country_contrib['pct_numerator'] = country_contrib['sum_contrib'] / country_contrib['sum_contrib'].sum()\n",
    "country_contrib = country_contrib.sort_values('pct_numerator', ascending=False)\n",
    "country_contrib.to_csv(os.path.join(fold_output_dir, \"lagged_country_contributions.csv\"))\n",
    "display(country_contrib.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ab95e",
   "metadata": {},
   "source": [
    "# figuring it out.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f3055ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running full-sample lagged DML (t = gain_lag1) ...\n",
      "LOYO DML done in 13.1s; theta=0.465011; stacked rows=1468; folds used=28\n",
      "Saved dml_lag1_full_summary.csv to artifacts/dml_pooled\n",
      "Theta (lag1): {'theta': 0.4650110684887605, 'se': 0.29437564383715037, 'pval': 0.11418658843783448}\n",
      "Saved lagged_country_contributions.csv to artifacts/dml_pooled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3c</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>sum_contrib</th>\n",
       "      <th>sum_v2</th>\n",
       "      <th>pct_numerator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BGR</td>\n",
       "      <td>28</td>\n",
       "      <td>17246.807412</td>\n",
       "      <td>14419.408508</td>\n",
       "      <td>1.013371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BGD</td>\n",
       "      <td>20</td>\n",
       "      <td>45.614607</td>\n",
       "      <td>652.447146</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>16</td>\n",
       "      <td>38.900907</td>\n",
       "      <td>45.777355</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>COL</td>\n",
       "      <td>17</td>\n",
       "      <td>19.098528</td>\n",
       "      <td>314.435708</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MLT</td>\n",
       "      <td>28</td>\n",
       "      <td>18.290525</td>\n",
       "      <td>298.014846</td>\n",
       "      <td>0.001075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NOR</td>\n",
       "      <td>28</td>\n",
       "      <td>16.228809</td>\n",
       "      <td>939.061621</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PAK</td>\n",
       "      <td>28</td>\n",
       "      <td>15.671617</td>\n",
       "      <td>369.073812</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CIV</td>\n",
       "      <td>5</td>\n",
       "      <td>14.598417</td>\n",
       "      <td>95.926293</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>VNM</td>\n",
       "      <td>14</td>\n",
       "      <td>12.614045</td>\n",
       "      <td>33.301829</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>TUR</td>\n",
       "      <td>13</td>\n",
       "      <td>11.083187</td>\n",
       "      <td>66.167886</td>\n",
       "      <td>0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CHN</td>\n",
       "      <td>16</td>\n",
       "      <td>10.638452</td>\n",
       "      <td>453.762486</td>\n",
       "      <td>0.000625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAN</td>\n",
       "      <td>28</td>\n",
       "      <td>9.683556</td>\n",
       "      <td>411.552707</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>KOR</td>\n",
       "      <td>23</td>\n",
       "      <td>9.626532</td>\n",
       "      <td>344.002865</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>POL</td>\n",
       "      <td>24</td>\n",
       "      <td>8.836243</td>\n",
       "      <td>273.684110</td>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NZL</td>\n",
       "      <td>28</td>\n",
       "      <td>8.048627</td>\n",
       "      <td>1121.926538</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>IND</td>\n",
       "      <td>28</td>\n",
       "      <td>6.947283</td>\n",
       "      <td>491.566116</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DEU</td>\n",
       "      <td>28</td>\n",
       "      <td>6.902973</td>\n",
       "      <td>358.994270</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>PRT</td>\n",
       "      <td>28</td>\n",
       "      <td>4.906455</td>\n",
       "      <td>280.480875</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>IDN</td>\n",
       "      <td>14</td>\n",
       "      <td>3.909869</td>\n",
       "      <td>143.407478</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PHL</td>\n",
       "      <td>27</td>\n",
       "      <td>3.536947</td>\n",
       "      <td>297.622825</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iso3c  n_obs   sum_contrib        sum_v2  pct_numerator\n",
       "6    BGR     28  17246.807412  14419.408508       1.013371\n",
       "5    BGD     20     45.614607    652.447146       0.002680\n",
       "66   ZMB     16     38.900907     45.777355       0.002286\n",
       "14   COL     17     19.098528    314.435708       0.001122\n",
       "41   MLT     28     18.290525    298.014846       0.001075\n",
       "46   NOR     28     16.228809    939.061621       0.000954\n",
       "48   PAK     28     15.671617    369.073812       0.000921\n",
       "13   CIV      5     14.598417     95.926293       0.000858\n",
       "64   VNM     14     12.614045     33.301829       0.000741\n",
       "62   TUR     13     11.083187     66.167886       0.000651\n",
       "12   CHN     16     10.638452    453.762486       0.000625\n",
       "9    CAN     28      9.683556    411.552707       0.000569\n",
       "35   KOR     23      9.626532    344.002865       0.000566\n",
       "51   POL     24      8.836243    273.684110       0.000519\n",
       "47   NZL     28      8.048627   1121.926538       0.000473\n",
       "28   IND     28      6.947283    491.566116       0.000408\n",
       "17   DEU     28      6.902973    358.994270       0.000406\n",
       "52   PRT     28      4.906455    280.480875       0.000288\n",
       "27   IDN     14      3.909869    143.407478       0.000230\n",
       "50   PHL     27      3.536947    297.622825       0.000208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 1: Full-sample lagged DML (LOYO) + per-country contribution check\n",
    "import numpy as np, pandas as pd, os, time\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# params\n",
    "idcol = 'iso3c'\n",
    "timecol = 'year'\n",
    "tcol_input = 'gain'        # original gain column\n",
    "tlag_name = 'gain_lag1'    # we'll create this\n",
    "n_trees = 200\n",
    "random_seed = 2025\n",
    "min_train_rows = 10\n",
    "\n",
    "# ensure output folder\n",
    "fold_output_dir = fold_output_dir if 'fold_output_dir' in globals() else \"artifacts\"\n",
    "os.makedirs(fold_output_dir, exist_ok=True)\n",
    "\n",
    "# create lag column\n",
    "df = df.copy().reset_index(drop=True)\n",
    "df[tlag_name] = df.groupby(idcol)[tcol_input].shift(1)\n",
    "\n",
    "# helper: LOYO DML function (returns dict with theta, res, u_all, v_all, groups)\n",
    "def run_dml_loyo(df_local, covs, idcol='iso3c', timecol='year', ycol=Y_col, tcol=tlag_name,\n",
    "                 n_trees=200, random_seed=2025, min_train_rows=10):\n",
    "    years = sorted(df_local[timecol].dropna().unique())\n",
    "    u_list = []; v_list = []; groups_list = []; diag = []\n",
    "    t0 = time.time()\n",
    "    for fnum, y in enumerate(years):\n",
    "        train = df_local[df_local[timecol] != y].reset_index(drop=True).copy()\n",
    "        test  = df_local[df_local[timecol] == y].reset_index(drop=True).copy()\n",
    "\n",
    "        # prepare X\n",
    "        covs_present = [c for c in covs if c in train.columns]\n",
    "        if len(covs_present) == 0:\n",
    "            continue\n",
    "        Xtr = train[covs_present].apply(pd.to_numeric, errors='coerce')\n",
    "        Xte = test[covs_present].apply(pd.to_numeric, errors='coerce')\n",
    "        ytr = pd.to_numeric(train[ycol], errors='coerce') if ycol in train.columns else pd.Series(np.nan, index=train.index)\n",
    "        yte = pd.to_numeric(test[ycol], errors='coerce') if ycol in test.columns else pd.Series(np.nan, index=test.index)\n",
    "        ttr = pd.to_numeric(train[tcol], errors='coerce') if tcol in train.columns else pd.Series(np.nan, index=train.index)\n",
    "        tte = pd.to_numeric(test[tcol], errors='coerce') if tcol in test.columns else pd.Series(np.nan, index=test.index)\n",
    "\n",
    "        # impute/scale on train\n",
    "        try:\n",
    "            imp = KNNImputer(n_neighbors=5)\n",
    "            Xtr_imp = pd.DataFrame(imp.fit_transform(Xtr), columns=Xtr.columns)\n",
    "            Xte_imp = pd.DataFrame(imp.transform(Xte), columns=Xte.columns)\n",
    "        except Exception:\n",
    "            Xtr_imp = Xtr.fillna(Xtr.mean()); Xte_imp = Xte.fillna(Xtr.mean())\n",
    "        try:\n",
    "            sc = StandardScaler()\n",
    "            Xtr_s = pd.DataFrame(sc.fit_transform(Xtr_imp), columns=Xtr_imp.columns)\n",
    "            Xte_s = pd.DataFrame(sc.transform(Xte_imp), columns=Xte_imp.columns)\n",
    "        except Exception:\n",
    "            Xtr_s = Xtr_imp; Xte_s = Xte_imp\n",
    "\n",
    "        # add year dummies (train -> test alignment)\n",
    "        yrs_tr = pd.get_dummies(train[timecol], prefix='yr').reset_index(drop=True)\n",
    "        yrs_te = pd.get_dummies(test[timecol], prefix='yr').reindex(columns=yrs_tr.columns, fill_value=0).reset_index(drop=True)\n",
    "        Xtrain_full = pd.concat([Xtr_s.reset_index(drop=True), yrs_tr], axis=1)\n",
    "        Xtest_full  = pd.concat([Xte_s.reset_index(drop=True), yrs_te], axis=1)\n",
    "        Xtest_full  = Xtest_full.reindex(columns=Xtrain_full.columns, fill_value=0)\n",
    "\n",
    "        # training mask\n",
    "        train_mask = (~ytr.isna()) & (~ttr.isna())\n",
    "        if train_mask.sum() < min_train_rows:\n",
    "            continue\n",
    "        pos = np.where(train_mask)[0]\n",
    "        Xtrain_sub = Xtrain_full.iloc[pos, :].copy()\n",
    "        ytrain_sub = ytr.iloc[pos].copy()\n",
    "        ttrain_sub = ttr.iloc[pos].copy()\n",
    "        # require variation in t\n",
    "        if np.nanvar(ttrain_sub.to_numpy()) == 0:\n",
    "            continue\n",
    "\n",
    "        # fit p(X) with LassoCV\n",
    "        try:\n",
    "            p_model = LassoCV(cv=5, random_state=random_seed).fit(Xtrain_sub, ttrain_sub)\n",
    "            p_hat_test = p_model.predict(Xtest_full)\n",
    "        except Exception:\n",
    "            from sklearn.linear_model import Lasso\n",
    "            p_model = Lasso(max_iter=10000).fit(Xtrain_sub, ttrain_sub)\n",
    "            p_hat_test = p_model.predict(Xtest_full)\n",
    "\n",
    "        # fit m(X) with RandomForest\n",
    "        try:\n",
    "            m_model = RandomForestRegressor(n_estimators=n_trees, random_state=random_seed, n_jobs=-1).fit(Xtrain_sub, ytrain_sub)\n",
    "            m_hat_test = m_model.predict(Xtest_full)\n",
    "        except Exception:\n",
    "            m_ols = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "            m_hat_test = m_ols.predict(sm.add_constant(Xtest_full))\n",
    "\n",
    "        # collect test residuals where y and t present\n",
    "        test_mask = (~yte.isna()) & (~tte.isna())\n",
    "        if test_mask.sum() == 0:\n",
    "            continue\n",
    "        test_pos = np.where(test_mask)[0]\n",
    "        u_hat = (yte.to_numpy()[test_pos] - m_hat_test[test_pos])\n",
    "        v_hat = (tte.to_numpy()[test_pos] - p_hat_test[test_pos])\n",
    "        base = fnum * 1000000\n",
    "        idxs = [base + i for i in range(len(u_hat))]\n",
    "        u_list.append(pd.Series(u_hat, index=idxs))\n",
    "        v_list.append(pd.Series(v_hat, index=idxs))\n",
    "        groups_list.append(pd.Series(test.loc[test_pos, idcol].values, index=idxs))\n",
    "        diag.append({'fold': fnum, 'year_holdout': y, 'n_train': len(train), 'n_test': len(test), 'n_kept': len(u_hat)})\n",
    "\n",
    "    # aggregate\n",
    "    if len(u_list) == 0:\n",
    "        return {'theta': np.nan, 'res': None, 'u_all': None, 'v_all': None, 'groups': None, 'diag': pd.DataFrame(diag)}\n",
    "    u_all = pd.concat(u_list).sort_index()\n",
    "    v_all = pd.concat(v_list).sort_index()\n",
    "    groups = pd.concat(groups_list).sort_index()\n",
    "    theta = (v_all * u_all).sum() / (v_all**2).sum()\n",
    "    res = sm.OLS(u_all.values, v_all.values).fit(cov_type='cluster', cov_kwds={'groups': groups.values})\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"LOYO DML done in {elapsed:.1f}s; theta={theta:.6g}; stacked rows={len(u_all)}; folds used={len(u_list)}\")\n",
    "    return {'theta': float(theta), 'res': res, 'u_all': u_all, 'v_all': v_all, 'groups': groups, 'diag': pd.DataFrame(diag)}\n",
    "\n",
    "# Run full-sample lagged DML\n",
    "print(\"Running full-sample lagged DML (t = gain_lag1) ...\")\n",
    "df_full = df.dropna(subset=[Y_col]).reset_index(drop=True)\n",
    "out_lag1 = run_dml_loyo(df_full, covariates_to_use, idcol=idcol, timecol=timecol, ycol=Y_col, tcol=tlag_name,\n",
    "                        n_trees=n_trees, random_seed=random_seed, min_train_rows=min_train_rows)\n",
    "\n",
    "# save main summary\n",
    "if out_lag1['res'] is not None:\n",
    "    summary = {'theta': out_lag1['theta'], 'se': float(out_lag1['res'].bse[0]), 'pval': float(out_lag1['res'].pvalues[0])}\n",
    "else:\n",
    "    summary = {'theta': out_lag1['theta'], 'se': None, 'pval': None}\n",
    "pd.Series(summary).to_csv(os.path.join(fold_output_dir, \"dml_lag1_full_summary.csv\"))\n",
    "print(\"Saved dml_lag1_full_summary.csv to\", fold_output_dir)\n",
    "print(\"Theta (lag1):\", summary)\n",
    "\n",
    "# Per-country contribution: v * u numerator and v^2 denominator share\n",
    "if out_lag1['u_all'] is not None:\n",
    "    df_uv = pd.DataFrame({'u': out_lag1['u_all'], 'v': out_lag1['v_all'], 'iso3c': out_lag1['groups']})\n",
    "    df_uv['contrib'] = df_uv['u'] * df_uv['v']\n",
    "    country_contrib = df_uv.groupby('iso3c').agg(\n",
    "        n_obs=('u','size'),\n",
    "        sum_contrib=('contrib','sum'),\n",
    "        sum_v2=('v', lambda s: (s**2).sum())\n",
    "    ).reset_index()\n",
    "    total_num = country_contrib['sum_contrib'].sum()\n",
    "    country_contrib['pct_numerator'] = country_contrib['sum_contrib'] / (total_num + 1e-20)\n",
    "    country_contrib = country_contrib.sort_values('pct_numerator', ascending=False)\n",
    "    country_contrib.to_csv(os.path.join(fold_output_dir, \"lagged_country_contributions.csv\"), index=False)\n",
    "    print(\"Saved lagged_country_contributions.csv to\", fold_output_dir)\n",
    "    display(country_contrib.head(20))\n",
    "else:\n",
    "    print(\"No residuals produced; cannot compute country contributions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "166abf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LOCO over 67 countries. This may take some minutes...\n",
      "LOYO DML done in 12.7s; theta=0.449931; stacked rows=1460; folds used=28\n",
      "LOYO DML done in 12.6s; theta=0.509478; stacked rows=1458; folds used=28\n",
      "LOYO DML done in 12.8s; theta=0.444758; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 12.7s; theta=0.444458; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 12.8s; theta=0.469172; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 13.1s; theta=0.370846; stacked rows=1448; folds used=28\n",
      "LOYO DML done in 12.5s; theta=-0.0086125; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 15.3s; theta=0.44987; stacked rows=1452; folds used=28\n",
      "LOYO DML done in 13.7s; theta=0.283721; stacked rows=1449; folds used=28\n",
      "LOYO DML done in 13.8s; theta=0.440708; stacked rows=1440; folds used=28\n",
      "LOCO progress: 10/67\n",
      "LOYO DML done in 14.6s; theta=0.449166; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 16.2s; theta=0.456267; stacked rows=1464; folds used=28\n",
      "LOYO DML done in 17.4s; theta=0.493847; stacked rows=1452; folds used=28\n",
      "LOYO DML done in 16.9s; theta=0.450499; stacked rows=1463; folds used=28\n",
      "LOYO DML done in 16.6s; theta=0.42515; stacked rows=1451; folds used=28\n",
      "LOYO DML done in 16.2s; theta=0.44368; stacked rows=1442; folds used=28\n",
      "LOYO DML done in 15.8s; theta=0.454465; stacked rows=1445; folds used=28\n",
      "LOYO DML done in 15.7s; theta=0.457922; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 16.4s; theta=0.428609; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 20.0s; theta=0.424463; stacked rows=1457; folds used=28\n",
      "LOCO progress: 20/67\n",
      "LOYO DML done in 16.6s; theta=0.436796; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 17.2s; theta=0.443065; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 16.0s; theta=0.430955; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 16.0s; theta=0.448578; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 15.6s; theta=0.444673; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 16.1s; theta=0.448925; stacked rows=1453; folds used=28\n",
      "LOYO DML done in 15.5s; theta=0.469395; stacked rows=1444; folds used=28\n",
      "LOYO DML done in 15.5s; theta=0.458246; stacked rows=1454; folds used=28\n",
      "LOYO DML done in 15.5s; theta=0.370006; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 15.9s; theta=0.470003; stacked rows=1440; folds used=28\n",
      "LOCO progress: 30/67\n",
      "LOYO DML done in 19.5s; theta=0.445489; stacked rows=1449; folds used=28\n",
      "LOYO DML done in 15.7s; theta=0.45009; stacked rows=1457; folds used=28\n",
      "LOYO DML done in 15.8s; theta=0.44359; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 15.8s; theta=0.450438; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 15.7s; theta=0.318432; stacked rows=1453; folds used=28\n",
      "LOYO DML done in 16.1s; theta=0.459503; stacked rows=1445; folds used=28\n",
      "LOYO DML done in 15.7s; theta=0.451449; stacked rows=1459; folds used=28\n",
      "LOYO DML done in 15.5s; theta=0.449763; stacked rows=1442; folds used=28\n",
      "LOYO DML done in 15.5s; theta=0.501141; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 15.7s; theta=0.468853; stacked rows=1443; folds used=28\n",
      "LOCO progress: 40/67\n",
      "LOYO DML done in 16.1s; theta=0.446445; stacked rows=1446; folds used=28\n",
      "LOYO DML done in 19.5s; theta=0.455156; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 17.5s; theta=0.402731; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 17.0s; theta=0.273876; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 17.8s; theta=0.458739; stacked rows=1452; folds used=28\n",
      "LOYO DML done in 17.7s; theta=0.451945; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 17.7s; theta=0.460567; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 17.6s; theta=0.474442; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 19.5s; theta=0.276399; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 20.5s; theta=0.453238; stacked rows=1450; folds used=28\n",
      "LOCO progress: 50/67\n",
      "LOYO DML done in 19.6s; theta=0.458794; stacked rows=1441; folds used=28\n",
      "LOYO DML done in 19.2s; theta=0.461606; stacked rows=1444; folds used=28\n",
      "LOYO DML done in 17.8s; theta=0.458469; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 16.7s; theta=0.490165; stacked rows=1457; folds used=28\n",
      "LOYO DML done in 17.1s; theta=0.458223; stacked rows=1446; folds used=28\n",
      "LOYO DML done in 17.7s; theta=0.018986; stacked rows=1441; folds used=28\n",
      "LOYO DML done in 18.3s; theta=0.454457; stacked rows=1443; folds used=28\n",
      "LOYO DML done in 18.4s; theta=0.444307; stacked rows=1463; folds used=28\n",
      "LOYO DML done in 18.6s; theta=0.458089; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 20.8s; theta=0.465541; stacked rows=1447; folds used=28\n",
      "LOCO progress: 60/67\n",
      "LOYO DML done in 12.0s; theta=0.471665; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 12.3s; theta=0.449775; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 1027.6s; theta=0.443843; stacked rows=1455; folds used=28\n",
      "LOYO DML done in 12.4s; theta=0.471547; stacked rows=1457; folds used=28\n",
      "LOYO DML done in 14.8s; theta=0.441962; stacked rows=1454; folds used=28\n",
      "LOYO DML done in 16.0s; theta=0.443751; stacked rows=1440; folds used=28\n",
      "LOYO DML done in 15.6s; theta=0.462153; stacked rows=1452; folds used=28\n",
      "Saved loco_lag1_results.csv to artifacts/dml_pooled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_left_out</th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGR</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUS</td>\n",
       "      <td>0.018986</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>1441</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAM</td>\n",
       "      <td>0.273876</td>\n",
       "      <td>0.265633</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAK</td>\n",
       "      <td>0.276399</td>\n",
       "      <td>0.267992</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BWA</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.271264</td>\n",
       "      <td>1449</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KEN</td>\n",
       "      <td>0.318432</td>\n",
       "      <td>0.295501</td>\n",
       "      <td>1453</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IND</td>\n",
       "      <td>0.370006</td>\n",
       "      <td>0.321620</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BGD</td>\n",
       "      <td>0.370846</td>\n",
       "      <td>0.327519</td>\n",
       "      <td>1448</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MYS</td>\n",
       "      <td>0.402731</td>\n",
       "      <td>0.329475</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EGY</td>\n",
       "      <td>0.424463</td>\n",
       "      <td>0.336336</td>\n",
       "      <td>1457</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_left_out     theta        se  n_obs note\n",
       "0              BGR -0.008612  0.010527   1440     \n",
       "1              RUS  0.018986  0.018006   1441     \n",
       "2              NAM  0.273876  0.265633   1440     \n",
       "3              PAK  0.276399  0.267992   1440     \n",
       "4              BWA  0.283721  0.271264   1449     \n",
       "5              KEN  0.318432  0.295501   1453     \n",
       "6              IND  0.370006  0.321620   1440     \n",
       "7              BGD  0.370846  0.327519   1448     \n",
       "8              MYS  0.402731  0.329475   1440     \n",
       "9              EGY  0.424463  0.336336   1457     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_left_out</th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>BEL</td>\n",
       "      <td>0.469172</td>\n",
       "      <td>0.334726</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>HUN</td>\n",
       "      <td>0.469395</td>\n",
       "      <td>0.336137</td>\n",
       "      <td>1444</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>IRL</td>\n",
       "      <td>0.470003</td>\n",
       "      <td>0.331697</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>UGA</td>\n",
       "      <td>0.471547</td>\n",
       "      <td>0.321703</td>\n",
       "      <td>1457</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SWE</td>\n",
       "      <td>0.471665</td>\n",
       "      <td>0.341568</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NZL</td>\n",
       "      <td>0.474442</td>\n",
       "      <td>0.344252</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>QAT</td>\n",
       "      <td>0.490165</td>\n",
       "      <td>0.325753</td>\n",
       "      <td>1457</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CHN</td>\n",
       "      <td>0.493847</td>\n",
       "      <td>0.278412</td>\n",
       "      <td>1452</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>LUX</td>\n",
       "      <td>0.501141</td>\n",
       "      <td>0.317155</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ARM</td>\n",
       "      <td>0.509478</td>\n",
       "      <td>0.325739</td>\n",
       "      <td>1458</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_left_out     theta        se  n_obs note\n",
       "57              BEL  0.469172  0.334726   1440     \n",
       "58              HUN  0.469395  0.336137   1444     \n",
       "59              IRL  0.470003  0.331697   1440     \n",
       "60              UGA  0.471547  0.321703   1457     \n",
       "61              SWE  0.471665  0.341568   1440     \n",
       "62              NZL  0.474442  0.344252   1440     \n",
       "63              QAT  0.490165  0.325753   1457     \n",
       "64              CHN  0.493847  0.278412   1452     \n",
       "65              LUX  0.501141  0.317155   1440     \n",
       "66              ARM  0.509478  0.325739   1458     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCO theta: min, 10th, 25th, median, 75th, 90th, max:\n",
      "{0.0: -0.008612496781852916, 0.1: 0.3705099914014955, 0.25: 0.44332735225749853, 0.5: 0.44993142001565467, 0.75: 0.45876652453861566, 0.9: 0.4706208405842573, 1.0: 0.5094781079936738}\n",
      "Top 10 countries by absolute change in theta when omitted:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_left_out</th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>note</th>\n",
       "      <th>theta_diff</th>\n",
       "      <th>abs_theta_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGR</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "      <td>-0.473624</td>\n",
       "      <td>0.473624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUS</td>\n",
       "      <td>0.018986</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>1441</td>\n",
       "      <td></td>\n",
       "      <td>-0.446025</td>\n",
       "      <td>0.446025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAM</td>\n",
       "      <td>0.273876</td>\n",
       "      <td>0.265633</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "      <td>-0.191135</td>\n",
       "      <td>0.191135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAK</td>\n",
       "      <td>0.276399</td>\n",
       "      <td>0.267992</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "      <td>-0.188612</td>\n",
       "      <td>0.188612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BWA</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.271264</td>\n",
       "      <td>1449</td>\n",
       "      <td></td>\n",
       "      <td>-0.181290</td>\n",
       "      <td>0.181290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KEN</td>\n",
       "      <td>0.318432</td>\n",
       "      <td>0.295501</td>\n",
       "      <td>1453</td>\n",
       "      <td></td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>0.146579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IND</td>\n",
       "      <td>0.370006</td>\n",
       "      <td>0.321620</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "      <td>-0.095005</td>\n",
       "      <td>0.095005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BGD</td>\n",
       "      <td>0.370846</td>\n",
       "      <td>0.327519</td>\n",
       "      <td>1448</td>\n",
       "      <td></td>\n",
       "      <td>-0.094165</td>\n",
       "      <td>0.094165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MYS</td>\n",
       "      <td>0.402731</td>\n",
       "      <td>0.329475</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "      <td>-0.062281</td>\n",
       "      <td>0.062281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ARM</td>\n",
       "      <td>0.509478</td>\n",
       "      <td>0.325739</td>\n",
       "      <td>1458</td>\n",
       "      <td></td>\n",
       "      <td>0.044467</td>\n",
       "      <td>0.044467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_left_out     theta        se  n_obs note  theta_diff  \\\n",
       "0               BGR -0.008612  0.010527   1440        -0.473624   \n",
       "1               RUS  0.018986  0.018006   1441        -0.446025   \n",
       "2               NAM  0.273876  0.265633   1440        -0.191135   \n",
       "3               PAK  0.276399  0.267992   1440        -0.188612   \n",
       "4               BWA  0.283721  0.271264   1449        -0.181290   \n",
       "5               KEN  0.318432  0.295501   1453        -0.146579   \n",
       "6               IND  0.370006  0.321620   1440        -0.095005   \n",
       "7               BGD  0.370846  0.327519   1448        -0.094165   \n",
       "8               MYS  0.402731  0.329475   1440        -0.062281   \n",
       "66              ARM  0.509478  0.325739   1458         0.044467   \n",
       "\n",
       "    abs_theta_diff  \n",
       "0         0.473624  \n",
       "1         0.446025  \n",
       "2         0.191135  \n",
       "3         0.188612  \n",
       "4         0.181290  \n",
       "5         0.146579  \n",
       "6         0.095005  \n",
       "7         0.094165  \n",
       "8         0.062281  \n",
       "66        0.044467  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 2: LOCO for lagged DML\n",
    "import pandas as pd, os\n",
    "countries = sorted(df['iso3c'].dropna().unique())\n",
    "loco_rows = []\n",
    "min_sample_size = 50   # skip very small-sample exclusions (tune if needed)\n",
    "\n",
    "print(\"Running LOCO over\", len(countries), \"countries. This may take some minutes...\")\n",
    "\n",
    "for i, c in enumerate(countries):\n",
    "    df_loco = df[df['iso3c'] != c].copy().reset_index(drop=True)\n",
    "    # need lag column present\n",
    "    df_loco['gain_lag1'] = df_loco.groupby('iso3c')['gain'].shift(1)\n",
    "    # drop rows with missing outcome or treatment\n",
    "    df_loco = df_loco.dropna(subset=[Y_col, 'gain_lag1']).reset_index(drop=True)\n",
    "    if len(df_loco) < min_sample_size:\n",
    "        loco_rows.append({'country_left_out': c, 'theta': None, 'se': None, 'n_obs': len(df_loco), 'note': 'sample too small'})\n",
    "        continue\n",
    "    # run DML on df_loco - using the same run_dml_loyo function from CELL 1\n",
    "    try:\n",
    "        out = run_dml_loyo(df_loco, covariates_to_use, idcol=idcol, timecol=timecol, ycol=Y_col, tcol='gain_lag1',\n",
    "                            n_trees=n_trees, random_seed=random_seed, min_train_rows=min_train_rows)\n",
    "    except Exception as e:\n",
    "        loco_rows.append({'country_left_out': c, 'theta': None, 'se': None, 'n_obs': len(df_loco), 'note': f'error: {e}'})\n",
    "        continue\n",
    "    theta_c = out['theta']\n",
    "    se_c = float(out['res'].bse[0]) if out['res'] is not None else None\n",
    "    loco_rows.append({'country_left_out': c, 'theta': theta_c, 'se': se_c, 'n_obs': len(df_loco), 'note': ''})\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"LOCO progress: {i+1}/{len(countries)}\")\n",
    "\n",
    "loco_df = pd.DataFrame(loco_rows).sort_values('theta', na_position='first').reset_index(drop=True)\n",
    "loco_df.to_csv(os.path.join(fold_output_dir, \"loco_lag1_results.csv\"), index=False)\n",
    "print(\"Saved loco_lag1_results.csv to\", fold_output_dir)\n",
    "display(loco_df.head(10))\n",
    "display(loco_df.tail(10))\n",
    "\n",
    "# quick summary stats\n",
    "valid = loco_df.dropna(subset=['theta'])\n",
    "if len(valid) > 0:\n",
    "    print(\"LOCO theta: min, 10th, 25th, median, 75th, 90th, max:\")\n",
    "    print(valid['theta'].quantile([0.0,0.1,0.25,0.5,0.75,0.9,1.0]).to_dict())\n",
    "    # show top movers (countries whose omission changes theta relative to full-sample)\n",
    "    full_theta = out_lag1['theta'] if 'out_lag1' in globals() and out_lag1.get('theta') is not None else None\n",
    "    if full_theta is not None:\n",
    "        loco_df['theta_diff'] = loco_df['theta'].apply(lambda x: None if pd.isna(x) else (x - full_theta))\n",
    "        loco_df['abs_theta_diff'] = loco_df['theta_diff'].abs()\n",
    "        print(\"Top 10 countries by absolute change in theta when omitted:\")\n",
    "        display(loco_df.sort_values('abs_theta_diff', ascending=False).head(10))\n",
    "else:\n",
    "    print(\"No valid LOCO runs produced a theta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65844ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows for BGR:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3c</th>\n",
       "      <th>year</th>\n",
       "      <th>gain</th>\n",
       "      <th>sovereign_spread</th>\n",
       "      <th>sovereign_spread_lag1</th>\n",
       "      <th>gdp_annual_growth_rate</th>\n",
       "      <th>debt_to_gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1995</td>\n",
       "      <td>48.985823</td>\n",
       "      <td>57.291017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1996</td>\n",
       "      <td>49.407723</td>\n",
       "      <td>191.905063</td>\n",
       "      <td>57.291017</td>\n",
       "      <td>7.475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1997</td>\n",
       "      <td>50.414609</td>\n",
       "      <td>125.399665</td>\n",
       "      <td>191.905063</td>\n",
       "      <td>-14.350</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1998</td>\n",
       "      <td>50.339846</td>\n",
       "      <td>5.324559</td>\n",
       "      <td>125.399665</td>\n",
       "      <td>4.400</td>\n",
       "      <td>67.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1999</td>\n",
       "      <td>50.268918</td>\n",
       "      <td>4.669588</td>\n",
       "      <td>5.324559</td>\n",
       "      <td>-8.225</td>\n",
       "      <td>78.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2000</td>\n",
       "      <td>49.676519</td>\n",
       "      <td>1.490886</td>\n",
       "      <td>4.669588</td>\n",
       "      <td>5.950</td>\n",
       "      <td>73.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2001</td>\n",
       "      <td>49.710558</td>\n",
       "      <td>1.808094</td>\n",
       "      <td>1.490886</td>\n",
       "      <td>3.900</td>\n",
       "      <td>67.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2002</td>\n",
       "      <td>50.234597</td>\n",
       "      <td>2.195291</td>\n",
       "      <td>1.808094</td>\n",
       "      <td>5.750</td>\n",
       "      <td>53.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2003</td>\n",
       "      <td>51.140676</td>\n",
       "      <td>2.433512</td>\n",
       "      <td>2.195291</td>\n",
       "      <td>5.250</td>\n",
       "      <td>45.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2004</td>\n",
       "      <td>51.927374</td>\n",
       "      <td>1.086361</td>\n",
       "      <td>2.433512</td>\n",
       "      <td>6.600</td>\n",
       "      <td>37.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2005</td>\n",
       "      <td>51.951606</td>\n",
       "      <td>-0.415477</td>\n",
       "      <td>1.086361</td>\n",
       "      <td>6.975</td>\n",
       "      <td>28.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2006</td>\n",
       "      <td>51.329003</td>\n",
       "      <td>-0.609101</td>\n",
       "      <td>-0.415477</td>\n",
       "      <td>6.725</td>\n",
       "      <td>22.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2007</td>\n",
       "      <td>51.073758</td>\n",
       "      <td>-0.097402</td>\n",
       "      <td>-0.609101</td>\n",
       "      <td>6.975</td>\n",
       "      <td>17.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2008</td>\n",
       "      <td>50.913159</td>\n",
       "      <td>1.710619</td>\n",
       "      <td>-0.097402</td>\n",
       "      <td>6.075</td>\n",
       "      <td>14.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2009</td>\n",
       "      <td>51.343478</td>\n",
       "      <td>3.961568</td>\n",
       "      <td>1.710619</td>\n",
       "      <td>-3.475</td>\n",
       "      <td>14.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2010</td>\n",
       "      <td>51.333959</td>\n",
       "      <td>2.900316</td>\n",
       "      <td>3.961568</td>\n",
       "      <td>1.425</td>\n",
       "      <td>14.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2011</td>\n",
       "      <td>51.819201</td>\n",
       "      <td>2.345985</td>\n",
       "      <td>2.900316</td>\n",
       "      <td>2.350</td>\n",
       "      <td>14.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2012</td>\n",
       "      <td>52.116743</td>\n",
       "      <td>2.697882</td>\n",
       "      <td>2.345985</td>\n",
       "      <td>0.500</td>\n",
       "      <td>16.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2013</td>\n",
       "      <td>52.448877</td>\n",
       "      <td>1.183569</td>\n",
       "      <td>2.697882</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>17.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2014</td>\n",
       "      <td>53.077255</td>\n",
       "      <td>0.875374</td>\n",
       "      <td>1.183569</td>\n",
       "      <td>1.150</td>\n",
       "      <td>26.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2015</td>\n",
       "      <td>53.044633</td>\n",
       "      <td>0.690125</td>\n",
       "      <td>0.875374</td>\n",
       "      <td>3.350</td>\n",
       "      <td>25.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2016</td>\n",
       "      <td>53.016159</td>\n",
       "      <td>0.509108</td>\n",
       "      <td>0.690125</td>\n",
       "      <td>3.075</td>\n",
       "      <td>27.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2017</td>\n",
       "      <td>52.894087</td>\n",
       "      <td>-0.596568</td>\n",
       "      <td>0.509108</td>\n",
       "      <td>2.775</td>\n",
       "      <td>22.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2018</td>\n",
       "      <td>53.965269</td>\n",
       "      <td>-1.803595</td>\n",
       "      <td>-0.596568</td>\n",
       "      <td>2.800</td>\n",
       "      <td>20.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2019</td>\n",
       "      <td>54.056573</td>\n",
       "      <td>-1.048663</td>\n",
       "      <td>-1.803595</td>\n",
       "      <td>3.725</td>\n",
       "      <td>18.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2020</td>\n",
       "      <td>53.597382</td>\n",
       "      <td>-0.395815</td>\n",
       "      <td>-1.048663</td>\n",
       "      <td>-3.300</td>\n",
       "      <td>22.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2021</td>\n",
       "      <td>53.913427</td>\n",
       "      <td>-1.103390</td>\n",
       "      <td>-0.395815</td>\n",
       "      <td>7.300</td>\n",
       "      <td>22.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2022</td>\n",
       "      <td>53.183702</td>\n",
       "      <td>-0.209855</td>\n",
       "      <td>-1.103390</td>\n",
       "      <td>4.350</td>\n",
       "      <td>21.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BGR</td>\n",
       "      <td>2023</td>\n",
       "      <td>53.244991</td>\n",
       "      <td>0.738569</td>\n",
       "      <td>-0.209855</td>\n",
       "      <td>1.950</td>\n",
       "      <td>21.872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iso3c  year       gain  sovereign_spread  sovereign_spread_lag1  \\\n",
       "0    BGR  1995  48.985823         57.291017                    NaN   \n",
       "1    BGR  1996  49.407723        191.905063              57.291017   \n",
       "2    BGR  1997  50.414609        125.399665             191.905063   \n",
       "3    BGR  1998  50.339846          5.324559             125.399665   \n",
       "4    BGR  1999  50.268918          4.669588               5.324559   \n",
       "5    BGR  2000  49.676519          1.490886               4.669588   \n",
       "6    BGR  2001  49.710558          1.808094               1.490886   \n",
       "7    BGR  2002  50.234597          2.195291               1.808094   \n",
       "8    BGR  2003  51.140676          2.433512               2.195291   \n",
       "9    BGR  2004  51.927374          1.086361               2.433512   \n",
       "10   BGR  2005  51.951606         -0.415477               1.086361   \n",
       "11   BGR  2006  51.329003         -0.609101              -0.415477   \n",
       "12   BGR  2007  51.073758         -0.097402              -0.609101   \n",
       "13   BGR  2008  50.913159          1.710619              -0.097402   \n",
       "14   BGR  2009  51.343478          3.961568               1.710619   \n",
       "15   BGR  2010  51.333959          2.900316               3.961568   \n",
       "16   BGR  2011  51.819201          2.345985               2.900316   \n",
       "17   BGR  2012  52.116743          2.697882               2.345985   \n",
       "18   BGR  2013  52.448877          1.183569               2.697882   \n",
       "19   BGR  2014  53.077255          0.875374               1.183569   \n",
       "20   BGR  2015  53.044633          0.690125               0.875374   \n",
       "21   BGR  2016  53.016159          0.509108               0.690125   \n",
       "22   BGR  2017  52.894087         -0.596568               0.509108   \n",
       "23   BGR  2018  53.965269         -1.803595              -0.596568   \n",
       "24   BGR  2019  54.056573         -1.048663              -1.803595   \n",
       "25   BGR  2020  53.597382         -0.395815              -1.048663   \n",
       "26   BGR  2021  53.913427         -1.103390              -0.395815   \n",
       "27   BGR  2022  53.183702         -0.209855              -1.103390   \n",
       "28   BGR  2023  53.244991          0.738569              -0.209855   \n",
       "\n",
       "    gdp_annual_growth_rate  debt_to_gdp  \n",
       "0                      NaN          NaN  \n",
       "1                    7.475          NaN  \n",
       "2                  -14.350          NaN  \n",
       "3                    4.400       67.322  \n",
       "4                   -8.225       78.671  \n",
       "5                    5.950       73.341  \n",
       "6                    3.900       67.060  \n",
       "7                    5.750       53.404  \n",
       "8                    5.250       45.428  \n",
       "9                    6.600       37.764  \n",
       "10                   6.975       28.472  \n",
       "11                   6.725       22.608  \n",
       "12                   6.975       17.588  \n",
       "13                   6.075       14.702  \n",
       "14                  -3.475       14.540  \n",
       "15                   1.425       14.064  \n",
       "16                   2.350       14.335  \n",
       "17                   0.500       16.545  \n",
       "18                  -0.600       17.165  \n",
       "19                   1.150       26.266  \n",
       "20                   3.350       25.359  \n",
       "21                   3.075       27.007  \n",
       "22                   2.775       22.919  \n",
       "23                   2.800       20.100  \n",
       "24                   3.725       18.382  \n",
       "25                  -3.300       22.715  \n",
       "26                   7.300       22.362  \n",
       "27                   4.350       21.457  \n",
       "28                   1.950       21.872  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A: show raw rows for Bulgaria (BGR) and compute changes\n",
    "bgr = df[df['iso3c']=='BGR'].copy().sort_values(['year']).reset_index(drop=True)\n",
    "cols = ['iso3c','year','gain','sovereign_spread','sovereign_spread_lag1','gdp_annual_growth_rate','debt_to_gdp']\n",
    "print(\"Rows for BGR:\")\n",
    "display(bgr[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6af1b79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical BGR event rows: 3\n",
      "Data-driven extreme rows: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3c</th>\n",
       "      <th>year</th>\n",
       "      <th>gain</th>\n",
       "      <th>gain_diff1</th>\n",
       "      <th>sovereign_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1995</td>\n",
       "      <td>48.985823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.291017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1996</td>\n",
       "      <td>49.407723</td>\n",
       "      <td>0.421899</td>\n",
       "      <td>191.905063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1997</td>\n",
       "      <td>50.414609</td>\n",
       "      <td>1.006886</td>\n",
       "      <td>125.399665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iso3c  year       gain  gain_diff1  sovereign_spread\n",
       "128   BGR  1995  48.985823         NaN         57.291017\n",
       "129   BGR  1996  49.407723    0.421899        191.905063\n",
       "130   BGR  1997  50.414609    1.006886        125.399665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3c</th>\n",
       "      <th>year</th>\n",
       "      <th>gain</th>\n",
       "      <th>gain_diff1</th>\n",
       "      <th>sovereign_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2019</td>\n",
       "      <td>48.720793</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>25.216374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1995</td>\n",
       "      <td>48.985823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.291017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1996</td>\n",
       "      <td>49.407723</td>\n",
       "      <td>0.421899</td>\n",
       "      <td>191.905063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>BGR</td>\n",
       "      <td>1997</td>\n",
       "      <td>50.414609</td>\n",
       "      <td>1.006886</td>\n",
       "      <td>125.399665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>GRC</td>\n",
       "      <td>2012</td>\n",
       "      <td>54.082061</td>\n",
       "      <td>-0.449528</td>\n",
       "      <td>22.389240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>LKA</td>\n",
       "      <td>2022</td>\n",
       "      <td>43.985004</td>\n",
       "      <td>-0.889052</td>\n",
       "      <td>20.331128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>ROU</td>\n",
       "      <td>2001</td>\n",
       "      <td>47.046388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>RUS</td>\n",
       "      <td>1998</td>\n",
       "      <td>50.067652</td>\n",
       "      <td>0.527729</td>\n",
       "      <td>20.632892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>RUS</td>\n",
       "      <td>1999</td>\n",
       "      <td>50.982355</td>\n",
       "      <td>0.914703</td>\n",
       "      <td>24.846255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2015</td>\n",
       "      <td>39.211797</td>\n",
       "      <td>-0.630993</td>\n",
       "      <td>19.909780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2016</td>\n",
       "      <td>39.909523</td>\n",
       "      <td>0.697726</td>\n",
       "      <td>23.295212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2019</td>\n",
       "      <td>39.515631</td>\n",
       "      <td>0.201211</td>\n",
       "      <td>27.178869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2020</td>\n",
       "      <td>39.329346</td>\n",
       "      <td>-0.186285</td>\n",
       "      <td>34.315702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2021</td>\n",
       "      <td>39.323505</td>\n",
       "      <td>-0.005841</td>\n",
       "      <td>30.433106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2022</td>\n",
       "      <td>40.375415</td>\n",
       "      <td>1.051910</td>\n",
       "      <td>24.035787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2023</td>\n",
       "      <td>40.581943</td>\n",
       "      <td>0.206528</td>\n",
       "      <td>25.309861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iso3c  year       gain  gain_diff1  sovereign_spread\n",
       "8      ARG  2019  48.720793    0.405713         25.216374\n",
       "128    BGR  1995  48.985823         NaN         57.291017\n",
       "129    BGR  1996  49.407723    0.421899        191.905063\n",
       "130    BGR  1997  50.414609    1.006886        125.399665\n",
       "552    GRC  2012  54.082061   -0.449528         22.389240\n",
       "816    LKA  2022  43.985004   -0.889052         20.331128\n",
       "1256   ROU  2001  47.046388         NaN         29.612500\n",
       "1281   RUS  1998  50.067652    0.527729         20.632892\n",
       "1282   RUS  1999  50.982355    0.914703         24.846255\n",
       "1526   ZMB  2015  39.211797   -0.630993         19.909780\n",
       "1527   ZMB  2016  39.909523    0.697726         23.295212\n",
       "1530   ZMB  2019  39.515631    0.201211         27.178869\n",
       "1531   ZMB  2020  39.329346   -0.186285         34.315702\n",
       "1532   ZMB  2021  39.323505   -0.005841         30.433106\n",
       "1533   ZMB  2022  40.375415    1.051910         24.035787\n",
       "1534   ZMB  2023  40.581943    0.206528         25.309861"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create event flags: historical and data-driven\n",
    "df = df.copy()\n",
    "# HISTORICAL flag for Bulgaria (edit years if you prefer)\n",
    "event_years = [1995, 1996, 1997]   # change if you prefer earlier/later bounds\n",
    "df['bgr_hist_event'] = ((df['iso3c'] == 'BGR') & (df['year'].isin(event_years))).astype(int)\n",
    "\n",
    "# DATA-DRIVEN flag: large gain_diff1 or huge sovereign_spread (choose thresholds)\n",
    "df['gain_diff1'] = df.groupby('iso3c')['gain'].diff()\n",
    "# threshold by percentile\n",
    "spread_thresh = df['sovereign_spread'].quantile(0.99)    # top 1% spreads\n",
    "df['extreme_change_flag'] = (df['sovereign_spread'] >= spread_thresh).astype(int)\n",
    "\n",
    "# Quick summary\n",
    "print(\"Historical BGR event rows:\", df['bgr_hist_event'].sum())\n",
    "print(\"Data-driven extreme rows:\", df['extreme_change_flag'].sum())\n",
    "# show those rows\n",
    "display(df[df['bgr_hist_event']==1][['iso3c','year','gain','gain_diff1','sovereign_spread']])\n",
    "display(df[df['extreme_change_flag']==1][['iso3c','year','gain','gain_diff1','sovereign_spread']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee015d4",
   "metadata": {},
   "source": [
    "2) DML including the event dummy as a control and with an interaction\n",
    "\n",
    "Add the event dummy to your covariates (fold-validated). Also create an interaction term gain_lag1 * bgr_hist_event so you can test whether the ND-GAIN → spread relationship differs during the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b8dd79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOYO DML done in 15.7s; theta=0.284202; stacked rows=1468; folds used=28\n",
      "DML with event-control: theta, se, p: 0.2842019258500209 0.14224356338989652 0.04571720416784348\n"
     ]
    }
   ],
   "source": [
    "# Add flag variables to covariate set for DML\n",
    "covs_plus_event = covariates_to_use.copy()\n",
    "if 'bgr_hist_event' not in df.columns:\n",
    "    raise RuntimeError(\"Run the flag creation cell first.\")\n",
    "# include the event flag\n",
    "covs_plus_event = covs_plus_event + ['bgr_hist_event', 'extreme_change_flag']\n",
    "\n",
    "# create interaction column (lagged treatment * event)\n",
    "df['gain_lag1'] = df.groupby('iso3c')['gain'].shift(1)\n",
    "df['gain_lag1_bgr_event'] = df['gain_lag1'] * df['bgr_hist_event']\n",
    "\n",
    "# include the interaction in covariates as a control so p(X) can learn it\n",
    "covs_with_interaction = covs_plus_event + ['gain_lag1_bgr_event']\n",
    "\n",
    "# Run DML with event flag included\n",
    "out_with_event = run_dml_loyo(df.dropna(subset=[Y_col]).reset_index(drop=True), covs_with_interaction,\n",
    "                              idcol='iso3c', timecol='year', ycol=Y_col, tcol='gain_lag1', n_trees=200, random_seed=2025)\n",
    "print(\"DML with event-control: theta, se, p:\", out_with_event['theta'], \n",
    "      float(out_with_event['res'].bse[0]) if out_with_event['res'] is not None else None,\n",
    "      float(out_with_event['res'].pvalues[0]) if out_with_event['res'] is not None else None)\n",
    "# You can also check the interaction effect by running a small residual regression:\n",
    "# residualise y and regress on residualised gain_lag1 and residualised interaction (similar to DML final stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b8eab",
   "metadata": {},
   "source": [
    "3) DML excluding flagged observations (trim) — save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c674fe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOYO DML done in 12.1s; theta=-0.0180119; stacked rows=1465; folds used=28\n",
      "DML excluding BGR event rows: theta, se, p: -0.018011931524993325 0.010954055271601185 0.1001108861650819\n",
      "Saved dml_bgr_event_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Exclude BGR historical event rows (trim)\n",
    "df_trim = df[~((df['iso3c']=='BGR') & (df['bgr_hist_event']==1))].copy().reset_index(drop=True)\n",
    "df_trim['gain_lag1'] = df_trim.groupby('iso3c')['gain'].shift(1)\n",
    "\n",
    "out_no_bgr_event = run_dml_loyo(df_trim.dropna(subset=[Y_col]).reset_index(drop=True), covariates_to_use,\n",
    "                                idcol='iso3c', timecol='year', ycol=Y_col, tcol='gain_lag1', n_trees=200, random_seed=2025)\n",
    "print(\"DML excluding BGR event rows: theta, se, p:\", out_no_bgr_event['theta'],\n",
    "      float(out_no_bgr_event['res'].bse[0]) if out_no_bgr_event['res'] is not None else None,\n",
    "      float(out_no_bgr_event['res'].pvalues[0]) if out_no_bgr_event['res'] is not None else None)\n",
    "# Save summary\n",
    "import pandas as pd, os\n",
    "pd.Series({'theta_full': out_lag1['theta'], 'se_full': float(out_lag1['res'].bse[0]) if out_lag1['res'] is not None else None,\n",
    "           'theta_no_bgr_event': out_no_bgr_event['theta'], 'se_no_bgr_event': float(out_no_bgr_event['res'].bse[0]) if out_no_bgr_event['res'] is not None else None}\n",
    "          ).to_csv(os.path.join(fold_output_dir, \"dml_bgr_event_comparison.csv\"))\n",
    "print(\"Saved dml_bgr_event_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365950dd",
   "metadata": {},
   "source": [
    "3) Code — estimate interaction explicitly (residualised second stage) and compute cluster-robust OLS; then wild cluster bootstrap for the main coefficient\n",
    "\n",
    "Run the cell below. It does the following (no leakage, LOYO residualisation):\n",
    "\t•\tResidualises Y on X (LOYO) → y_res\n",
    "\t•\tResidualises treatment gain_lag1 on X (LOYO) → t_res\n",
    "\t•\tResidualises interaction gain_lag1_bgr_event on X (LOYO) → int_res\n",
    "\t•\tRuns OLS y_res ~ t_res + int_res with cluster-robust SEs and prints coefficients + clustered inference.\n",
    "\t•\tPerforms wild cluster bootstrap (Rademacher, B=999) for the t_res coefficient (and also reports bootstrap p for the interaction).\n",
    "\n",
    "Note: this uses the same LOYO structure you used earlier. It relies on the event flag bgr_hist_event and gain_lag1 being present in df. If you ran the event-creation cell earlier those exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c6081e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residuals stacked: 1468 rows; folds used: 28 elapsed: 14.592428922653198\n",
      "Final-stage OLS (clustered):\n",
      "coef_t (gain_lag1) = 0.402243, se = 0.256711, p = 0.1171\n",
      "coef_int (gain_lag1 x bgr_event) = 2.214940, se = 0.050812, p = 0.0000\n",
      "Saved interaction_finalstage.csv\n"
     ]
    }
   ],
   "source": [
    "# === Residualise Y, treatment and interaction (LOYO) and run 2-variable final-stage with cluster SEs ===\n",
    "import numpy as np, pandas as pd, statsmodels.api as sm, random, time\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# names\n",
    "idcol = 'iso3c'\n",
    "timecol = 'year'\n",
    "ycol = Y_col\n",
    "tcol = 'gain_lag1'\n",
    "event_col = 'bgr_hist_event'   # ensure you ran the flag creation\n",
    "intcol = 'gain_lag1_bgr_event' # should be tcol * event_col\n",
    "\n",
    "# Sanity check\n",
    "if event_col not in df.columns or intcol not in df.columns:\n",
    "    raise RuntimeError(\"Please create bgr_hist_event and gain_lag1_bgr_event in df first (see earlier cell).\")\n",
    "\n",
    "years = sorted(df[timecol].dropna().unique())\n",
    "y_res_list = []; t_res_list = []; int_res_list = []; groups_list = []; idxs_list = []\n",
    "start = time.time()\n",
    "\n",
    "for fnum, y in enumerate(years):\n",
    "    train = df[df[timecol] != y].reset_index(drop=True).copy()\n",
    "    test  = df[df[timecol] == y].reset_index(drop=True).copy()\n",
    "\n",
    "    # covariates to residualise on\n",
    "    covs_present = [c for c in covariates_to_use if c in train.columns]\n",
    "    if len(covs_present) == 0:\n",
    "        continue\n",
    "\n",
    "    # Build X on train/test, impute & scale on train\n",
    "    Xtr = train[covs_present].apply(pd.to_numeric, errors='coerce')\n",
    "    Xte = test[covs_present].apply(pd.to_numeric, errors='coerce')\n",
    "    try:\n",
    "        imp = KNNImputer(n_neighbors=5)\n",
    "        Xtr_imp = pd.DataFrame(imp.fit_transform(Xtr), columns=Xtr.columns)\n",
    "        Xte_imp = pd.DataFrame(imp.transform(Xte), columns=Xte.columns)\n",
    "    except Exception:\n",
    "        Xtr_imp = Xtr.fillna(Xtr.mean()); Xte_imp = Xte.fillna(Xtr.mean())\n",
    "    try:\n",
    "        sc = StandardScaler()\n",
    "        Xtr_s = pd.DataFrame(sc.fit_transform(Xtr_imp), columns=Xtr_imp.columns)\n",
    "        Xte_s = pd.DataFrame(sc.transform(Xte_imp), columns=Xte_imp.columns)\n",
    "    except Exception:\n",
    "        Xtr_s = Xtr_imp; Xte_s = Xte_imp\n",
    "\n",
    "    # add year dummies (train -> test alignment)\n",
    "    yrs_tr = pd.get_dummies(train[timecol], prefix='yr').reset_index(drop=True)\n",
    "    yrs_te = pd.get_dummies(test[timecol], prefix='yr').reindex(columns=yrs_tr.columns, fill_value=0).reset_index(drop=True)\n",
    "    Xtrain_full = pd.concat([Xtr_s.reset_index(drop=True), yrs_tr], axis=1)\n",
    "    Xtest_full  = pd.concat([Xte_s.reset_index(drop=True), yrs_te], axis=1)\n",
    "    Xtest_full  = Xtest_full.reindex(columns=Xtrain_full.columns, fill_value=0)\n",
    "\n",
    "    # Build y,t,int on train/test (numeric coercion)\n",
    "    ytr = pd.to_numeric(train[ycol], errors='coerce'); yte = pd.to_numeric(test[ycol], errors='coerce')\n",
    "    ttr = pd.to_numeric(train[tcol], errors='coerce'); tte = pd.to_numeric(test[tcol], errors='coerce')\n",
    "    itr = pd.to_numeric(train[intcol], errors='coerce'); ite = pd.to_numeric(test[intcol], errors='coerce')\n",
    "\n",
    "    # Fit nuisances on train (we'll use Lasso for p's separately for t and for interaction)\n",
    "    train_mask = (~ytr.isna()) & (~ttr.isna())  # require both present in train to fit models\n",
    "    if train_mask.sum() < 10:\n",
    "        continue\n",
    "    pos = np.where(train_mask)[0]\n",
    "    Xtrain_sub = Xtrain_full.iloc[pos,:].copy()\n",
    "    ytrain_sub = ytr.iloc[pos].copy()\n",
    "    ttrain_sub = ttr.iloc[pos].copy()\n",
    "    itrain_sub = itr.iloc[pos].copy()\n",
    "\n",
    "    # Fit m(X) for y\n",
    "    try:\n",
    "        m_model = RandomForestRegressor(n_estimators=200, random_state=2025, n_jobs=-1).fit(Xtrain_sub, ytrain_sub)\n",
    "        m_hat_test = m_model.predict(Xtest_full)\n",
    "    except Exception:\n",
    "        m_ols = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "        m_hat_test = m_ols.predict(sm.add_constant(Xtest_full))\n",
    "\n",
    "    # Fit p(X) for t (LassoCV)\n",
    "    try:\n",
    "        p_model = LassoCV(cv=5, random_state=2025).fit(Xtrain_sub, ttrain_sub)\n",
    "        p_hat_test = p_model.predict(Xtest_full)\n",
    "    except Exception:\n",
    "        from sklearn.linear_model import Lasso\n",
    "        p_model = Lasso(max_iter=10000).fit(Xtrain_sub, ttrain_sub)\n",
    "        p_hat_test = p_model.predict(Xtest_full)\n",
    "\n",
    "    # Fit p_int(X) for interaction (if variation present)\n",
    "    if np.nanvar(itrain_sub.to_numpy()) > 0:\n",
    "        try:\n",
    "            pint_model = LassoCV(cv=5, random_state=2025).fit(Xtrain_sub, itrain_sub)\n",
    "            pint_hat_test = pint_model.predict(Xtest_full)\n",
    "        except Exception:\n",
    "            from sklearn.linear_model import Lasso\n",
    "            pint_model = Lasso(max_iter=10000).fit(Xtrain_sub, itrain_sub)\n",
    "            pint_hat_test = pint_model.predict(Xtest_full)\n",
    "    else:\n",
    "        pint_hat_test = np.full(Xtest_full.shape[0], np.nan)\n",
    "\n",
    "    # Collect rows where y and t exist in test\n",
    "    test_mask = (~yte.isna()) & (~tte.isna())\n",
    "    if test_mask.sum() == 0:\n",
    "        continue\n",
    "    idxs = test.index[test_mask].tolist()\n",
    "    # residuals\n",
    "    u_vals = yte.to_numpy()[test_mask] - m_hat_test[test_mask]\n",
    "    v_vals = tte.to_numpy()[test_mask] - p_hat_test[test_mask]\n",
    "    w_vals = ite.to_numpy()[test_mask] - pint_hat_test[test_mask]  # interaction residual\n",
    "    # synthetic unique idx base\n",
    "    base = fnum * 1000000\n",
    "    idxs_unique = [base + i for i in range(len(u_vals))]\n",
    "    y_res_list.append(pd.Series(u_vals, index=idxs_unique))\n",
    "    t_res_list.append(pd.Series(v_vals, index=idxs_unique))\n",
    "    int_res_list.append(pd.Series(w_vals, index=idxs_unique))\n",
    "    groups_list.append(pd.Series(test.loc[test_mask, idcol].values, index=idxs_unique))\n",
    "\n",
    "# aggregate residuals\n",
    "u_all = pd.concat(y_res_list).sort_index()\n",
    "v_all = pd.concat(t_res_list).sort_index()\n",
    "w_all = pd.concat(int_res_list).sort_index()\n",
    "groups = pd.concat(groups_list).sort_index()\n",
    "\n",
    "print(\"Residuals stacked:\", len(u_all), \"rows; folds used:\", len(y_res_list), \"elapsed:\", time.time()-start)\n",
    "\n",
    "# run OLS y_res ~ t_res + int_res with cluster-robust SE\n",
    "Xmat = np.vstack([v_all.values, w_all.values]).T\n",
    "res2 = sm.OLS(u_all.values, Xmat).fit(cov_type='cluster', cov_kwds={'groups': groups.values})\n",
    "coefs = res2.params\n",
    "bse = res2.bse\n",
    "pvals = res2.pvalues\n",
    "print(\"Final-stage OLS (clustered):\")\n",
    "print(\"coef_t (gain_lag1) = {:.6f}, se = {:.6f}, p = {:.4f}\".format(coefs[0], bse[0], pvals[0]))\n",
    "print(\"coef_int (gain_lag1 x bgr_event) = {:.6f}, se = {:.6f}, p = {:.4f}\".format(coefs[1], bse[1], pvals[1]))\n",
    "\n",
    "# Save a small CSV with the 2 results\n",
    "pd.DataFrame([{'term':'gain_lag1','coef':coefs[0],'se':bse[0],'pval':pvals[0]},\n",
    "              {'term':'gain_lag1_x_bgr_event','coef':coefs[1],'se':bse[1],'pval':pvals[1]}]\n",
    "            ).to_csv(os.path.join(fold_output_dir, \"interaction_finalstage.csv\"), index=False)\n",
    "print(\"Saved interaction_finalstage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7b0eb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wild cluster bootstrap p-value (gain_lag1 coef): 1.0\n"
     ]
    }
   ],
   "source": [
    "# === Wild cluster bootstrap for the t coefficient from the model above ===\n",
    "B = 999\n",
    "cluster_ids = np.unique(groups.values)\n",
    "cluster_to_idxs = {c: np.where(groups.values == c)[0] for c in cluster_ids}\n",
    "beta_hat = coefs[0]\n",
    "t_obs = coefs[0] / bse[0]\n",
    "\n",
    "def wild_one():\n",
    "    # perturb cluster-level residuals (Rademacher)\n",
    "    eps = u_all.values - (beta_hat * v_all.values + coefs[1] * w_all.values)  # residual from fitted two-var model\n",
    "    ws = {c: random.choice([1.0, -1.0]) for c in cluster_ids}\n",
    "    u_star = u_all.values.copy()\n",
    "    for c, idxs in cluster_to_idxs.items():\n",
    "        u_star[idxs] = (beta_hat * v_all.values[idxs] + coefs[1] * w_all.values[idxs]) + ws[c] * eps[idxs]\n",
    "    # refit OLS on starred u\n",
    "    resb = sm.OLS(u_star, np.vstack([v_all.values, w_all.values]).T).fit()\n",
    "    return (resb.params[0] - beta_hat) / resb.bse[0]\n",
    "\n",
    "t_boot = [wild_one() for _ in range(B)]\n",
    "p_boot = np.mean(np.abs(t_boot) >= np.abs(t_obs))\n",
    "print(\"Wild cluster bootstrap p-value (gain_lag1 coef):\", p_boot)\n",
    "# Save bootstrap distribution if desired\n",
    "pd.Series(t_boot).to_csv(os.path.join(fold_output_dir, \"wild_boot_t_boot_gain_lag1.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9cf060",
   "metadata": {},
   "source": [
    "### Next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf7bbd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting base LassoCV to extract alpha_ (this is quick)\n",
      "Base alpha: 8467.83979435314\n",
      "Running spec: p_lasso_alpha_4233.919897__m_rf\n",
      "Running spec: p_lasso_alpha_4233.919897__m_xgb\n",
      "Running spec: p_lasso_alpha_8467.839794__m_rf\n",
      "Running spec: p_lasso_alpha_8467.839794__m_xgb\n",
      "Running spec: p_lasso_alpha_16935.679589__m_rf\n",
      "Running spec: p_lasso_alpha_16935.679589__m_xgb\n",
      "Running spec: p_elastic_alpha_EN__m_rf\n",
      "Running spec: p_elastic_alpha_EN__m_xgb\n",
      "Saved dml_segrid_event_control_results.csv to artifacts/dml_pooled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec</th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>pval</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p_lasso_alpha_4233.919897__m_rf</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.207577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_lasso_alpha_4233.919897__m_xgb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pandas data cast to numpy dtype of object. Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p_lasso_alpha_8467.839794__m_rf</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.207577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p_lasso_alpha_8467.839794__m_xgb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pandas data cast to numpy dtype of object. Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p_lasso_alpha_16935.679589__m_rf</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.207577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p_lasso_alpha_16935.679589__m_xgb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pandas data cast to numpy dtype of object. Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p_elastic_alpha_EN__m_rf</td>\n",
       "      <td>0.256536</td>\n",
       "      <td>0.139204</td>\n",
       "      <td>0.065348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p_elastic_alpha_EN__m_xgb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pandas data cast to numpy dtype of object. Che...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                spec     theta        se      pval  \\\n",
       "0    p_lasso_alpha_4233.919897__m_rf -0.004704  0.003733  0.207577   \n",
       "1   p_lasso_alpha_4233.919897__m_xgb       NaN       NaN       NaN   \n",
       "2    p_lasso_alpha_8467.839794__m_rf -0.004704  0.003733  0.207577   \n",
       "3   p_lasso_alpha_8467.839794__m_xgb       NaN       NaN       NaN   \n",
       "4   p_lasso_alpha_16935.679589__m_rf -0.004704  0.003733  0.207577   \n",
       "5  p_lasso_alpha_16935.679589__m_xgb       NaN       NaN       NaN   \n",
       "6           p_elastic_alpha_EN__m_rf  0.256536  0.139204  0.065348   \n",
       "7          p_elastic_alpha_EN__m_xgb       NaN       NaN       NaN   \n",
       "\n",
       "                                               error  \n",
       "0                                                NaN  \n",
       "1  Pandas data cast to numpy dtype of object. Che...  \n",
       "2                                                NaN  \n",
       "3  Pandas data cast to numpy dtype of object. Che...  \n",
       "4                                                NaN  \n",
       "5  Pandas data cast to numpy dtype of object. Che...  \n",
       "6                                                NaN  \n",
       "7  Pandas data cast to numpy dtype of object. Che...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === SE-grid and p-learner sensitivity for event-controlled lagged spec ===\n",
    "import numpy as np, pandas as pd, os, time\n",
    "from sklearn.linear_model import Lasso, LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# settings\n",
    "idcol = 'iso3c'; timecol = 'year'\n",
    "ycol = Y_col; tcol = 'gain_lag1'\n",
    "event_col = 'bgr_hist_event'\n",
    "intcol = 'gain_lag1_bgr_event'\n",
    "covs_base = covariates_to_use.copy() + [event_col, 'extreme_change_flag', intcol]  # ensure event and interaction included\n",
    "\n",
    "out_rows = []\n",
    "foldout = fold_output_dir if 'fold_output_dir' in globals() else \"artifacts\"\n",
    "os.makedirs(foldout, exist_ok=True)\n",
    "\n",
    "# helper: function to run LOYO DML using specific learners (Lasso/ElasticNet/RandomForest/XGBoost)\n",
    "def run_dml_loyo_with_learners(df_local, covs, p_learner_kind='lasso', p_alpha=None,\n",
    "                               m_learner_kind='rf', n_trees=200, random_seed=2025):\n",
    "    years = sorted(df_local[timecol].dropna().unique())\n",
    "    u_list=[]; v_list=[]; groups_list=[]\n",
    "    for fnum, y in enumerate(years):\n",
    "        train = df_local[df_local[timecol] != y].reset_index(drop=True).copy()\n",
    "        test  = df_local[df_local[timecol] == y].reset_index(drop=True).copy()\n",
    "        # basic checks\n",
    "        covs_present = [c for c in covs if c in train.columns]\n",
    "        if len(covs_present)==0: continue\n",
    "\n",
    "        # prepare X/y/t\n",
    "        Xtr = train[covs_present].apply(pd.to_numeric, errors='coerce')\n",
    "        Xte = test[covs_present].apply(pd.to_numeric, errors='coerce')\n",
    "        ytr = pd.to_numeric(train[ycol], errors='coerce'); yte = pd.to_numeric(test[ycol], errors='coerce')\n",
    "        ttr = pd.to_numeric(train[tcol], errors='coerce'); tte = pd.to_numeric(test[tcol], errors='coerce')\n",
    "\n",
    "        # impute/scale on train (KNN)\n",
    "        try:\n",
    "            from sklearn.impute import KNNImputer\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            imp = KNNImputer(n_neighbors=5)\n",
    "            Xtr_imp = pd.DataFrame(imp.fit_transform(Xtr), columns=Xtr.columns)\n",
    "            Xte_imp = pd.DataFrame(imp.transform(Xte), columns=Xte.columns)\n",
    "            sc = StandardScaler()\n",
    "            Xtr_s = pd.DataFrame(sc.fit_transform(Xtr_imp), columns=Xtr_imp.columns)\n",
    "            Xte_s = pd.DataFrame(sc.transform(Xte_imp), columns=Xte_imp.columns)\n",
    "        except Exception:\n",
    "            Xtr_s = Xtr.fillna(Xtr.mean()); Xte_s = Xte.fillna(Xtr.mean())\n",
    "\n",
    "        yrs_tr = pd.get_dummies(train[timecol], prefix='yr').reset_index(drop=True)\n",
    "        yrs_te = pd.get_dummies(test[timecol], prefix='yr').reindex(columns=yrs_tr.columns, fill_value=0).reset_index(drop=True)\n",
    "        Xtrain_full = pd.concat([Xtr_s.reset_index(drop=True), yrs_tr], axis=1)\n",
    "        Xtest_full  = pd.concat([Xte_s.reset_index(drop=True), yrs_te], axis=1)\n",
    "        Xtest_full  = Xtest_full.reindex(columns=Xtrain_full.columns, fill_value=0)\n",
    "\n",
    "        train_mask = (~ytr.isna()) & (~ttr.isna())\n",
    "        if train_mask.sum() < 10: continue\n",
    "        pos = np.where(train_mask)[0]\n",
    "        Xtrain_sub = Xtrain_full.iloc[pos,:].copy(); ytrain_sub = ytr.iloc[pos].copy(); ttrain_sub = ttr.iloc[pos].copy()\n",
    "        if np.nanvar(ttrain_sub.to_numpy()) == 0: continue\n",
    "\n",
    "        # p_learner\n",
    "        if p_learner_kind == 'lasso':\n",
    "            # using provided alpha if given, otherwise LassoCV to select\n",
    "            if p_alpha is None:\n",
    "                try:\n",
    "                    pmod = LassoCV(cv=5, random_state=random_seed).fit(Xtrain_sub, ttrain_sub)\n",
    "                    p_hat_test = pmod.predict(Xtest_full)\n",
    "                except Exception:\n",
    "                    pmod = Lasso(alpha=1e-3, max_iter=10000).fit(Xtrain_sub, ttrain_sub)\n",
    "                    p_hat_test = pmod.predict(Xtest_full)\n",
    "            else:\n",
    "                pmod = Lasso(alpha=p_alpha, max_iter=10000).fit(Xtrain_sub, ttrain_sub)\n",
    "                p_hat_test = pmod.predict(Xtest_full)\n",
    "        elif p_learner_kind == 'elastic':\n",
    "            try:\n",
    "                pmod = ElasticNetCV(cv=5, random_state=random_seed).fit(Xtrain_sub, ttrain_sub)\n",
    "                p_hat_test = pmod.predict(Xtest_full)\n",
    "            except Exception:\n",
    "                pmod = Lasso(alpha=1e-3, max_iter=10000).fit(Xtrain_sub, ttrain_sub)\n",
    "                p_hat_test = pmod.predict(Xtest_full)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown p_learner_kind\")\n",
    "\n",
    "        # m_learner\n",
    "        if m_learner_kind == 'rf':\n",
    "            try:\n",
    "                m_model = RandomForestRegressor(n_estimators=n_trees, random_state=random_seed, n_jobs=-1).fit(Xtrain_sub, ytrain_sub)\n",
    "                m_hat_test = m_model.predict(Xtest_full)\n",
    "            except Exception:\n",
    "                m_ols = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "                m_hat_test = m_ols.predict(sm.add_constant(Xtest_full))\n",
    "        elif m_learner_kind == 'xgb':\n",
    "            try:\n",
    "                from xgboost import XGBRegressor\n",
    "                m_model = XGBRegressor(n_estimators=n_trees, random_state=random_seed).fit(Xtrain_sub, ytrain_sub)\n",
    "                m_hat_test = m_model.predict(Xtest_full)\n",
    "            except Exception:\n",
    "                m_ols = sm.OLS(ytrain_sub.values, sm.add_constant(Xtrain_sub)).fit()\n",
    "                m_hat_test = m_ols.predict(sm.add_constant(Xtest_full))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown m_learner_kind\")\n",
    "\n",
    "        # collect test residuals\n",
    "        test_mask = (~yte.isna()) & (~tte.isna())\n",
    "        if test_mask.sum() == 0: continue\n",
    "        test_pos = np.where(test_mask)[0]\n",
    "        u_hat = (yte.to_numpy()[test_pos] - m_hat_test[test_pos])\n",
    "        v_hat = (tte.to_numpy()[test_pos] - p_hat_test[test_pos])\n",
    "        base = fnum * 1000000\n",
    "        idxs = [base + i for i in range(len(u_hat))]\n",
    "        u_list.append(pd.Series(u_hat, index=idxs))\n",
    "        v_list.append(pd.Series(v_hat, index=idxs))\n",
    "        groups_list.append(pd.Series(test.loc[test_pos, idcol].values, index=idxs))\n",
    "\n",
    "    # aggregate and compute theta\n",
    "    if len(u_list) == 0:\n",
    "        return {'theta': np.nan, 'res': None}\n",
    "    u_all = pd.concat(u_list).sort_index(); v_all = pd.concat(v_list).sort_index(); groups = pd.concat(groups_list).sort_index()\n",
    "    theta = (v_all * u_all).sum() / (v_all**2).sum()\n",
    "    res = sm.OLS(u_all.values, v_all.values).fit(cov_type='cluster', cov_kwds={'groups': groups.values})\n",
    "    return {'theta': float(theta), 'res': res}\n",
    "\n",
    "# 1) get base LassoCV alpha on the event-controlled spec (to build alpha grid)\n",
    "print(\"Fitting base LassoCV to extract alpha_ (this is quick)\")\n",
    "try:\n",
    "    # fit once on full training-like data for an alpha baseline (use all years except one at a time - approximate here)\n",
    "    tmp = df.dropna(subset=[ycol]).copy()\n",
    "    tmp['gain_lag1'] = tmp.groupby('iso3c')['gain'].shift(1)\n",
    "    covs_present = [c for c in covs_base if c in tmp.columns]\n",
    "    Xtmp = tmp[covs_present].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    ytmp = tmp['gain_lag1'].fillna(0)\n",
    "    base_lasso = LassoCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "    base_alpha = base_lasso.alpha_\n",
    "except Exception:\n",
    "    base_alpha = 0.001\n",
    "print(\"Base alpha:\", base_alpha)\n",
    "\n",
    "p_alphas = [base_alpha*0.5, base_alpha, base_alpha*2.0]\n",
    "p_kinds = [('lasso',a) for a in p_alphas] + [('elastic', None)]\n",
    "m_kinds = ['rf', 'xgb']  # xgb will gracefully fallback if not installed\n",
    "\n",
    "for p_kind, p_alpha in p_kinds:\n",
    "    for m_kind in m_kinds:\n",
    "        spec_name = f\"p_{p_kind}_alpha_{str(round(p_alpha,6)) if p_alpha is not None else 'EN'}__m_{m_kind}\"\n",
    "        print(\"Running spec:\", spec_name)\n",
    "        try:\n",
    "            out = run_dml_loyo_with_learners(df.dropna(subset=[ycol]).reset_index(drop=True), covs_base,\n",
    "                                             p_learner_kind=p_kind, p_alpha=p_alpha,\n",
    "                                             m_learner_kind=m_kind, n_trees=200, random_seed=2025)\n",
    "            if out['res'] is not None:\n",
    "                out_rows.append({'spec': spec_name, 'theta': out['theta'], 'se': float(out['res'].bse[0]), 'pval': float(out['res'].pvalues[0])})\n",
    "            else:\n",
    "                out_rows.append({'spec': spec_name, 'theta': out['theta'], 'se': None, 'pval': None})\n",
    "        except Exception as e:\n",
    "            out_rows.append({'spec': spec_name, 'theta': None, 'se': None, 'pval': None, 'error': str(e)})\n",
    "\n",
    "# save\n",
    "res_df = pd.DataFrame(out_rows)\n",
    "res_df.to_csv(os.path.join(foldout, \"dml_segrid_event_control_results.csv\"), index=False)\n",
    "print(\"Saved dml_segrid_event_control_results.csv to\", foldout)\n",
    "display(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1392e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   learner  p_oos_median  p_oos_mean  m_oos_median\n",
      "0    lasso      0.882269    0.572660      0.877288\n",
      "1  elastic      0.888918    0.604879      0.877288\n",
      "Learner: lasso\n",
      " p_hat mean, sd, min, max: 56.88004217940917 10.737860730317069 31.453198606591318 203.31725413024674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    28.000000\n",
       "mean      0.572660\n",
       "std       1.423682\n",
       "min      -6.660294\n",
       "25%       0.863781\n",
       "50%       0.882269\n",
       "75%       0.900349\n",
       "max       0.920427\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner: elastic\n",
      " p_hat mean, sd, min, max: 56.87734457536333 10.583753850970066 32.17211087201461 192.13454695237704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    28.000000\n",
       "mean      0.604879\n",
       "std       1.224398\n",
       "min      -5.592656\n",
       "25%       0.861242\n",
       "50%       0.888918\n",
       "75%       0.902220\n",
       "max       0.918016\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DIAG 1: LOYO p_oos_R2 and m_oos_R2 for LassoCV vs ElasticNetCV (m = RF)\n",
    "import numpy as np, pandas as pd, time\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "idcol='iso3c'; timecol='year'; ycol=Y_col; tcol='gain_lag1'\n",
    "covs = covariates_to_use.copy() + ['bgr_hist_event','extreme_change_flag','gain_lag1_bgr_event']\n",
    "\n",
    "years = sorted(df[timecol].dropna().unique())\n",
    "results = []\n",
    "\n",
    "for learner in ['lasso','elastic']:\n",
    "    p_oos_list = []\n",
    "    m_oos_list = []\n",
    "    p_hat_all = []\n",
    "    for y in years:\n",
    "        train = df[df[timecol] != y].reset_index(drop=True).copy()\n",
    "        test  = df[df[timecol] == y].reset_index(drop=True).copy()\n",
    "        covs_present = [c for c in covs if c in train.columns]\n",
    "        if len(covs_present)==0: continue\n",
    "\n",
    "        # prepare X / impute / scale on train\n",
    "        Xtr = train[covs_present].apply(pd.to_numeric, errors='coerce')\n",
    "        Xte = test[covs_present].apply(pd.to_numeric, errors='coerce')\n",
    "        try:\n",
    "            imp = KNNImputer(n_neighbors=5)\n",
    "            Xtr_imp = pd.DataFrame(imp.fit_transform(Xtr), columns=Xtr.columns)\n",
    "            Xte_imp = pd.DataFrame(imp.transform(Xte), columns=Xte.columns)\n",
    "        except Exception:\n",
    "            Xtr_imp = Xtr.fillna(Xtr.mean()); Xte_imp = Xte.fillna(Xtr.mean())\n",
    "        try:\n",
    "            sc = StandardScaler()\n",
    "            Xtr_s = pd.DataFrame(sc.fit_transform(Xtr_imp), columns=Xtr_imp.columns)\n",
    "            Xte_s = pd.DataFrame(sc.transform(Xte_imp), columns=Xte_imp.columns)\n",
    "        except Exception:\n",
    "            Xtr_s = Xtr_imp; Xte_s = Xte_imp\n",
    "\n",
    "        # year dummies alignment\n",
    "        yrs_tr = pd.get_dummies(train[timecol], prefix='yr').reset_index(drop=True)\n",
    "        yrs_te = pd.get_dummies(test[timecol], prefix='yr').reindex(columns=yrs_tr.columns, fill_value=0).reset_index(drop=True)\n",
    "        Xtrain_full = pd.concat([Xtr_s.reset_index(drop=True), yrs_tr], axis=1)\n",
    "        Xtest_full  = pd.concat([Xte_s.reset_index(drop=True), yrs_te], axis=1)\n",
    "        Xtest_full  = Xtest_full.reindex(columns=Xtrain_full.columns, fill_value=0)\n",
    "\n",
    "        ytr = pd.to_numeric(train[ycol], errors='coerce')\n",
    "        yte = pd.to_numeric(test[ycol], errors='coerce')\n",
    "        ttr = pd.to_numeric(train[tcol], errors='coerce')\n",
    "        tte = pd.to_numeric(test[tcol], errors='coerce')\n",
    "\n",
    "        train_mask = (~ytr.isna()) & (~ttr.isna())\n",
    "        if train_mask.sum() < 10:\n",
    "            continue\n",
    "        pos = np.where(train_mask)[0]\n",
    "        Xtrain_sub = Xtrain_full.iloc[pos,:]; ytrain_sub = ytr.iloc[pos]; ttrain_sub = ttr.iloc[pos]\n",
    "\n",
    "        # fit p\n",
    "        if learner=='lasso':\n",
    "            pmod = LassoCV(cv=5, random_state=2025).fit(Xtrain_sub, ttrain_sub)\n",
    "        else:\n",
    "            pmod = ElasticNetCV(cv=5, random_state=2025).fit(Xtrain_sub, ttrain_sub)\n",
    "        # predict p_hat on test rows (only where t present)\n",
    "        test_mask = (~yte.isna()) & (~tte.isna())\n",
    "        if test_mask.sum()==0: continue\n",
    "        p_hat_test = pmod.predict(Xtest_full)[test_mask.values]\n",
    "        # compute p_oos_r2 (compare t_test & p_hat_test)\n",
    "        t_test_vals = tte[test_mask].to_numpy()\n",
    "        p_oos = None\n",
    "        if len(t_test_vals) > 1:\n",
    "            p_oos = r2_score(t_test_vals, p_hat_test)\n",
    "        p_oos_list.append(p_oos if p_oos is not None else np.nan)\n",
    "        p_hat_all.extend(p_hat_test.tolist())\n",
    "\n",
    "        # fit m (RF)\n",
    "        try:\n",
    "            mmod = RandomForestRegressor(n_estimators=200, random_state=2025, n_jobs=-1).fit(Xtrain_sub, ytrain_sub)\n",
    "            m_hat_test = mmod.predict(Xtest_full)[test_mask.values]\n",
    "            m_oos = r2_score(yte[test_mask].to_numpy(), m_hat_test) if len(m_hat_test)>1 else np.nan\n",
    "        except Exception:\n",
    "            m_oos = np.nan\n",
    "        m_oos_list.append(m_oos)\n",
    "\n",
    "    results.append({\n",
    "        'learner': learner,\n",
    "        'p_oos_median': np.nanmedian(p_oos_list) if len(p_oos_list)>0 else np.nan,\n",
    "        'p_oos_mean': np.nanmean(p_oos_list) if len(p_oos_list)>0 else np.nan,\n",
    "        'm_oos_median': np.nanmedian(m_oos_list) if len(m_oos_list)>0 else np.nan,\n",
    "        'p_oos_list': p_oos_list,\n",
    "        'm_oos_list': m_oos_list,\n",
    "        'p_hat_all': p_hat_all\n",
    "    })\n",
    "\n",
    "res = pd.DataFrame([{'learner':r['learner'],'p_oos_median':r['p_oos_median'],'p_oos_mean':r['p_oos_mean'],'m_oos_median':r['m_oos_median']} for r in results])\n",
    "print(res)\n",
    "# show p_hat summaries\n",
    "for r in results:\n",
    "    print(\"Learner:\", r['learner'])\n",
    "    ph = np.array(r['p_hat_all'])\n",
    "    print(\" p_hat mean, sd, min, max:\", np.nanmean(ph), np.nanstd(ph), np.nanmin(ph), np.nanmax(ph))\n",
    "    display(pd.Series(r['p_oos_list']).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "46f4a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !brew install libomp\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "144c9bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept by ElasticNet but not Lasso: set()\n",
      "Kept by Lasso but not ElasticNet: set()\n"
     ]
    }
   ],
   "source": [
    "# DIAG 2: detailed compare nonzero coefficients from pooled fits (one-shot)\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "covs_try = [c for c in covariates_to_use if c in df.columns] + ['bgr_hist_event','extreme_change_flag','gain_lag1_bgr_event']\n",
    "Xtmp = df[covs_try].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "ytmp = df['gain_lag1'].fillna(0)\n",
    "\n",
    "en = ElasticNetCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "la = LassoCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "\n",
    "coef_en = pd.Series(en.coef_, index=Xtmp.columns)\n",
    "coef_la = pd.Series(la.coef_, index=Xtmp.columns)\n",
    "nz_en = coef_en[coef_en.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "nz_la = coef_la[coef_la.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "print(\"ElasticNet nonzero (top 30):\"); display(nz_en.head(30))\n",
    "print(\"Lasso nonzero (top 30):\"); display(nz_la.head(30))\n",
    "\n",
    "# show covariates kept by en but not la\n",
    "print(\"Kept by ElasticNet but not Lasso:\", set(nz_en.index) - set(nz_la.index))\n",
    "print(\"Kept by Lasso but not ElasticNet:\", set(nz_la.index) - set(nz_en.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24683e27",
   "metadata": {},
   "source": [
    "#### xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63adb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "298f3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost unavailable: \n",
      "XGBoost Library (libxgboost.dylib) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed\n",
      "    - vcomp140.dll or libgomp-1.dll for Windows\n",
      "    - libomp.dylib for Mac OSX\n",
      "    - libgomp.so for Linux and other UNIX-like OSes\n",
      "    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "\n",
      "Error message(s): [\"dlopen(/Users/leosgambato/Library/Python/3.9/lib/python/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <89AD948E-E564-3266-867D-7AF89D6488F0> /Users/leosgambato/Library/Python/3.9/lib/python/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Safe learner selection: use xgboost if import works, else RF\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    has_xgb = True\n",
    "    print(\"xgboost import OK, version:\", xgb.__version__)\n",
    "except Exception as e:\n",
    "    has_xgb = False\n",
    "    print(\"xgboost unavailable:\", e)\n",
    "\n",
    "# Example: construct m_learner factory\n",
    "def make_m_learner(kind='auto', n_trees=200, random_state=2025):\n",
    "    if kind == 'auto':\n",
    "        if has_xgb:\n",
    "            return xgb.XGBRegressor(n_estimators=n_trees, random_state=random_state, n_jobs=-1, verbosity=0)\n",
    "        else:\n",
    "            return RandomForestRegressor(n_estimators=n_trees, random_state=random_state, n_jobs=-1)\n",
    "    elif kind == 'xgb':\n",
    "        if not has_xgb:\n",
    "            raise RuntimeError(\"xgboost not available\")\n",
    "        return xgb.XGBRegressor(n_estimators=n_trees, random_state=random_state, n_jobs=-1, verbosity=0)\n",
    "    elif kind == 'rf':\n",
    "        return RandomForestRegressor(n_estimators=n_trees, random_state=random_state, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown kind\")\n",
    "\n",
    "# Example usage in your LOYO routine (pseudo):\n",
    "# m_model = make_m_learner('auto', n_trees=200).fit(Xtrain_sub, ytrain_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd7e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept by ElasticNet but not Lasso: set()\n",
      "Kept by Lasso but not ElasticNet: set()\n"
     ]
    }
   ],
   "source": [
    "# DIAG 2: detailed compare nonzero coefficients from pooled fits (one-shot)\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "covs_try = [c for c in covariates_to_use if c in df.columns] + ['bgr_hist_event','extreme_change_flag','gain_lag1_bgr_event']\n",
    "Xtmp = df[covs_try].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "ytmp = df['gain_lag1'].fillna(0)\n",
    "\n",
    "en = ElasticNetCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "la = LassoCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "\n",
    "coef_en = pd.Series(en.coef_, index=Xtmp.columns)\n",
    "coef_la = pd.Series(la.coef_, index=Xtmp.columns)\n",
    "nz_en = coef_en[coef_en.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "nz_la = coef_la[coef_la.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "print(\"ElasticNet nonzero (top 30):\"); display(nz_en.head(30))\n",
    "print(\"Lasso nonzero (top 30):\"); display(nz_la.head(30))\n",
    "\n",
    "# show covariates kept by en but not la\n",
    "print(\"Kept by ElasticNet but not Lasso:\", set(nz_en.index) - set(nz_la.index))\n",
    "print(\"Kept by Lasso but not ElasticNet:\", set(nz_la.index) - set(nz_en.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept by ElasticNet but not Lasso: set()\n",
      "Kept by Lasso but not ElasticNet: set()\n"
     ]
    }
   ],
   "source": [
    "# DIAG 2: detailed compare nonzero coefficients from pooled fits (one-shot)\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "covs_try = [c for c in covariates_to_use if c in df.columns] + ['bgr_hist_event','extreme_change_flag','gain_lag1_bgr_event']\n",
    "Xtmp = df[covs_try].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "ytmp = df['gain_lag1'].fillna(0)\n",
    "\n",
    "en = ElasticNetCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "la = LassoCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "\n",
    "coef_en = pd.Series(en.coef_, index=Xtmp.columns)\n",
    "coef_la = pd.Series(la.coef_, index=Xtmp.columns)\n",
    "nz_en = coef_en[coef_en.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "nz_la = coef_la[coef_la.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "print(\"ElasticNet nonzero (top 30):\"); display(nz_en.head(30))\n",
    "print(\"Lasso nonzero (top 30):\"); display(nz_la.head(30))\n",
    "\n",
    "# show covariates kept by en but not la\n",
    "print(\"Kept by ElasticNet but not Lasso:\", set(nz_en.index) - set(nz_la.index))\n",
    "print(\"Kept by Lasso but not ElasticNet:\", set(nz_la.index) - set(nz_en.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa74069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept by ElasticNet but not Lasso: set()\n",
      "Kept by Lasso but not ElasticNet: set()\n"
     ]
    }
   ],
   "source": [
    "# DIAG 2: detailed compare nonzero coefficients from pooled fits (one-shot)\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "covs_try = [c for c in covariates_to_use if c in df.columns] + ['bgr_hist_event','extreme_change_flag','gain_lag1_bgr_event']\n",
    "Xtmp = df[covs_try].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "ytmp = df['gain_lag1'].fillna(0)\n",
    "\n",
    "en = ElasticNetCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "la = LassoCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "\n",
    "coef_en = pd.Series(en.coef_, index=Xtmp.columns)\n",
    "coef_la = pd.Series(la.coef_, index=Xtmp.columns)\n",
    "nz_en = coef_en[coef_en.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "nz_la = coef_la[coef_la.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "print(\"ElasticNet nonzero (top 30):\"); display(nz_en.head(30))\n",
    "print(\"Lasso nonzero (top 30):\"); display(nz_la.head(30))\n",
    "\n",
    "# show covariates kept by en but not la\n",
    "print(\"Kept by ElasticNet but not Lasso:\", set(nz_en.index) - set(nz_la.index))\n",
    "print(\"Kept by Lasso but not ElasticNet:\", set(nz_la.index) - set(nz_en.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a2e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso nonzero (top 30):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deficit_to_gdp_lag1    0.000757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept by ElasticNet but not Lasso: set()\n",
      "Kept by Lasso but not ElasticNet: set()\n"
     ]
    }
   ],
   "source": [
    "# DIAG 2: detailed compare nonzero coefficients from pooled fits (one-shot)\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "covs_try = [c for c in covariates_to_use if c in df.columns] + ['bgr_hist_event','extreme_change_flag','gain_lag1_bgr_event']\n",
    "Xtmp = df[covs_try].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "ytmp = df['gain_lag1'].fillna(0)\n",
    "\n",
    "en = ElasticNetCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "la = LassoCV(cv=5, random_state=2025).fit(Xtmp, ytmp)\n",
    "\n",
    "coef_en = pd.Series(en.coef_, index=Xtmp.columns)\n",
    "coef_la = pd.Series(la.coef_, index=Xtmp.columns)\n",
    "nz_en = coef_en[coef_en.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "nz_la = coef_la[coef_la.abs()>1e-8].sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "print(\"ElasticNet nonzero (top 30):\"); display(nz_en.head(30))\n",
    "print(\"Lasso nonzero (top 30):\"); display(nz_la.head(30))\n",
    "\n",
    "# show covariates kept by en but not la\n",
    "print(\"Kept by ElasticNet but not Lasso:\", set(nz_en.index) - set(nz_la.index))\n",
    "print(\"Kept by Lasso but not ElasticNet:\", set(nz_la.index) - set(nz_en.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727745ee",
   "metadata": {},
   "source": [
    "## Real shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b5d72219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOYO DML done in 13.2s; theta=-0.338356; stacked rows=1468; folds used=28\n",
      "LOYO DML done in 13.2s; theta=0.035909; stacked rows=1401; folds used=27\n",
      "Saved dml_delta_gain_results.csv\n"
     ]
    }
   ],
   "source": [
    "# DML on ΔND-GAIN (contemporaneous and lagged) using Lasso-RF baseline\n",
    "df2 = df.copy()\n",
    "df2['gain_diff1'] = df2.groupby('iso3c')['gain'].diff()\n",
    "df2['gain_diff1_lag1'] = df2.groupby('iso3c')['gain_diff1'].shift(1)\n",
    "\n",
    "specs_out = {}\n",
    "\n",
    "# contemporaneous change\n",
    "df_diff = df2.dropna(subset=['gain_diff1', Y_col]).reset_index(drop=True).rename(columns={'gain_diff1':'gain_temp'})\n",
    "out_diff = run_dml_loyo(df_diff, covariates_to_use + ['bgr_hist_event','extreme_change_flag'], idcol='iso3c', timecol='year', ycol=Y_col, tcol='gain_temp', n_trees=200, random_seed=2025)\n",
    "specs_out['dml_gain_diff1'] = out_diff\n",
    "\n",
    "# lagged change\n",
    "df_difflag = df2.dropna(subset=['gain_diff1_lag1', Y_col]).reset_index(drop=True).rename(columns={'gain_diff1_lag1':'gain_temp'})\n",
    "out_difflag = run_dml_loyo(df_difflag, covariates_to_use + ['bgr_hist_event','extreme_change_flag'], idcol='iso3c', timecol='year', ycol=Y_col, tcol='gain_temp', n_trees=200, random_seed=2025)\n",
    "specs_out['dml_gain_diff1_lag1'] = out_difflag\n",
    "\n",
    "# Save results brief\n",
    "import pandas as pd, os\n",
    "rows=[]\n",
    "for k,v in specs_out.items():\n",
    "    rows.append({'spec':k, 'theta':v['theta'], 'se': float(v['res'].bse[0]) if v['res'] is not None else None, 'pval': float(v['res'].pvalues[0]) if v['res'] is not None else None})\n",
    "pd.DataFrame(rows).to_csv(os.path.join(fold_output_dir, \"dml_delta_gain_results.csv\"), index=False)\n",
    "print(\"Saved dml_delta_gain_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "16f61bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap p-value (interaction): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Run the wild cluster bootstrap for interaction (if you produced u_all, v_all, w_all, groups earlier)\n",
    "# This code returns bootstrap p-value for the interaction term (index 1).\n",
    "import random, numpy as np, pandas as pd, statsmodels.api as sm, os\n",
    "\n",
    "B = 999\n",
    "cluster_ids = np.unique(groups.values)\n",
    "cluster_to_idxs = {c: np.where(groups.values == c)[0] for c in cluster_ids}\n",
    "gamma_hat = coefs[1]   # interaction coefficient from final-stage residual OLS\n",
    "t_obs_int = gamma_hat / bse[1]\n",
    "eps = u_all.values - (coefs[0] * v_all.values + gamma_hat * w_all.values)\n",
    "\n",
    "def wild_one_interaction():\n",
    "    ws = {c: random.choice([1.0, -1.0]) for c in cluster_ids}\n",
    "    u_star = (coefs[0] * v_all.values + gamma_hat * w_all.values).copy()\n",
    "    for c, idxs in cluster_to_idxs.items():\n",
    "        u_star[idxs] = (coefs[0] * v_all.values[idxs] + gamma_hat * w_all.values[idxs]) + ws[c]*eps[idxs]\n",
    "    resb = sm.OLS(u_star, np.vstack([v_all.values, w_all.values]).T).fit()\n",
    "    return (resb.params[1] - gamma_hat) / resb.bse[1]\n",
    "\n",
    "t_boot = [wild_one_interaction() for _ in range(B)]\n",
    "p_boot_int = np.mean(np.abs(t_boot) >= np.abs(t_obs_int))\n",
    "pd.Series(t_boot).to_csv(os.path.join(fold_output_dir, \"wild_boot_t_boot_interaction.csv\"), index=False)\n",
    "print(\"Bootstrap p-value (interaction):\", p_boot_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fe68f894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dml_final_master_summary.csv to artifacts/dml_pooled\n"
     ]
    }
   ],
   "source": [
    "# Compile final summary CSV from saved outputs and in-memory results\n",
    "import pandas as pd, os\n",
    "\n",
    "summary = []\n",
    "\n",
    "def add_spec(name, out_dict):\n",
    "    try:\n",
    "        res = out_dict.get('res', None)\n",
    "        theta = out_dict.get('theta', None)\n",
    "        se = float(res.bse[0]) if (res is not None and hasattr(res, \"bse\")) else None\n",
    "        pval = float(res.pvalues[0]) if (res is not None and hasattr(res, \"pvalues\")) else None\n",
    "        summary.append({\n",
    "            'spec': name,\n",
    "            'theta': theta,\n",
    "            'se': se,\n",
    "            'pval': pval\n",
    "        })\n",
    "    except Exception as e:\n",
    "        summary.append({'spec': name, 'theta': out_dict.get('theta', None), 'se': None, 'pval': None})\n",
    "\n",
    "# Only add specs if the objects exist in the namespace\n",
    "if 'out_lag1' in locals():\n",
    "    add_spec('pooled_lag1', out_lag1)\n",
    "if 'out_with_event' in locals():\n",
    "    add_spec('lag1_event_control', out_with_event)\n",
    "if 'out_no_bgr_event' in locals():\n",
    "    add_spec('lag1_no_bgr', out_no_bgr_event)\n",
    "if 'out_fe' in locals():\n",
    "    add_spec('fe_dml', out_fe)\n",
    "if 'out_mundlak_obj' in locals():\n",
    "    add_spec('mundlak', out_mundlak_obj)\n",
    "# Example for elasticnet_rf, replace with real object if available\n",
    "if 'out_elasticnet_rf' in locals():\n",
    "    add_spec('elasticnet_rf', out_elasticnet_rf)\n",
    "else:\n",
    "    add_spec('elasticnet_rf', {'theta': 0.256535, 'res': None})\n",
    "\n",
    "pd.DataFrame(summary).to_csv(os.path.join(fold_output_dir, \"dml_final_master_summary.csv\"), index=False)\n",
    "print(\"Saved dml_final_master_summary.csv to\", fold_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "638c16fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gain: min, mean, max: 31.9854538648142 56.87173187903155 78.3151199668366\n",
      "vulnerability: min, mean, max: 0.251030071399067 0.36961605168882466 0.568568181856243\n",
      "Correlation: gain vs spread: -0.41413460811725195\n",
      "Correlation: vulnerability vs spread: 0.3588327093129401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3c</th>\n",
       "      <th>year</th>\n",
       "      <th>gain</th>\n",
       "      <th>vulnerability</th>\n",
       "      <th>sovereign_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2010</td>\n",
       "      <td>46.299003</td>\n",
       "      <td>0.401211</td>\n",
       "      <td>15.604236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2012</td>\n",
       "      <td>45.844055</td>\n",
       "      <td>0.402685</td>\n",
       "      <td>9.079577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2013</td>\n",
       "      <td>45.512061</td>\n",
       "      <td>0.400681</td>\n",
       "      <td>6.987068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2014</td>\n",
       "      <td>45.076998</td>\n",
       "      <td>0.401534</td>\n",
       "      <td>7.833954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2015</td>\n",
       "      <td>44.899691</td>\n",
       "      <td>0.401350</td>\n",
       "      <td>5.376118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2016</td>\n",
       "      <td>46.512091</td>\n",
       "      <td>0.402708</td>\n",
       "      <td>1.361908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2017</td>\n",
       "      <td>46.441575</td>\n",
       "      <td>0.403896</td>\n",
       "      <td>4.101448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2018</td>\n",
       "      <td>48.315080</td>\n",
       "      <td>0.383315</td>\n",
       "      <td>14.894352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARG</td>\n",
       "      <td>2019</td>\n",
       "      <td>48.720793</td>\n",
       "      <td>0.381365</td>\n",
       "      <td>25.216374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2013</td>\n",
       "      <td>51.706720</td>\n",
       "      <td>0.363941</td>\n",
       "      <td>11.647921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2014</td>\n",
       "      <td>52.875154</td>\n",
       "      <td>0.360753</td>\n",
       "      <td>8.735600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2015</td>\n",
       "      <td>53.071007</td>\n",
       "      <td>0.361692</td>\n",
       "      <td>12.745292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2016</td>\n",
       "      <td>53.430073</td>\n",
       "      <td>0.362617</td>\n",
       "      <td>12.605876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2017</td>\n",
       "      <td>53.525618</td>\n",
       "      <td>0.360058</td>\n",
       "      <td>8.786274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2018</td>\n",
       "      <td>54.130369</td>\n",
       "      <td>0.367643</td>\n",
       "      <td>6.812326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2019</td>\n",
       "      <td>55.238560</td>\n",
       "      <td>0.368527</td>\n",
       "      <td>7.347392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2020</td>\n",
       "      <td>55.689762</td>\n",
       "      <td>0.370648</td>\n",
       "      <td>7.094562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2021</td>\n",
       "      <td>56.244156</td>\n",
       "      <td>0.364062</td>\n",
       "      <td>7.938411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2022</td>\n",
       "      <td>56.413472</td>\n",
       "      <td>0.359561</td>\n",
       "      <td>8.257838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ARM</td>\n",
       "      <td>2023</td>\n",
       "      <td>56.714012</td>\n",
       "      <td>0.357312</td>\n",
       "      <td>7.084159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iso3c  year       gain  vulnerability  sovereign_spread\n",
       "0    ARG  2010  46.299003       0.401211         15.604236\n",
       "1    ARG  2012  45.844055       0.402685          9.079577\n",
       "2    ARG  2013  45.512061       0.400681          6.987068\n",
       "3    ARG  2014  45.076998       0.401534          7.833954\n",
       "4    ARG  2015  44.899691       0.401350          5.376118\n",
       "5    ARG  2016  46.512091       0.402708          1.361908\n",
       "6    ARG  2017  46.441575       0.403896          4.101448\n",
       "7    ARG  2018  48.315080       0.383315         14.894352\n",
       "8    ARG  2019  48.720793       0.381365         25.216374\n",
       "9    ARM  2013  51.706720       0.363941         11.647921\n",
       "10   ARM  2014  52.875154       0.360753          8.735600\n",
       "11   ARM  2015  53.071007       0.361692         12.745292\n",
       "12   ARM  2016  53.430073       0.362617         12.605876\n",
       "13   ARM  2017  53.525618       0.360058          8.786274\n",
       "14   ARM  2018  54.130369       0.367643          6.812326\n",
       "15   ARM  2019  55.238560       0.368527          7.347392\n",
       "16   ARM  2020  55.689762       0.370648          7.094562\n",
       "17   ARM  2021  56.244156       0.364062          7.938411\n",
       "18   ARM  2022  56.413472       0.359561          8.257838\n",
       "19   ARM  2023  56.714012       0.357312          7.084159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick checks: what is 'gain' and 'vulnerability' relation and correlation with spread\n",
    "print(\"gain: min, mean, max:\", df['gain'].min(), df['gain'].mean(), df['gain'].max())\n",
    "if 'vulnerability' in df.columns:\n",
    "    print(\"vulnerability: min, mean, max:\", df['vulnerability'].min(), df['vulnerability'].mean(), df['vulnerability'].max())\n",
    "print(\"Correlation: gain vs spread:\", df[['gain','sovereign_spread']].dropna().corr().iloc[0,1])\n",
    "if 'vulnerability' in df.columns:\n",
    "    print(\"Correlation: vulnerability vs spread:\", df[['vulnerability','sovereign_spread']].dropna().corr().iloc[0,1])\n",
    "# Inspect few rows\n",
    "display(df[['iso3c','year','gain','vulnerability','sovereign_spread']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6a4670e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\n",
      "(31.985, 37.133]    8.528894\n",
      "(37.133, 42.281]    8.537515\n",
      "(42.281, 47.429]    6.401155\n",
      "(47.429, 52.576]    6.491366\n",
      "(52.576, 57.724]    2.212224\n",
      "(57.724, 62.872]    0.355864\n",
      "(62.872, 68.02]    -0.312648\n",
      "(68.02, 73.167]    -0.169486\n",
      "(73.167, 78.315]   -0.029130\n",
      "Name: sovereign_spread, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# simple scatter\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(df['gain'], df['sovereign_spread'], alpha=0.3)\n",
    "plt.xlabel('gain'); plt.ylabel('sovereign_spread'); plt.title('gain vs spread')\n",
    "plt.show()\n",
    "\n",
    "# binned average\n",
    "import numpy as np\n",
    "df_temp = df.dropna(subset=['gain','sovereign_spread'])\n",
    "bins = np.linspace(df_temp['gain'].min(), df_temp['gain'].max(), 10)\n",
    "df_temp['bin'] = pd.cut(df_temp['gain'], bins)\n",
    "print(df_temp.groupby('bin')['sovereign_spread'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d903c387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOYO DML done in 12.9s; theta=0.460759; stacked rows=1468; folds used=28\n",
      "Pooled lag1: 0.4607589973175241 0.33710072376720807 0.1716789551307546\n",
      "LOYO DML done in 14.5s; theta=0.298408; stacked rows=1468; folds used=28\n",
      "Pooled lag1 + BGR event: 0.2984084833464504 0.11507961159030124 0.009512582311993395\n",
      "LOYO DML done in 12.9s; theta=0.0518418; stacked rows=1466; folds used=28\n",
      "Pooled lag1 excluding BGR event years: 0.05184184380145649 0.019300253891159785 0.0072297818939481995\n"
     ]
    }
   ],
   "source": [
    "    # 1) create lags/leads\n",
    "df['gain_lag1'] = df.groupby('iso3c')['gain'].shift(1)\n",
    "df['gain_lag2'] = df.groupby('iso3c')['gain'].shift(2)\n",
    "df['gain_lag3'] = df.groupby('iso3c')['gain'].shift(3)\n",
    "# leads (placebo)\n",
    "df['gain_lead1'] = df.groupby('iso3c')['gain'].shift(-1)\n",
    "df['gain_lead2'] = df.groupby('iso3c')['gain'].shift(-2)\n",
    "\n",
    "# If you prefer vulnerability variable (higher = worse), create it:\n",
    "# df['vulnerability'] = 100.0 - df['gain']   # only if you want to invert 'gain'\n",
    "# df['vulnerability_lag1'] = df.groupby('iso3c')['vulnerability'].shift(1)\n",
    "\n",
    "# 2) baseline: pooled lag1 (use 'gain_lag1' or 'vulnerability_lag1')\n",
    "tcol = 'gain_lag1'\n",
    "df_run = df.dropna(subset=[tcol, Y_col]).reset_index(drop=True)\n",
    "out_pooled_lag1 = run_dml_loyo(df_run, covariates_to_use, idcol='iso3c', timecol='year',\n",
    "                               ycol=Y_col, tcol=tcol, n_trees=200, random_seed=2025)\n",
    "print(\"Pooled lag1:\", out_pooled_lag1['theta'], float(out_pooled_lag1['res'].bse[0]), float(out_pooled_lag1['res'].pvalues[0]))\n",
    "\n",
    "# 3) pooled + Bulgaria event control\n",
    "covs_plus = covariates_to_use + ['bgr_hist_event','extreme_change_flag']\n",
    "# optionally add interaction term (vul_lag1_bgr) if used in your pipeline\n",
    "df_run['gain_lag1_bgr'] = df_run['gain_lag1'] * df_run.get('bgr_hist_event', 0)\n",
    "covs_plus.append('gain_lag1_bgr')\n",
    "\n",
    "out_pooled_lag1_event = run_dml_loyo(df_run, covs_plus, idcol='iso3c', timecol='year',\n",
    "                                     ycol=Y_col, tcol=tcol, n_trees=200, random_seed=2025)\n",
    "print(\"Pooled lag1 + BGR event:\", out_pooled_lag1_event['theta'],\n",
    "      float(out_pooled_lag1_event['res'].bse[0]), float(out_pooled_lag1_event['res'].pvalues[0]))\n",
    "\n",
    "# 4) pooled excluding BGR event years\n",
    "df_no_bgr = df[~((df['iso3c']=='BGR') & (df.get('bgr_hist_event',0)==1))].copy()\n",
    "df_run2 = df_no_bgr.dropna(subset=[tcol, Y_col]).reset_index(drop=True)\n",
    "out_pooled_lag1_no_bgr = run_dml_loyo(df_run2, covariates_to_use, idcol='iso3c', timecol='year',\n",
    "                                      ycol=Y_col, tcol=tcol, n_trees=200, random_seed=2025)\n",
    "print(\"Pooled lag1 excluding BGR event years:\", out_pooled_lag1_no_bgr['theta'],\n",
    "      float(out_pooled_lag1_no_bgr['res'].bse[0]), float(out_pooled_lag1_no_bgr['res'].pvalues[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fa4dcdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr gain vs gdp_pc: 0.77914823053717\n",
      "corr gain vs wgi_ge: 0.8994312552665098\n",
      "corr gdp_pc vs spread: -0.3443151262774711\n",
      "partial corr (gain,spread | gdp,wgi): -0.05826558125073728\n"
     ]
    }
   ],
   "source": [
    "# correlations\n",
    "print(\"corr gain vs gdp_pc:\", df[['gain','gdp_per_capita']].dropna().corr().iloc[0,1])\n",
    "print(\"corr gain vs wgi_ge:\", df[['gain','wgi_ge']].dropna().corr().iloc[0,1])\n",
    "print(\"corr gdp_pc vs spread:\", df[['gdp_per_capita','sovereign_spread']].dropna().corr().iloc[0,1])\n",
    "# partial correlation (gain vs spread controlling for gdp_pc and wgi_ge)\n",
    "import statsmodels.api as sm\n",
    "ctrls = df[['gdp_per_capita','wgi_ge']].apply(pd.to_numeric, errors='coerce')\n",
    "tmp = df[['gain','sovereign_spread']].join(ctrls).dropna()\n",
    "res1 = sm.OLS(tmp['gain'], sm.add_constant(tmp[['gdp_per_capita','wgi_ge']])).fit()\n",
    "res2 = sm.OLS(tmp['sovereign_spread'], sm.add_constant(tmp[['gdp_per_capita','wgi_ge']])).fit()\n",
    "gain_resid = res1.resid\n",
    "spread_resid = res2.resid\n",
    "import numpy as np\n",
    "print(\"partial corr (gain,spread | gdp,wgi):\", np.corrcoef(gain_resid, spread_resid)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3be152ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With: ['gain_lag1']  coef gain: -0.2817914960531141 p: 3.2395774911278696e-17\n",
      "With: ['gain_lag1', 'ln_gdp_per_capita_lag1']  coef gain: -0.06480669791982335 p: 0.39078813031819726\n",
      "With: ['gain_lag1', 'ln_gdp_per_capita_lag1', 'wgi_ge_lag1']  coef gain: 0.04799001792912996 p: 0.37034374475868415\n",
      "With: ['gain_lag1', 'ln_gdp_per_capita_lag1', 'wgi_ge_lag1', 'sovereign_spread_lag1']  coef gain: -0.006309732542455055 p: 0.706863185519852\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "base = ['gain_lag1'] \n",
    "df['wgi_ge_lag1'] = df.groupby('iso3c')['wgi_ge'].shift(1) # or vulnerability_lag1 if you prefer\n",
    "suspects = ['ln_gdp_per_capita_lag1','wgi_ge_lag1','sovereign_spread_lag1']\n",
    "for i in range(len(suspects)+1):\n",
    "    Xcols = base + suspects[:i]\n",
    "    tmp = df.dropna(subset=Xcols+[Y_col]).copy()\n",
    "    X = sm.add_constant(tmp[Xcols].apply(pd.to_numeric, errors='coerce'))\n",
    "    y = tmp[Y_col].astype(float)\n",
    "    res = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': tmp['iso3c']})\n",
    "    print(\"With:\", Xcols, \" coef gain:\", res.params['gain_lag1'], \"p:\", res.pvalues['gain_lag1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOYO DML done in 9.9s; theta=0.439669; stacked rows=1468; folds used=28\n",
      "core (0.4396687897124389, 0.2443512718432048, 0.0719663556648683)\n",
      "LOYO DML done in 7.3s; theta=0.335524; stacked rows=1468; folds used=28\n",
      "no_gdp (0.335523648268108, 0.21410394246614928, 0.11708983467508763)\n",
      "LOYO DML done in 8.6s; theta=0.36641; stacked rows=1468; folds used=28\n",
      "no_wgi (0.3664095205938563, 0.1745974605206101, 0.03585253516844122)\n",
      "LOYO DML done in 9.3s; theta=0.231969; stacked rows=1468; folds used=28\n",
      "no_lagspread (0.23196936589831618, 0.20901900637942103, 0.2670850695723538)\n",
      "LOYO DML done in 10.8s; theta=0.439669; stacked rows=1468; folds used=28\n",
      "core_plus_suspects (0.43966878971243883, 0.24435127184320468, 0.07196635566486823)\n"
     ]
    }
   ],
   "source": [
    "df['wgi_rl_lag1'] = df.groupby('iso3c')['wgi_rl'].shift(1)\n",
    "# Define covariate sets\n",
    "core = ['gdp_annual_growth_rate_lag1','ln_gdp_per_capita_lag1','debt_to_gdp_lag1',\n",
    "        'deficit_to_gdp_lag1','cpi_yoy_lag1','sovereign_spread_lag1',\n",
    "        'vix','us_10y','brent','wgi_ge_lag1','wgi_rl_lag1']  # baseline core: lagged macros + lagged WGIs\n",
    "\n",
    "no_gdp = [c for c in core if 'gdp' not in c]   # drop GDP vars\n",
    "no_wgi = [c for c in core if not c.startswith('wgi_')]\n",
    "no_lagspread = [c for c in core if c!='sovereign_spread_lag1']\n",
    "\n",
    "specs = {\n",
    "    'core': core,\n",
    "    'no_gdp': no_gdp,\n",
    "    'no_wgi': no_wgi,\n",
    "    'no_lagspread': no_lagspread,\n",
    "    'core_plus_suspects': core + ['credit_rating_lag1']  # example of adding potential mediators \n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, covs in specs.items():\n",
    "    df_run = df.dropna(subset=['gain_lag1', Y_col]).reset_index(drop=True)\n",
    "    out = run_dml_loyo(df_run, covs, idcol='iso3c', timecol='year', ycol=Y_col, tcol='gain_lag1',\n",
    "                       n_trees=200, random_seed=2025)\n",
    "    results[name] = (out['theta'], float(out['res'].bse[0]), float(out['res'].pvalues[0]))\n",
    "    print(name, results[name])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
